{"pages":[],"posts":[{"title":"Backpack II","text":"Question lintcode: (125) Backpack II Problem Statement Given n items with size $$Ai$$ and value Vi, and a backpack with size m.What’s the maximum value can you put into the backpack? ExampleGiven 4 items with size [2, 3, 5, 7] and value [1, 5, 2, 4], and abackpack with size 10. The maximum value is 9. NoteYou cannot divide item into small pieces and the total size of items youchoose should smaller or equal to m. ChallengeO(n x m) memory is acceptable, can you do it in O(m) memory? 题解首先定义状态 $$K(i,w)$$ 为前 $$i$$ 个物品放入size为 $$w$$ 的背包中所获得的最大价值，则相应的状态转移方程为：$$K(i,w) = \\max {K(i-1, w), K(i-1, w - w_i) + v_i}$$ 详细分析过程见 Knapsack C++ - 2D vector for result12345678910111213141516171819202122232425262728293031323334class Solution {public: /** * @param m: An integer m denotes the size of a backpack * @param A &amp; V: Given n items with size A[i] and value V[i] * @return: The maximum value */ int backPackII(int m, vector&lt;int&gt; A, vector&lt;int&gt; V) { if (A.empty() || V.empty() || m &lt; 1) { return 0; } const int N = A.size() + 1; const int M = m + 1; vector&lt;vector&lt;int&gt; &gt; result; result.resize(N); for (vector&lt;int&gt;::size_type i = 0; i != N; ++i) { result[i].resize(M); std::fill(result[i].begin(), result[i].end(), 0); } for (vector&lt;int&gt;::size_type i = 1; i != N; ++i) { for (int j = 0; j != M; ++j) { if (j &lt; A[i - 1]) { result[i][j] = result[i - 1][j]; } else { int temp = result[i - 1][j - A[i - 1]] + V[i - 1]; result[i][j] = max(temp, result[i - 1][j]); } } } return result[N - 1][M - 1]; }}; Java12345678910111213141516171819202122232425public class Solution { /** * @param m: An integer m denotes the size of a backpack * @param A &amp; V: Given n items with size A[i] and value V[i] * @return: The maximum value */ public int backPackII(int m, int[] A, int V[]) { if (A == null || V == null || A.length == 0 || V.length == 0) return 0; final int N = A.length; final int M = m; int[][] bp = new int[N + 1][M + 1]; for (int i = 0; i &lt; N; i++) { for (int j = 0; j &lt;= M; j++) { if (A[i] &gt; j) { bp[i + 1][j] = bp[i][j]; } else { bp[i + 1][j] = Math.max(bp[i][j], bp[i][j - A[i]] + V[i]); } } } return bp[N][M]; }} 源码分析 使用二维矩阵保存结果result 返回result矩阵的右下角元素——背包size限制为m时的最大价值 按照第一题backpack的思路，这里可以使用一维数组进行空间复杂度优化。优化方法为逆序求result[j]，优化后的代码如下： C++ 1D vector for result12345678910111213141516171819202122232425262728293031class Solution {public: /** * @param m: An integer m denotes the size of a backpack * @param A &amp; V: Given n items with size A[i] and value V[i] * @return: The maximum value */ int backPackII(int m, vector&lt;int&gt; A, vector&lt;int&gt; V) { if (A.empty() || V.empty() || m &lt; 1) { return 0; } const int M = m + 1; vector&lt;int&gt; result; result.resize(M); std::fill(result.begin(), result.end(), 0); for (vector&lt;int&gt;::size_type i = 0; i != A.size(); ++i) { for (int j = m; j &gt;= 0; --j) { if (j &lt; A[i]) { // result[j] = result[j]; } else { int temp = result[j - A[i]] + V[i]; result[j] = max(temp, result[j]); } } } return result[M - 1]; }}; Reference Lintcode: Backpack II - neverlandly - 博客园 九章算法 | 背包问题","link":"/2019/09/22/Backpack-II/"},{"title":"CYK算法详解与代码实现","text":"概述在计算机科学领域，CYK算法（也称为Cocke–Younger–Kasami算法）是一种用来对上下文无关文法（CFG，Context Free Grammar）进行语法分析（parsing）的算法。该算法最早由John Cocke, Daniel Younger and Tadao Kasami分别独立提出，其中John Cocke还是1987年度的图灵奖得主。CYK算法是基于动态规划思想设计的一种自底向上语法分析算法。 乔姆斯基范式我们首先来谈谈CNF的话题。通常把一门语言定义成一些由单词组成的词串（也就是句子）构成的集合。所以如果问两种语法（或文法）是否等价，其实就是要考察它们能否生成完全一样的词串集合。事实上，两个完全不同的CFG是不可能生成相同语言的。 而谈到两种语法“等价”，我们又可以定义弱等价和强等价两种类型的等价： 如果两种语法能够生成相同的词串集合，且为每个句子都赋与相同的短语结构（phrase structure），也就是说仅允许对non-terminal symbols进行重命名，那么它们就是强等价的。 如果两种语法能够生成相同的词串集合，但不会为每个句子都赋与相同的短语结构，那么它们就是弱等价的。 CNF(Chomsky Normal Form)是一种这样的语法标准： 如果一个$CFG是 \\varepsilon-free$，而且它的规则只有如下两种形式: $A\\rightarrow BC$ $A\\rightarrow a$ 那么这个CFG就是CNF形式的，可见CNF语法都是二分叉的。任何语法都可以转化成一个弱等价的CNF形式，具体方法如下： Step 1: Convert $A\\rightarrow Bc$ to $A\\rightarrow BC$,$C\\rightarrow c$ Step 2: Convert $A\\rightarrow BCD$ to $A\\rightarrow BX,X\\rightarrow CD$ CYK算法CYK算法处理的语法必须是CNF形式的，所以如果输入的是任意文法，那么需要按照前面的步骤把CFG转换成CNF形式。 CYK算法是用来判断一个字符串是否属于某个CNF语法，故设输入的字符串w长度为n。 接下来我们需要用程序填一个动态规划的状态转移表，这里我们叫这个表parse table。 parse table的规模为$(n + 1) \\times n$ 算法原理注意，我们前面说过CYK是一种自底向上的算法，这里的自底向上意思是从单词开始，朝向 S(句子)工作。所以在上图我们填写的大方向是从左到右填写的。S 位于表的右上角，表示成功。算法描述如下：其中，i 和 j 指示的内容如下图所示： 我们定义$PT[n + 1][n]$表示parse table，且$PT[n, :]$依次存储字符串w中的每一个符号$a_1, a_2, \\dots, a_n$。$$\\begin{bmatrix}&amp; &amp;\\dots &amp; \\&amp; \\vdots &amp; \\ddots &amp; \\a_1 &amp; a_2 &amp; \\dots &amp;a_n\\end{bmatrix} %]]&gt;$$我们设根据给定CNF，即G能推导出w中第i到第j个字符的串的集合为$x_{i,j}$ 为了填写这个表，我们一行一行，自下而上地处理。每一行对应一种长度的子串。最下面一行对应长度为1的子串，倒数第二行对应长度为2的子串，以此类推。最上面一行就对应长度为n的子串，即w本身。计算该表的任何一个表项的方法如下： 对于最下面一行的元素，即$x_{i,i}$，是使得$A \\rightarrow a_i$是G的产生式的变元A的集合。 对于不在最下面一行的元素，我们需要找到符合以下条件的变元A的集合： 1、整数k满足$i \\leq k &lt; j$ 2、$B \\in X_{i,k}$ 3、$C \\in X_{k+1, j}$ 4、$A \\rightarrow BC$是G的产生式 根据这样的方法，我们可以填出一个下三角矩阵。 例如： CNF文法G的产生式：$$S \\rightarrow AB|BC \\A \\rightarrow BA|a \\B \\rightarrow CC|b \\C \\rightarrow AB|a$$对L(G)测试字符串$w = baaba$的成员性构造Parse Table如下：$$\\begin{bmatrix}x_{1,5}={S, A,C} &amp; &amp; &amp; &amp; \\&amp; x_{2,5}={S, A, C} &amp; &amp; &amp; \\&amp; x_{2,4}={B} &amp; x_{3,5}={B} &amp; &amp; \\x_{1,2} = {S, A} &amp; x_{2,3}={B} &amp; x_{3,4}={S, C} &amp; x_{4,5}={S, A} &amp;\\x_{1,1} = {B} &amp; x_{2,2} = {A, C} &amp; x_{3,3} ={A, C} &amp; x_{4,4}={B } &amp; x_{5,5}={A,C} \\a_1 = b &amp; a_2 = a &amp; a_3 = a &amp; a_4 = b &amp; a_5 = a\\end{bmatrix} %]]&gt;$$最终得到$x_{1,5}$集合之后，判断起始变元$S$是否属于$x_{1,5}$。如果是，则w可被G接受，反之不接受。 代码实现cyk.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#!usr/bin/env/python 3.6.5#-*- coding: utf-8 -*-'''Python 3.6.5installed module: - tkinter'''import reimport itertoolsimport tkinterfrom tkinter import ttkclass CNF(object): def __init__(self): self.__rules = {} def read_file(self, filename): with open(filename, 'r') as inFile: for line in inFile.readlines(): line = re.sub('[\\n\\t ]', '', line) rec_begin = line[:line.find('-')] for element in line[line.find('&gt;') + 1:].split('|'): if element in self._CNF__rules: self.__rules[element].append(rec_begin) else: self._CNF__rules[element] = [rec_begin] def get_inf(self, tar): if isinstance(tar, list) == False: exit() inf_set = [] for tarEle in tar: inf_set.extend(self.__rules.get(tarEle, [])) return list(set(inf_set))class CYK(object): def __init__(self, filename): if isinstance(filename, str) == False: exit() self.__str = '' self.__srtlen = 0 self.__canvas = [] self.__myCNF = CNF() self.__myCNF.read_file(filename) def get_str(self): self._CYK__str = input('input string:\\n').strip() if len(self._CYK__str) == 0: exit() self._CYK__srtlen = len(self._CYK__str) # MaxRow == MaxCol + 1 self._CYK__canvas = list(list([] for tmp in range(self._CYK__srtlen)) for tmp in range(self._CYK__srtlen + 1)) for iter in range(self._CYK__srtlen): self._CYK__canvas[self._CYK__srtlen][iter].append(self._CYK__str[iter]) def CYK_process(self): # for lowest level for col in range(self._CYK__srtlen): self._CYK__canvas[self._CYK__srtlen - 1][col].extend(self._CYK__myCNF.get_inf(self._CYK__canvas[self._CYK__srtlen][col])) # for upper level for row in range(self._CYK__srtlen - 2, -1, -1): for col in range(row + 1): mid_set = set() idx_i, idx_j = col + 1, col - row + self._CYK__srtlen for mid_k in range(idx_i, idx_j): fir_row, fir_col = idx_i - mid_k - 1 + self._CYK__srtlen, idx_i - 1 sec_row, sec_col = mid_k - idx_j + self._CYK__srtlen, mid_k mid_set |= set(obj[0] + obj[1] for obj in itertools.product(self._CYK__canvas[fir_row][fir_col], self._CYK__canvas[sec_row][sec_col])) self._CYK__canvas[row][col].extend(self._CYK__myCNF.get_inf(list(mid_set))) # get answer if 'S' in self._CYK__canvas[0][0]: print ('%s can be accepted.' % self._CYK__str) else: print ('%s can not be accepted.' % self._CYK__str) def GUI_show(self): def exc(line, step, row): if isinstance(line, list) == False and isinstance(line[0], list) == False: exit() for col in range(len(line)): line[col] = str('{' + '%s, ' * (len(line[col]) - 1) + '%s' * (len(line[col]) &gt; 0) + '}') % (tuple(line[col])) if col &lt;= row: line[col] = 'X%d,%d = ' % (col + 1, step + col + 1) + line[col] return (line) # default window = tkinter.Tk() window.geometry('800x400') window.title('CYK algorithm') table = ttk.Treeview(window, height = 10, show = 'headings') table['columns'] = (list(elem for elem in range(self._CYK__srtlen))) for col in range(self._CYK__srtlen): table.column(str(col), width = 100) # y&amp;x scrollbar yscrollbar = tkinter.Scrollbar(window, orient = tkinter.VERTICAL, command = table.yview) table.configure(yscrollcommand = yscrollbar.set) yscrollbar.pack(side = tkinter.RIGHT, fill = tkinter.Y) xscrollbar = tkinter.Scrollbar(window, orient = tkinter.HORIZONTAL, command = table.xview) table.configure(xscrollcommand = xscrollbar.set) xscrollbar.pack(side = tkinter.TOP, fill = tkinter.X) # insert information for row in range(self._CYK__srtlen): table.insert('', row, values = exc(self._CYK__canvas[row], self._CYK__srtlen - row - 1, row)) table.insert('', self._CYK__srtlen, values = (self._CYK__canvas[self._CYK__srtlen])) # end table.pack(side = tkinter.TOP, expand = 1, fill = tkinter.BOTH) window.mainloop()def main(): myCYK = CYK('./CNF.cfg') myCYK.get_str() myCYK.CYK_process() myCYK.GUI_show()if __name__ == '__main__': main() 实验效果 参考文献概率上下文无关文法PCFG Tagging Problems, and Hidden Markov Models NLP底层技术之语言模型","link":"/2018/07/15/CYK%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%E4%B8%8E%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},{"title":"First Position of Target","text":"Question lintcode: First Position of Target Problem Statement For a given sorted array (ascending order) and a target number, find thefirst index of this number in O(log n) time complexity. If the target number does not exist in the array, return -1. Example If the array is [1, 2, 3, 3, 4, 5, 10], for given target 3, return 2. Challenge If the count of numbers is bigger than $$2^{32}$$, can your code work properly? 题解 对于已排序升序(升序)数组，使用二分查找可满足复杂度要求，注意数组中可能有重复值，所以需要使用类似lower_bound中提到的方法。 Java12345678910111213141516171819202122232425262728293031class Solution { /** * @param nums: The integer array. * @param target: Target to find. * @return: The first position of target. Position starts from 0. */ public int binarySearch(int[] nums, int target) { if (nums == null || nums.length == 0) { return -1; } int start = -1, end = nums.length; int mid; while (start + 1 &lt; end) { // avoid overflow when (end + start) mid = start + (end - start) / 2; if (nums[mid] &lt; target) { start = mid; } else { end = mid; } } if (end == nums.length || nums[end] != target) { return -1; } else { return end; } }} 源码分析 首先对输入做异常处理，数组为空或者长度为0。 初始化 start, end, mid三个变量，这里start初始化为-1主要是考虑到end为1。注意mid的求值方法，可以防止两个整型值相加时溢出。 使用迭代而不是递归进行二分查找，因为工程中递归写法存在潜在溢出的可能。 while终止条件应为start + 1 &lt; end而不是start &lt;= end，start == end时可能出现死循环。即循环终止条件是相邻或相交元素时退出。由于这里初始化时start &lt; end，所以一定是start + 1 == end时退出循环。 迭代终止时有两种情况，一种是在原数组中找到了，这种情况下一定是end, 因为start的更新只在nums[mid] &lt; target. 最后判断end和target的关系，先排除end为数组长度这种会引起越界的情况，然后再判断和目标值是否相等。 复杂度分析时间复杂度 $$O(\\log n)$$, 空间复杂度 $$(1)$$.对于题中的 follow up, Java 中数组不允许使用 long 型，如果使用 long 型，那么数组大小可大 17GB 之巨！！几乎没法用。 Reference 《挑战程序设计竞赛》3.1节","link":"/2019/10/29/First-Position-of-Target/"},{"title":"Palindrome Linked List","text":"Question leetcode: Palindrome Linked List | LeetCode OJ lintcode: Palindrome Linked List Function to check if a singly linked list is palindrome - GeeksforGeeks Problem Statement Implement a function to check if a linked list is a palindrome. ExampleGiven 1-&gt;2-&gt;1, return true ChallengeCould you do it in O(n) time and O(1) space? 题解1 - 使用辅助栈根据栈的特性(FILO)，可以首先遍历链表并入栈(最后访问栈时则反过来了)，随后再次遍历链表并比较当前节点和栈顶元素，若比较结果完全相同则为回文。 又根据回文的特性，实际上还可以只遍历链表前半部分节点，再用栈中的元素和后半部分元素进行比较，分链表节点个数为奇数或者偶数考虑即可。由于链表长度未知，因此可以考虑使用快慢指针求得。 Python123456789101112131415161718192021222324252627282930## Definition for singly-linked list# class ListNode:# def __init__(self, val):# self.val = val# self.next = Noneclass Solution: # @param head, a ListNode # @return a boolean def is_palindrome(self, head): if not head or not head.next: return True stack = [] slow, fast = head, head.next while fast and fast.next: stack.append(slow.val) slow = slow.next fast = fast.next.next # for even numbers add mid if fast: stack.append(slow.val) curt = slow.next while curt: if curt.val != stack.pop(): return False curt = curt.next return True 源码分析注意， 在python code中， slow 和 fast pointer 分别指向head 和head.next。 这样指向的好处是：当linked－list 有奇数个数字的时候， 最终位置，slow会停在mid的位置， 而fast指向空。 当linked－list有偶数个node时， 最终位置，slow和slow.next为中间的两个元素， fast指向最后一个node。所以slow的最终位置总是mid 或者mid 偏左一点的位置。这样的位置非常方便分割linked－list，以及其他计算。推荐采用这种方法来寻找linked－list的mid位置。模版优势，请见solution2。 Java12345678910111213141516171819202122232425262728293031323334353637/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */public class Solution { /** * @param head a ListNode * @return a boolean */ public boolean isPalindrome(ListNode head) { if (head == null || head.next == null) return true; Deque&lt;Integer&gt; stack = new ArrayDeque&lt;Integer&gt;(); // find middle ListNode slow = head, fast = head; while (fast != null &amp;&amp; fast.next != null) { stack.push(slow.val); slow = slow.next; fast = fast.next.next; } // skip mid node if the number of ListNode is odd if (fast != null) slow = slow.next; ListNode rCurr = slow; while (rCurr != null) { if (rCurr.val != stack.pop()) return false; rCurr = rCurr.next; } return true; }} 源码分析注意区分好链表中个数为奇数还是偶数就好了，举几个简单例子辅助分析。 复杂度分析使用了栈作为辅助空间，空间复杂度为 $$O(\\frac{1}{2}n)$$, 分别遍历链表的前半部分和后半部分，时间复杂度为 $$O(n)$$. 题解2 - 原地翻转题解 1 的解法使用了辅助空间，在可以改变原来的链表的基础上，可使用原地翻转，思路为翻转前半部分，然后迭代比较。具体可分为以下四个步骤。 找中点。 翻转链表的后半部分。 逐个比较前后部分节点值。 链表复原，翻转后半部分链表。 Python123456789101112131415161718192021222324252627282930313233# class ListNode:# def __init__(self, val):# self.val = val# self.next = Noneclass Solution: def is_palindrome(self, head): if not head or not head.next: return True slow, fast = head, head.next while fast and fast.next: fast = fast.next.next slow = slow.next mid = slow.next # break slow.next = None rhead = self.reverse(mid) while rhead: if rhead.val != head.val: return False rhead = rhead.next head = head.next return True def reverse(self, head): dummy = ListNode(-1) while head: temp = head.next head.next = dummy.next dummy.next = head head = temp return dummy.next 源码分析对比Java code， 会发现，把slow 和fast pointer 放在head和head.next减少了对odd 或者even number的判断。因为slow总是在mid的位置或者mid偏左的位置上， 所以把mid assign 为slow.next总是对的。 Java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */public class Solution { /** * @param head a ListNode * @return a boolean */ public boolean isPalindrome(ListNode head) { if (head == null || head.next == null) return true; // find middle ListNode slow = head, fast = head; while (fast != null &amp;&amp; fast.next != null) { slow = slow.next; fast = fast.next.next; } // skip mid node if the number of ListNode is odd if (fast != null) slow = slow.next; // reverse right part of List ListNode rHead = reverse(slow); ListNode lCurr = head, rCurr = rHead; while (rCurr != null) { if (rCurr.val != lCurr.val) { reverse(rHead); return false; } lCurr = lCurr.next; rCurr = rCurr.next; } // recover right part of List reverse(rHead); return true; } private ListNode reverse(ListNode head) { ListNode prev = null; while (head != null) { ListNode after = head.next; head.next = prev; prev = head; head = after; } return prev; }} C++12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution {public: bool isPalindrome(ListNode* head) { if (!head || !head-&gt;next) return true; // find middle ListNode* slow = head, *fast = head; while (fast &amp;&amp; fast-&gt;next) { slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; } // skip mid node if the number of ListNode is odd if (fast) slow = slow-&gt;next; // reverse right part of List ListNode* rHead = reverse(slow); ListNode* lCurr = head, *rCurr = rHead; while (rCurr) { if (rCurr-&gt;val != lCurr-&gt;val) { reverse(rHead); return false; } lCurr = lCurr-&gt;next; rCurr = rCurr-&gt;next; } // recover right part of List reverse(rHead); return true; } ListNode* reverse(ListNode* head) { ListNode* prev = NULL; while (head) { ListNode* after = head-&gt;next; head-&gt;next = prev; prev = head; head = after; } return prev; }} 源码分析连续翻转两次右半部分链表即可复原原链表，将一些功能模块如翻转等尽量模块化。 复杂度分析遍历链表若干次，时间复杂度近似为 $$O(n)$$, 使用了几个临时遍历，空间复杂度为 $$O(1)$$. 题解3 - 递归(TLE)递归需要两个重要条件，递归步的建立和递归终止条件。对于回文比较，理所当然应该递归比较第 i 个节点和第 n-i 个节点，那么问题来了，如何构建这个递归步？大致可以猜想出来递归的传入参数应该包含两个节点，用以指代第 i 个节点和第 n-i 个节点。返回参数应该包含布尔值(用以提前返回不是回文的情况)和左半部分节点的下一个节点(用以和右半部分的节点进行比较)。由于需要返回两个值，在 Java 中需要使用自定义类进行封装，C/C++ 中则可以使用指针改变在递归调用后进行比较时节点的值。 Python1234567891011class Solution: def is_palindrome(self, head): result = [head, True] self.helper(head, result) return result[1] def helper(self, right, result): if right: self.helper(right.next, result) is_pal = result[0].val == right.val and result[1] result = [result[0].next, is_pal] Java123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */class Result { ListNode lNode; boolean isP; Result(ListNode node, boolean isP) { this.lNode = node; this.isP = isP; }}public class Solution { /** * @param head a ListNode * @return a boolean */ public boolean isPalindrome(ListNode head) { Result result = new Result(head, true); helper(head, result); return result.isP; } private void helper(ListNode right, Result result) { if (right != null) { helper(right.next, result); boolean equal = (result.lNode.val == right.val); result.isP = equal &amp;&amp; result.isP; result.lNode = result.lNode.next; } }} 源码分析核心代码为如何在递归中推进左半部分节点而对右半部分使用栈的方式逆向获取节点。左半部分的推进需要借助辅助数据结构Result. 复杂度分析递归调用 n 层，时间复杂度近似为 $$O(n)$$, 使用了几个临时变量，空间复杂度为 $$O(1)$$. Bonus - Fancy Python Solution1234567class Solution: def is_palindrome(self, head): nodes = [] while head: nodes.append(head.val) head = head.next return nodes == nodes[::-1] 源码分析将linked－list问题，转化成判断一个array是否为palindrome的问题。 复杂度分析时间复杂度 $$O(n)$$, 空间复杂度也是 $$O(n)$$ Reference Function to check if a singly linked list is palindrome - GeeksforGeeks 回文判断 | The-Art-Of-Programming-By-July/01.04.md ctci/QuestionB.java at master · gaylemcd/ctci","link":"/2019/10/15/Palindrome-Linked-List/"},{"title":"Python惯例","text":"“惯例”这个词指的是“习惯的做法，常规的办法，一贯的做法”，与这个词对应的英文单词叫“idiom”。由于Python跟其他很多编程语言在语法和使用上还是有比较显著的差别，因此作为一个Python开发者如果不能掌握这些惯例，就无法写出“Pythonic”的代码。下面我们总结了一些在Python开发中的惯用的代码。 让代码既可以被导入又可以被执行。 12if __name__ == '__main__': 用下面的方式判断逻辑“真”或“假”。 123if x:if not x: 好的代码： 123456name = 'jackfrued'fruits = ['apple', 'orange', 'grape']owners = {'1001': '骆昊', '1002': '王大锤'}if name and fruits and owners: print('I love fruits!') 不好的代码： 123456name = 'jackfrued'fruits = ['apple', 'orange', 'grape']owners = {'1001': '骆昊', '1002': '王大锤'}if name != '' and len(fruits) &gt; 0 and owners != {}: print('I love fruits!') 善于使用in运算符。 123if x in items: # 包含for x in items: # 迭代 好的代码： 1234name = 'Hao LUO'if 'L' in name: print('The name has an L in it.') 不好的代码： 1234name = 'Hao LUO'if name.find('L') != -1: print('This name has an L in it!') 不使用临时变量交换两个值。 12a, b = b, a 用序列构建字符串。 好的代码： 1234chars = ['j', 'a', 'c', 'k', 'f', 'r', 'u', 'e', 'd']name = ''.join(chars)print(name) # jackfrued 不好的代码： 123456chars = ['j', 'a', 'c', 'k', 'f', 'r', 'u', 'e', 'd']name = ''for char in chars: name += charprint(name) # jackfrued EAFP优于LBYL。 EAFP - Easier to Ask Forgiveness than Permission. LBYL - Look Before You Leap. 好的代码： 1234567d = {'x': '5'}try: value = int(d['x']) print(value)except (KeyError, TypeError, ValueError): value = None 不好的代码： 12345678d = {'x': '5'}if 'x' in d and isinstance(d['x'], str) \\ and d['x'].isdigit(): value = int(d['x']) print(value)else: value = None 使用enumerate进行迭代。 好的代码： 1234fruits = ['orange', 'grape', 'pitaya', 'blueberry']for index, fruit in enumerate(fruits): print(index, ':', fruit) 不好的代码： 123456fruits = ['orange', 'grape', 'pitaya', 'blueberry']index = 0for fruit in fruits: print(index, ':', fruit) index += 1 用生成式生成列表。 好的代码： 1234data = [7, 20, 3, 15, 11]result = [num * 3 for num in data if num &gt; 10]print(result) # [60, 45, 33] 不好的代码： 1234567data = [7, 20, 3, 15, 11]result = []for i in data: if i &gt; 10: result.append(i * 3)print(result) # [60, 45, 33] 用zip组合键和值来创建字典。 好的代码： 12345keys = ['1001', '1002', '1003']values = ['骆昊', '王大锤', '白元芳']d = dict(zip(keys, values))print(d) 不好的代码： 1234567keys = ['1001', '1002', '1003']values = ['骆昊', '王大锤', '白元芳']d = {}for i, key in enumerate(keys): d[key] = values[i]print(d) 说明：这篇文章的内容来自于网络，有兴趣的读者可以阅读原文。","link":"/2017/07/08/Python%E6%83%AF%E4%BE%8B/"},{"title":"Remove Duplicates from Sorted List II","text":"Question leetcode: Remove Duplicates from Sorted List II | LeetCode OJ lintcode: (113) Remove Duplicates from Sorted List II Problem Statement Given a sorted linked list, delete all nodes that have duplicate numbers,leaving only distinct numbers from the original list. ExampleGiven 1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5, return 1-&gt;2-&gt;5.Given 1-&gt;1-&gt;1-&gt;2-&gt;3, return 2-&gt;3. 题解上题为保留重复值节点的一个，这题删除全部重复节点，看似区别不大，但是考虑到链表头不确定(可能被删除，也可能保留)，因此若用传统方式需要较多的if条件语句。这里介绍一个处理链表头节点不确定的方法——引入dummy node. 123ListNode *dummy = new ListNode(0);dummy-&gt;next = head;ListNode *node = dummy; 引入新的指针变量dummy，并将其next变量赋值为head，考虑到原来的链表头节点可能被删除，故应该从dummy处开始处理，这里复用了head变量。考虑链表A-&gt;B-&gt;C，删除B时，需要处理和考虑的是A和C，将A的next指向C。如果从空间使用效率考虑，可以使用head代替以上的node，含义一样，node比较好理解点。 与上题不同的是，由于此题引入了新的节点dummy，不可再使用node-&gt;val == node-&gt;next-&gt;val，原因有二： 此题需要将值相等的节点全部删掉，而删除链表的操作与节点前后两个节点都有关系，故需要涉及三个链表节点。且删除单向链表节点时不能删除当前节点，只能改变当前节点的next指向的节点。 在判断val是否相等时需先确定node-&gt;next和node-&gt;next-&gt;next均不为空，否则不可对其进行取值。 说多了都是泪，先看看我的错误实现： C++ - Wrong12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Definition of ListNode * class ListNode { * public: * int val; * ListNode *next; * ListNode(int val) { * this-&gt;val = val; * this-&gt;next = NULL; * } * } */class Solution{public: /** * @param head: The first node of linked list. * @return: head node */ ListNode * deleteDuplicates(ListNode *head) { if (head == NULL || head-&gt;next == NULL) { return NULL; } ListNode *dummy; dummy-&gt;next = head; ListNode *node = dummy; while (node-&gt;next != NULL &amp;&amp; node-&gt;next-&gt;next != NULL) { if (node-&gt;next-&gt;val == node-&gt;next-&gt;next-&gt;val) { int val = node-&gt;next-&gt;val; while (node-&gt;next != NULL &amp;&amp; val == node-&gt;next-&gt;val) { ListNode *temp = node-&gt;next; node-&gt;next = node-&gt;next-&gt;next; delete temp; } } else { node-&gt;next = node-&gt;next-&gt;next; } } return dummy-&gt;next; }}; 错因分析错在什么地方？ 节点dummy的初始化有问题，对类的初始化应该使用new 在else语句中node-&gt;next = node-&gt;next-&gt;next;改写了dummy-next中的内容，返回的dummy-next不再是队首元素，而是队尾元素。原因很微妙，应该使用node = node-&gt;next;，node代表节点指针变量，而node-&gt;next代表当前节点所指向的下一节点地址。具体分析可自行在纸上画图分析，可对指针和链表的理解又加深不少。 图中上半部分为ListNode的内存示意图，每个框底下为其内存地址。dummy指针变量本身的地址为ox7fff5d0d2500，其保存着指针变量值为0x7fbe7bc04c50. head指针变量本身的地址为ox7fff5d0d2508，其保存着指针变量值为0x7fbe7bc04c00. 好了，接下来看看正确实现及解析。 Python12345678910111213141516171819202122232425# Definition for singly-linked list.# class ListNode:# def __init__(self, x):# self.val = x# self.next = Noneclass Solution: # @param {ListNode} head # @return {ListNode} def deleteDuplicates(self, head): if head is None: return None dummy = ListNode(0) dummy.next = head node = dummy while node.next is not None and node.next.next is not None: if node.next.val == node.next.next.val: val_prev = node.next.val while node.next is not None and node.next.val == val_prev: node.next = node.next.next else: node = node.next return dummy.next C++123456789101112131415161718192021222324252627282930313233/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) {} * }; */class Solution {public: ListNode* deleteDuplicates(ListNode* head) { if (head == NULL) return NULL; ListNode dummy(0); dummy.next = head; ListNode *node = &amp;dummy; while (node-&gt;next != NULL &amp;&amp; node-&gt;next-&gt;next != NULL) { if (node-&gt;next-&gt;val == node-&gt;next-&gt;next-&gt;val) { int val_prev = node-&gt;next-&gt;val; // remove ListNode node-&gt;next while (node-&gt;next != NULL &amp;&amp; val_prev == node-&gt;next-&gt;val) { ListNode *temp = node-&gt;next; node-&gt;next = node-&gt;next-&gt;next; delete temp; } } else { node = node-&gt;next; } } return dummy.next; }}; Java1234567891011121314151617181920212223242526272829/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */public class Solution { public ListNode deleteDuplicates(ListNode head) { if (head == null) return null; ListNode dummy = new ListNode(0); dummy.next = head; ListNode node = dummy; while(node.next != null &amp;&amp; node.next.next != null) { if (node.next.val == node.next.next.val) { int val_prev = node.next.val; while (node.next != null &amp;&amp; node.next.val == val_prev) { node.next = node.next.next; } } else { node = node.next; } } return dummy.next; }} 源码分析 首先考虑异常情况，head 为 NULL 时返回 NULL new一个dummy变量，dummy-&gt;next指向原链表头。(C++中最好不要使用 new 的方式生成 dummy, 否则会有内存泄露) 使用新变量node并设置其为dummy头节点，遍历用。 当前节点和下一节点val相同时先保存当前值，便于while循环终止条件判断和删除节点。注意这一段代码也比较精炼。 最后返回dummy-&gt;next，即题目所要求的头节点。 Python 中也可不使用is not None判断，但是效率会低一点。 复杂度分析两根指针(node.next 和 node.next.next)遍历，时间复杂度为 $$O(2n)$$. 使用了一个 dummy 和中间缓存变量，空间复杂度近似为 $$O(1)$$. Reference Remove Duplicates from Sorted List II | 九章","link":"/2019/10/19/Remove-Duplicates-from-Sorted-List-II/"},{"title":"Reverse Linked List II","text":"Question leetcode: Reverse Linked List II | LeetCode OJ lintcode: (36) Reverse Linked List II Problem Statement Reverse a linked list from position m to n. Example Given 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL, m = 2 and n = 4, return1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;NULL. Note Given m, n satisfy the following condition: 1 ≤ m ≤ n ≤ length of list. Challenge Reverse it in-place and in one-pass 题解此题在上题的基础上加了位置要求，只翻转指定区域的链表。由于链表头节点不确定，祭出我们的dummy杀器。此题边界条件处理特别tricky，需要特别注意。 由于只翻转指定区域，分析受影响的区域为第m-1个和第n+1个节点 找到第m个节点，使用for循环n-m次，使用上题中的链表翻转方法 处理第m-1个和第n+1个节点 返回dummy-&gt;next C++123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * Definition of singly-linked-list: * * class ListNode { * public: * int val; * ListNode *next; * ListNode(int val) { * this-&gt;val = val; * this-&gt;next = NULL; * } * } */class Solution {public: /** * @param head: The head of linked list. * @param m: The start position need to reverse. * @param n: The end position need to reverse. * @return: The new head of partial reversed linked list. */ ListNode *reverseBetween(ListNode *head, int m, int n) { if (head == NULL || m &gt; n) { return NULL; } ListNode *dummy = new ListNode(0); dummy-&gt;next = head; ListNode *node = dummy; for (int i = 1; i != m; ++i) { if (node == NULL) { return NULL; } else { node = node-&gt;next; } } ListNode *premNode = node; ListNode *mNode = node-&gt;next; ListNode *nNode = mNode, *postnNode = nNode-&gt;next; for (int i = m; i != n; ++i) { if (postnNode == NULL) { return NULL; } ListNode *temp = postnNode-&gt;next; postnNode-&gt;next = nNode; nNode = postnNode; postnNode = temp; } premNode-&gt;next = nNode; mNode-&gt;next = postnNode; return dummy-&gt;next; }}; Java1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Definition for ListNode * public class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */public class Solution { /** * @param ListNode head is the head of the linked list * @oaram m and n * @return: The head of the reversed ListNode */ public ListNode reverseBetween(ListNode head, int m , int n) { ListNode dummy = new ListNode(0); dummy.next = head; // find the mth node ListNode premNode = dummy; for (int i = 1; i &lt; m; i++) { premNode = premNode.next; } // reverse node between m and n ListNode prev = null, curr = premNode.next; while (curr != null &amp;&amp; (m &lt;= n)) { ListNode nextNode = curr.next; curr.next = prev; prev = curr; curr = nextNode; m++; } // join head and tail before m and after n premNode.next.next = curr; premNode.next = prev; return dummy.next; }} 源码分析 处理异常 使用dummy辅助节点 找到premNode——m节点之前的一个节点 以nNode和postnNode进行遍历翻转，注意考虑在遍历到n之前postnNode可能为空 连接premNode和nNode，premNode-&gt;next = nNode; 连接mNode和postnNode，mNode-&gt;next = postnNode; 务必注意node 和node-&gt;next的区别！！，node指代节点，而node-&gt;next指代节点的下一连接。","link":"/2019/10/23/Reverse-Linked-List-II/"},{"title":"Rotate List","text":"Question leetcode: Rotate List | LeetCode OJ lintcode: (170) Rotate List Problem Statement Given a list, rotate the list to the right by k places, where k is non-negative. Example Given 1-&gt;2-&gt;3-&gt;4-&gt;5 and k = 2, return 4-&gt;5-&gt;1-&gt;2-&gt;3. 题解旋转链表，链表类问题通常需要找到需要处理节点处的前一个节点。因此我们只需要找到旋转节点和最后一个节点即可。需要注意的细节是 k 有可能比链表长度还要大，此时需要取模，另一个 corner case 则是链表长度和 k 等长。 Java123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */public class Solution { /** * @param head: the List * @param k: rotate to the right k places * @return: the list after rotation */ public ListNode rotateRight(ListNode head, int k) { if (head == null) return head; ListNode fast = head, slow = head; int len = 1; for (len = 1; fast.next != null &amp;&amp; len &lt;= k; len++) { fast = fast.next; } // k mod len if k &gt; len if (len &lt;= k) { k = k % len; fast = head; for (int i = 0; i &lt; k; i++) { fast = fast.next; } } // forward slow and fast while (fast.next != null) { fast = fast.next; slow = slow.next; } // return new head fast.next = head; head = slow.next; slow.next = null; return head; }} 源码分析由于需要处理的是节点的前一个节点，故最终的while 循环使用fast.next != null. k 与链表等长时包含在len &lt;= k中。 复杂度分析时间复杂度 $$O(n)$$, 空间复杂度 $$O(1)$$.","link":"/2019/10/24/Rotate-List/"},{"title":"Sort List","text":"Question leetcode: Sort List | LeetCode OJ lintcode: (98) Sort List 1Sort a linked list in O(n log n) time using constant space complexity. 题解1 - 归并排序(链表长度求中间节点)链表的排序操作，对于常用的排序算法，能达到 $$O(n \\log n)$$的复杂度有快速排序(平均情况)，归并排序，堆排序。快速排序不一定能保证其时间复杂度一定满足要求，归并排序和堆排序都能满足复杂度的要求。在数组排序中，归并排序通常需要使用 $$O(n)$$ 的额外空间，也有原地归并的实现，代码写起来略微麻烦一点。但是对于链表这种非随机访问数据结构，所谓的「排序」不过是指针next值的变化而已，主要通过指针操作，故仅需要常数级别的额外空间，满足题意。堆排序通常需要构建二叉树，在这道题中不太适合。 既然确定使用归并排序，我们就来思考归并排序实现的几个要素。 按长度等分链表，归并虽然不严格要求等分，但是等分能保证线性对数的时间复杂度。由于链表不能随机访问，故可以先对链表进行遍历求得其长度。 合并链表，细节已在 Merge Two Sorted Lists | Data Structure and Algorithm 中详述。 在按长度等分链表时进行「后序归并」——先求得左半部分链表的表头，再求得右半部分链表的表头，最后进行归并操作。 由于递归等分链表的操作需要传入链表长度信息，故需要另建一辅助函数。新鲜出炉的源码如下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * Definition of ListNode * class ListNode { * public: * int val; * ListNode *next; * ListNode(int val) { * this-&gt;val = val; * this-&gt;next = NULL; * } * } */class Solution {public: /** * @param head: The first node of linked list. * @return: You should return the head of the sorted linked list, using constant space complexity. */ ListNode *sortList(ListNode *head) { if (NULL == head) { return NULL; } // get the length of List int len = 0; ListNode *node = head; while (NULL != node) { node = node-&gt;next; ++len; } return sortListHelper(head, len); }private: ListNode *sortListHelper(ListNode *head, const int length) { if ((NULL == head) || (0 &gt;= length)) { return head; } ListNode *midNode = head; int count = 1; while (count &lt; length / 2) { midNode = midNode-&gt;next; ++count; } ListNode *rList = sortListHelper(midNode-&gt;next, length - length / 2); midNode-&gt;next = NULL; ListNode *lList = sortListHelper(head, length / 2); return mergeList(lList, rList); } ListNode *mergeList(ListNode *l1, ListNode *l2) { ListNode *dummy = new ListNode(0); ListNode *lastNode = dummy; while ((NULL != l1) &amp;&amp; (NULL != l2)) { if (l1-&gt;val &lt; l2-&gt;val) { lastNode-&gt;next = l1; l1 = l1-&gt;next; } else { lastNode-&gt;next = l2; l2 = l2-&gt;next; } lastNode = lastNode-&gt;next; } lastNode-&gt;next = (NULL != l1) ? l1 : l2; return dummy-&gt;next; }}; 源码分析 归并子程序没啥好说的了，见 Merge Two Sorted Lists | Data Structure and Algorithm. 在递归处理链表长度时，分析方法和 Convert Sorted List to Binary Search Tree | Data Structure and Algorithm 一致，**count表示遍历到链表中间时表头指针需要移动的节点数。**在纸上分析几个简单例子后即可确定，由于这个题需要的是「左右」而不是二叉搜索树那道题需要三分——「左中右」，故将count初始化为1更为方便，左半部分链表长度为length / 2, 这两个值的确定最好是先用纸笔分析再视情况取初值，不可死记硬背。 找到中间节点后首先将其作为右半部分链表处理，然后将其next值置为NULL, 否则归并子程序无法正确求解。这里需要注意的是midNode是左半部分的最后一个节点，midNode-&gt;next才是链表右半部分的起始节点。 递归模型中左、右、合并三者的顺序可以根据分治思想确定，即先找出左右链表，最后进行归并(因为归并排序的前提是两个子链表各自有序)。 复杂度分析遍历求得链表长度，时间复杂度为 $$O(n)$$, 「折半取中」过程中总共有 $$\\log(n)$$ 层，每层找中点需遍历 $$n/2$$ 个节点，故总的时间复杂度为 $$ n/2 \\cdot O(\\log n)$$ (折半取中), 每一层归并排序的时间复杂度介于 $$O(n/2)$$ 和 $$O(n)$$之间，故总的时间复杂度为 $$O(n \\log n)$$, 空间复杂度为常数级别，满足题意。 题解2 - 归并排序(快慢指针求中间节点)除了遍历链表求得总长外，还可使用看起来较为巧妙的技巧如「快慢指针」，快指针每次走两步，慢指针每次走一步，最后慢指针所指的节点即为中间节点。使用这种特技的关键之处在于如何正确确定快慢指针的起始位置。 C++12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * Definition of ListNode * class ListNode { * public: * int val; * ListNode *next; * ListNode(int val) { * this-&gt;val = val; * this-&gt;next = NULL; * } * } */class Solution {public: /** * @param head: The first node of linked list. * @return: You should return the head of the sorted linked list, using constant space complexity. */ ListNode *sortList(ListNode *head) { if (NULL == head || NULL == head-&gt;next) { return head; } ListNode *midNode = findMiddle(head); ListNode *rList = sortList(midNode-&gt;next); midNode-&gt;next = NULL; ListNode *lList = sortList(head); return mergeList(lList, rList); }private: ListNode *findMiddle(ListNode *head) { if (NULL == head || NULL == head-&gt;next) { return head; } ListNode *slow = head, *fast = head-&gt;next; while(NULL != fast &amp;&amp; NULL != fast-&gt;next) { fast = fast-&gt;next-&gt;next; slow = slow-&gt;next; } return slow; } ListNode *mergeList(ListNode *l1, ListNode *l2) { ListNode *dummy = new ListNode(0); ListNode *lastNode = dummy; while ((NULL != l1) &amp;&amp; (NULL != l2)) { if (l1-&gt;val &lt; l2-&gt;val) { lastNode-&gt;next = l1; l1 = l1-&gt;next; } else { lastNode-&gt;next = l2; l2 = l2-&gt;next; } lastNode = lastNode-&gt;next; } lastNode-&gt;next = (NULL != l1) ? l1 : l2; return dummy-&gt;next; }}; ###Java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Definition for ListNode. * public class ListNode { * int val; * ListNode next; * ListNode(int val) { * this.val = val; * this.next = null; * } * } */ public class Solution { /** * @param head: The head of linked list. * @return: You should return the head of the sorted linked list, using constant space complexity. */ public ListNode sortList(ListNode head) { // write your code here if (head == null || head.next == null) return head; ListNode mid = findMid(head); ListNode head1 = head; ListNode head2 = mid.next; mid.next = null; ListNode left = sortList(head1); ListNode right = sortList(head2); return merge(left, right); } // find mid public ListNode findMid(ListNode head) { if (head == null) return null; ListNode fast = head.next; ListNode slow = head; while (fast != null &amp;&amp; fast.next != null) { fast = fast.next.next; slow = slow.next; } return slow; } // merge public ListNode merge(ListNode head1, ListNode head2) { ListNode dummy = new ListNode(0); ListNode head = dummy; while (head1 != null || head2 != null) { int a = head1 == null ? Integer.MAX_VALUE : head1.val; int b = head2 == null ? Integer.MAX_VALUE : head2.val; if (a &lt; b) { head.next = new ListNode(a); if (head1 != null) head1 = head1.next; } else { head.next = new ListNode(b); if (head2 != null) head2 = head2.next; } head = head.next; } return dummy.next; } } 源码分析 异常处理不仅考虑了head, 还考虑了head-&gt;next, 可减少辅助程序中的异常处理。 使用快慢指针求中间节点时，将fast初始化为head-&gt;next可有效避免无法分割两个节点如1-&gt;2-&gt;null[^fast_slow_pointer]。 求中点的子程序也可不做异常处理，但前提是主程序sortList中对head-&gt;next做了检测。 最后进行merge归并排序。 Note 在递归和迭代程序中，需要尤其注意终止条件的确定，以及循环语句中变量的自增，以防出现死循环或访问空指针。 复杂度分析同上。 题解3 - 归并排序(自底向上)归并排序，总的时间复杂度是（nlogn),但是递归的空间复杂度并不是常数（和递归的层数有着关；递归的过程是自顶向下，好理解；这里提供自底向上的非递归方法； C++12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) {} * }; */class Solution {public: ListNode* sortList(ListNode* head) { int len_list = 0; ListNode *p=head; while(p){ p = p-&gt;next; len_list++; } ListNode *l_list,*r_list,**p_merge_list; for(int i = 1; i &lt; len_list; i &lt;&lt;= 1){ r_list = l_list = head; p_merge_list = &amp;head; for(int j = 0; j &lt; len_list - i ; j += i &lt;&lt; 1){ for(int k = 0; k &lt; i; ++k) r_list=r_list-&gt;next; int l_len=i,r_len=min(i, len_list - j - i); while(l_len || r_len ){ if(r_len &gt; 0 &amp;&amp; (l_len == 0 || r_list-&gt;val &lt;= l_list-&gt;val)){ *p_merge_list = r_list; p_merge_list=&amp;(r_list-&gt;next); r_list = r_list-&gt;next; --r_len; } else{ *p_merge_list = l_list; p_merge_list=&amp;(l_list-&gt;next); l_list = l_list-&gt;next; --l_len; } } l_list=r_list; } *p_merge_list = r_list; } return head; }}; 复杂度分析归并排序，分解子问题的过程是O(logn),合并子问题的过程是O(n); Reference Sort List | 九章算法 [^fast_slow_pointer]: LeetCode: Sort List 解题报告 - Yu’s Garden - 博客园","link":"/2019/10/25/Sort-List/"},{"title":"Validate Binary Search Tree","text":"Question leetcode: Validate Binary Search Tree lintcode: Validate Binary Search Tree Problem Statement Given a binary tree, determine if it is a valid binary search tree (BST). Assume a BST is defined as follows: The left subtree of a node contains only nodes with keys less than the node’s key. The right subtree of a node contains only nodes with keys greater than the node’s key. Both the left and right subtrees must also be binary search trees. A single node tree is a BST Example An example: 2 / \\ 1 4 / \\ 3 5 The above binary tree is serialized as {2,1,4,#,#,3,5} (in level order). 题解1 - recursion按照题中对二叉搜索树所给的定义递归判断，我们从递归的两个步骤出发分析： 基本条件/终止条件 - 返回值需斟酌。 递归步/条件递归 - 能使原始问题收敛。 终止条件好确定——当前节点为空，或者不符合二叉搜索树的定义，返回值分别是什么呢？先别急，分析下递归步试试先。递归步的核心步骤为比较当前节点的key和左右子节点的key大小，和定义不符则返回false, 否则递归处理。从这里可以看出在节点为空时应返回true, 由上层的其他条件判断。但需要注意的是这里不仅要考虑根节点与当前的左右子节点，还需要考虑左子树中父节点的最小值和右子树中父节点的最大值。否则程序在[10,5,15,#,#,6,20] 这种 case 误判。 由于不仅需要考虑当前父节点，还需要考虑父节点的父节点… 故递归时需要引入上界和下界值。画图分析可知对于左子树我们需要比较父节点中最小值，对于右子树则是父节点中的最大值。又由于满足二叉搜索树的定义时，左子结点的值一定小于根节点，右子节点的值一定大于根节点，故无需比较所有父节点的值，使用递推即可得上界与下界，这里的实现非常巧妙。 C++ - long long12345678910111213141516171819202122232425262728293031323334/** * Definition of TreeNode: * class TreeNode { * public: * int val; * TreeNode *left, *right; * TreeNode(int val) { * this-&gt;val = val; * this-&gt;left = this-&gt;right = NULL; * } * } */class Solution {public: /** * @param root: The root of binary tree. * @return: True if the binary tree is BST, or false */ bool isValidBST(TreeNode *root) { if (root == NULL) return true; return helper(root, LLONG_MIN, LLONG_MAX); } bool helper(TreeNode *root, long long lower, long long upper) { if (root == NULL) return true; if (root-&gt;val &lt;= lower || root-&gt;val &gt;= upper) return false; bool isLeftValidBST = helper(root-&gt;left, lower, root-&gt;val); bool isRightValidBST = helper(root-&gt;right, root-&gt;val, upper); return isLeftValidBST &amp;&amp; isRightValidBST; }}; C++ - without long long12345678910111213141516171819202122232425262728293031323334353637383940/** * Definition of TreeNode: * class TreeNode { * public: * int val; * TreeNode *left, *right; * TreeNode(int val) { * this-&gt;val = val; * this-&gt;left = this-&gt;right = NULL; * } * } */class Solution {public: /** * @param root: The root of binary tree. * @return: True if the binary tree is BST, or false */ bool isValidBST(TreeNode *root) { if (root == NULL) return true; return helper(root, INT_MIN, INT_MAX); } bool helper(TreeNode *root, int lower, int upper) { if (root == NULL) return true; if (root-&gt;val &lt;= lower || root-&gt;val &gt;= upper) { bool right_max = root-&gt;val == INT_MAX &amp;&amp; root-&gt;right == NULL; bool left_min = root-&gt;val == INT_MIN &amp;&amp; root-&gt;left == NULL; if (!(right_max || left_min)) { return false; } } bool isLeftValidBST = helper(root-&gt;left, lower, root-&gt;val); bool isRightValidBST = helper(root-&gt;right, root-&gt;val, upper); return isLeftValidBST &amp;&amp; isRightValidBST; }}; Java123456789101112131415161718192021222324252627282930313233/** * Definition of TreeNode: * public class TreeNode { * public int val; * public TreeNode left, right; * public TreeNode(int val) { * this.val = val; * this.left = this.right = null; * } * } */public class Solution { /** * @param root: The root of binary tree. * @return: True if the binary tree is BST, or false */ public boolean isValidBST(TreeNode root) { if (root == null) return true; return helper(root, Long.MIN_VALUE, Long.MAX_VALUE); } private boolean helper(TreeNode root, long lower, long upper) { if (root == null) return true; // System.out.println(&quot;root.val = &quot; + root.val + &quot;, lower = &quot; + lower + &quot;, upper = &quot; + upper); // left node value &lt; root node value &lt; right node value if (root.val &gt;= upper || root.val &lt;= lower) return false; boolean isLeftValidBST = helper(root.left, lower, root.val); boolean isRightValidBST = helper(root.right, root.val, upper); return isLeftValidBST &amp;&amp; isRightValidBST; }} 源码分析为避免节点中出现整型的最大最小值，引入 long 型进行比较。有些 BST 的定义允许左子结点的值与根节点相同，此时需要更改比较条件为root.val &gt; upper. C++ 中 long 可能与 int 范围相同，故使用 long long. 如果不使用比 int 型更大的类型，那么就需要在相等时多加一些判断。 复杂度分析递归遍历所有节点，时间复杂度为 $$O(n)$$, 使用了部分额外空间，空间复杂度为 $$O(1)$$. 题解2 - iteration联想到二叉树的中序遍历。 Java12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */public class Solution { public boolean isValidBST(TreeNode root) { Deque&lt;TreeNode&gt; st = new ArrayDeque&lt;&gt;(); long pre = Long.MIN_VALUE; // inorder traverse while (root != null || !st.isEmpty()) { if (root != null) { st.push(root); root = root.left; } else { root = st.pop(); if (root.val &gt; pre) pre = root.val; else return false; root = root.right; } } return true; }} Reference LeetCode: Validate Binary Search Tree 解题报告 - Yu’s Garden - 博客园 - 提供了4种不同的方法，思路可以参考。","link":"/2019/09/19/Validate-Binary-Search-Tree/"},{"title":"Add Two Numbers","text":"Question leetcode: Add Two Numbers | LeetCode OJ lintcode: Add Two Numbers Problem StatementYou have two numbers represented by a linked list, where each node contains a single digit. The digits are stored in reverse order, such that the 1’s digit is at the head of the list. Write a function that adds the two numbersand returns the sum as a linked list. ExampleGiven 7-&gt;1-&gt;6 + 5-&gt;9-&gt;2. That is, 617 + 295. Return 2-&gt;1-&gt;9. That is 912. Given 3-&gt;1-&gt;5 and 5-&gt;9-&gt;2, return 8-&gt;0-&gt;8. 题解一道看似简单的进位加法题，实则杀机重重，不信你不看答案自己先做做看。 首先由十进制加法可知应该注意进位的处理，但是这道题仅注意到这点就够了吗？还不够！因为两个链表长度有可能不等长！因此这道题的亮点在于边界和异常条件的处理，感谢 @wen 引入的 dummy 节点，处理起来更为优雅！ Python1234567891011121314151617181920212223242526272829# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution: def add_two_numbers(self, l1, l2): ''' :type l1: ListNode :type l2: ListNode :rtype: ListNode ''' carry = 0 dummy = prev = ListNode(-1) while l1 or l2 or carry: v1 = l1.val if l1 else 0 v2 = l2.val if l2 else 0 val = (v1 + v2 + carry) % 10 carry = (v1 + v2 + carry) / 10 prev.next = ListNode(val) prev = prev.next if l1: l1 = l1.next if l2: l2 = l2.next return dummy.next C++123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) {} * }; */class Solution {public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) { ListNode dummy(0); ListNode *curr = &amp;dummy; int carry = 0; while ((l1 != NULL) || (l2 != NULL) || (carry != 0)) { int l1_val = (l1 != NULL) ? l1-&gt;val : 0; int l2_val = (l2 != NULL) ? l2-&gt;val : 0; int sum = carry + l1_val + l2_val; carry = sum / 10; curr-&gt;next = new ListNode(sum % 10); curr = curr-&gt;next; if (l1 != NULL) l1 = l1-&gt;next; if (l2 != NULL) l2 = l2-&gt;next; } return dummy.next; }}; Java123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */public class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode dummy = new ListNode(0); ListNode curr = dummy; int carry = 0; while ((l1 != null) || (l2 != null) || (carry != 0)) { int l1_val = (l1 != null) ? l1.val : 0; int l2_val = (l2 != null) ? l2.val : 0; int sum = carry + l1_val + l2_val; // update carry carry = sum / 10; curr.next = new ListNode(sum % 10); curr = curr.next; if (l1 != null) l1 = l1.next; if (l2 != null) l2 = l2.next; } return dummy.next; }} 源码分析 迭代能正常进行的条件为(NULL != l1) || (NULL != l2) || (0 != carry), 缺一不可。 对于空指针节点的处理可以用相对优雅的方式处理 - int l1_val = (NULL == l1) ? 0 : l1-&gt;val; 生成新节点时需要先判断迭代终止条件 - (NULL == l1) &amp;&amp; (NULL == l2) &amp;&amp; (0 == carry), 避免多生成一位数0。 使用 dummy 节点可避免这一情况。 复杂度分析没啥好分析的，时间和空间复杂度均为 $$O(max(L1, L2))$$. Reference CC150 Chapter 9.2 题2.5，中文版 p123 Add two numbers represented by linked lists | Set 1 - GeeksforGeeks","link":"/2019/03/05/add_two_numbers/"},{"title":"数据类型","text":"&emsp;&emsp;MLlib既支持保存在单台机器上的本地向量和矩阵，也支持备份在一个或多个RDD中的分布式矩阵。本地向量和本地矩阵是简单的数据模型，作为公共接口提供。底层的线性代数操作通过Breeze和jblas提供。在MLlib中，用于有监督学习的训练样本称为标注点(labeled point)。 本地向量(Local vector)&emsp;&emsp;一个本地向量拥有从0开始的integer类型的索引以及double类型的值，它保存在单台机器上面。MLlib支持两种类型的本地向量：稠密(dense)向量和稀疏(sparse)向量。一个稠密向量通过一个double类型的数组保存数据，这个数组表示向量的条目值(entry values)；一个稀疏向量通过两个并行的数组（indices和values）保存数据。例如，一个向量(1.0, 0.0, 3.0)可以以稠密的格式保存为[1.0, 0.0, 3.0] 或者以稀疏的格式保存为(3, [0, 2], [1.0, 3.0])，其中3表示数组的大小。 &emsp;&emsp;本地向量的基类是Vector，Spark提供了两种实现：DenseVector和SparseVector。Spark官方推荐使用Vectors中实现的工厂方法去创建本地向量。下面是创建本地向量的例子。 1234567import org.apache.spark.mllib.linalg.{Vector, Vectors}// 创建一个dense vector (1.0, 0.0, 3.0).val dv: Vector = Vectors.dense(1.0, 0.0, 3.0)// 创建一个sparse vector (1.0, 0.0, 3.0)并且指定它的索引和值val sv1: Vector = Vectors.sparse(3, Array(0, 2), Array(1.0, 3.0))// 创建一个sparse vector (1.0, 0.0, 3.0)并且指定它的索引和值val sv2: Vector = Vectors.sparse(3, Seq((0, 1.0), (2, 3.0))) &emsp;&emsp; 注意，Scala默认引入scala.collection.immutable.Vector，这里我们需要主动引入MLLib中的org.apache.spark.mllib.linalg.Vector来操作。我们可以看看Vectors对象的部分方法。 1234567891011121314151617def dense(firstValue: Double, otherValues: Double*): Vector = new DenseVector((firstValue +: otherValues).toArray)def dense(values: Array[Double]): Vector = new DenseVector(values)def sparse(size: Int, indices: Array[Int], values: Array[Double]): Vector = new SparseVector(size, indices, values)def sparse(size: Int, elements: Seq[(Int, Double)]): Vector = { require(size &gt; 0, &quot;The size of the requested sparse vector must be greater than 0.&quot;) val (indices, values) = elements.sortBy(_._1).unzip var prev = -1 indices.foreach { i =&gt; require(prev &lt; i, s&quot;Found duplicate indices: $i.&quot;) prev = i } require(prev &lt; size, s&quot;You may not write an element to index $prev because the declared &quot; + s&quot;size of your vector is $size&quot;) new SparseVector(size, indices.toArray, values.toArray) } 标注点(Labeled point)&emsp;&emsp;一个标注点就是一个本地向量（或者是稠密的或者是稀疏的），这个向量和一个标签或者响应相关联。在MLlib中，标注点用于有监督学习算法。我们用一个double存储标签，这样我们就可以在回归和分类中使用标注点。对于二分类，一个标签可能是0或者是1；对于多分类，一个标签可能代表从0开始的类别索引。 &emsp;&emsp;在MLlib中，一个标注点通过样本类LabeledPoint表示。 123456789@Since(&quot;0.8.0&quot;)@BeanInfocase class LabeledPoint @Since(&quot;1.0.0&quot;) ( @Since(&quot;0.8.0&quot;) label: Double, @Since(&quot;1.0.0&quot;) features: Vector) { override def toString: String = { s&quot;($label,$features)&quot; }} &emsp;&emsp;下面是使用LabeledPoint的一个例子。 123456import org.apache.spark.mllib.linalg.Vectorsimport org.apache.spark.mllib.regression.LabeledPoint// Create a labeled point with a positive label and a dense feature vector.val pos = LabeledPoint(1.0, Vectors.dense(1.0, 0.0, 3.0))// Create a labeled point with a negative label and a sparse feature vector.val neg = LabeledPoint(0.0, Vectors.sparse(3, Array(0, 2), Array(1.0, 3.0))) &emsp;&emsp;在现实的应用中，训练数据是稀疏的情况非常常见，MLlib支持读取训练数据存储为LIBSVM格式。它是LIBSVM和LIBLINEAR默认的格式。它是一种文本格式，每一行表示一个标注的稀疏特征向量，如下所示： 1label index1:value1 index2:value2 ... 本地矩阵（Local matrix）&emsp;&emsp;一个本地矩阵拥有Integer类型的行和列索引以及Double类型的值。MLlib支持稠密矩阵和稀疏矩阵两种。稠密矩阵将条目(entry)值保存为单个double数组，这个数组根据列的顺序存储。稀疏矩阵的非零条目值保存为压缩稀疏列（Compressed Sparse Column ，CSC）格式，这种格式也是以列顺序存储。例如下面的稠密矩阵： &emsp;&emsp;这个稠密矩阵保存为一维数组[1.0, 3.0, 5.0, 2.0, 4.0, 6.0]，数组大小为(3,2)。 &emsp;&emsp;本地矩阵的基类是Matrix，它提供了两种实现：DenseMatrix和SparseMatrix。推荐使用Matrices的工厂方法来创建本地矩阵。下面是一个实现的例子： 12345import org.apache.spark.mllib.linalg.{Matrix, Matrices}// Create a dense matrix ((1.0, 2.0), (3.0, 4.0), (5.0, 6.0))val dm: Matrix = Matrices.dense(3, 2, Array(1.0, 3.0, 5.0, 2.0, 4.0, 6.0))// Create a sparse matrix ((9.0, 0.0), (0.0, 8.0), (0.0, 6.0))val sm: Matrix = Matrices.sparse(3, 2, Array(0, 1, 3), Array(0, 2, 1), Array(9, 6, 8)) &emsp;&emsp;稠密矩阵的存储很简单，不赘述。稀疏矩阵的存储使用CSC。关于压缩矩阵的介绍，请参看文献【1】。 分布式矩阵(Distributed matrix)&emsp;&emsp;一个分布式矩阵拥有long类型的行和列索引，以及double类型的值，分布式的存储在一个或多个RDD中。选择正确的格式存储大型分布式矩阵是非常重要的。将一个分布式矩阵转换为另外一个格式可能需要一个全局的shuffle，这是非常昂贵的。到目前为止，已经实现了三种类型的分布式矩阵。 &emsp;&emsp;基本的类型是RowMatrix，RowMatrix是一个面向行的分布式矩阵，它没有有意义的行索引。它的行保存为一个RDD,每一行都是一个本地向量。我们假设一个RowMatrix的列的数量不是很巨大，这样单个本地向量可以方便的和driver通信，也可以被单个节点保存和操作。IndexedRowMatrix和RowMatrix很像，但是它拥有行索引，行索引可以用于识别行和进行join操作。CoordinateMatrix是一个分布式矩阵，它使用COO格式存储。请参看文献【1】了解COO格式。 RowMatrix&emsp;&emsp;RowMatrix是一个面向行的分布式矩阵，它没有有意义的行索引。它的行保存为一个RDD,每一行都是一个本地向量。因为每一行保存为一个本地向量，所以列数限制在了整数范围。 &emsp;&emsp;一个RowMatrix可以通过RDD[Vector]实例创建。创建完之后，我们可以计算它的列的统计和分解。QR分解的形式为A=QR，其中Q是一个正交矩阵，R是一个上三角矩阵。下面是一个RowMatrix的例子。 12345678910import org.apache.spark.mllib.linalg.Vectorimport org.apache.spark.mllib.linalg.distributed.RowMatrixval rows: RDD[Vector] = ... // an RDD of local vectors// Create a RowMatrix from an RDD[Vector].val mat: RowMatrix = new RowMatrix(rows)// Get its size.val m = mat.numRows()val n = mat.numCols()// QR decomposition val qrResult = mat.tallSkinnyQR(true) IndexedRowMatrix&emsp;&emsp;IndexedRowMatrix和RowMatrix很像，但是它拥有行索引。索引的行保存为一个RDD[IndexedRow]，其中IndexedRow是一个参数为(Long, Vector)的样本类，所以每一行通过它的索引以及一个本地向量表示。 &emsp;&emsp;一个IndexedRowMatrix可以通过RDD[IndexedRow]实例创建，并且一个IndexedRowMatrix可以通过去掉它的行索引，转换成RowMatrix。下面是一个例子： 123456789import org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix, RowMatrix}val rows: RDD[IndexedRow] = ... // an RDD of indexed rows// Create an IndexedRowMatrix from an RDD[IndexedRow].val mat: IndexedRowMatrix = new IndexedRowMatrix(rows)// Get its size.val m = mat.numRows()val n = mat.numCols()// Drop its row indices.val rowMat: RowMatrix = mat.toRowMatrix() &emsp;&emsp; IndexedRow这个样本类的代码如下： 1case class IndexedRow(index: Long, vector: Vector) CoordinateMatrix&emsp;&emsp;CoordinateMatrix是一个分布式矩阵，它的条目保存为一个RDD。每一个条目是一个(i: Long, j: Long, value: Double)格式的元组，其中i表示行索引，j表示列索引，value表示条目值。CoordinateMatrix应该仅仅在矩阵维度很大并且矩阵非常稀疏的情况下使用。 &emsp;&emsp;CoordinateMatrix可以通过RDD[MatrixEntry]实例创建，其中MatrixEntry是(Long, Long, Double)的包装。CoordinateMatrix可以转换成IndexedRowMatrix。下面是一个例子： 123456789import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}val entries: RDD[MatrixEntry] = ... // an RDD of matrix entries// Create a CoordinateMatrix from an RDD[MatrixEntry].val mat: CoordinateMatrix = new CoordinateMatrix(entries)// Get its size.val m = mat.numRows()val n = mat.numCols()// Convert it to an IndexRowMatrix whose rows are sparse vectors.val indexedRowMatrix = mat.toIndexedRowMatrix() &emsp;&emsp; MatrixEntry这个样本类的代码如下： 1case class MatrixEntry(i: Long, j: Long, value: Double) BlockMatrix&emsp;&emsp;BlockMatrix是一个分布式矩阵，它的保存为一个MatrixBlocks的RDD。MatrixBlock是一个((Int, Int), Matrix)类型的元组，其中(Int, Int)代表块的索引，Matrix代表子矩阵。BlockMatrix支持诸如add和multiply等方法。BlockMatrix还有一个帮助方法validate，用来判断一个BlockMatrix是否正确的创建。 &emsp;&emsp;可以轻松的通过调用toBlockMatrix从一个IndexedRowMatrix或者CoordinateMatrix创建一个BlockMatrix。toBlockMatrix默认创建1024 * 1024大小的块，用户可以手动修个块的大小。下面是一个例子： 1234567891011import org.apache.spark.mllib.linalg.distributed.{BlockMatrix, CoordinateMatrix, MatrixEntry}val entries: RDD[MatrixEntry] = ... // an RDD of (i, j, v) matrix entries// Create a CoordinateMatrix from an RDD[MatrixEntry].val coordMat: CoordinateMatrix = new CoordinateMatrix(entries)// Transform the CoordinateMatrix to a BlockMatrixval matA: BlockMatrix = coordMat.toBlockMatrix().cache()// Validate whether the BlockMatrix is set up properly. Throws an Exception when it is not valid.// Nothing happens if it is valid.matA.validate()// Calculate A^T A.val ata = matA.transpose.multiply(matA) 参考文献【1】稀疏矩阵存储格式总结+存储效率对比:COO,CSR,DIA,ELL,HYB","link":"/2019/08/05/data-type/"},{"title":"递归和动态规划","text":"动态规划可以理解为是查表的递归。那么什么是递归？ 递归定义： 递归算法是一种直接或者间接调用自身函数或者方法的算法。 算法中使用递归可以很简单地完成一些用循环实现的功能，比如二叉树的左中右序遍历。递归在算法中有非常广泛的使用，包括现在日趋流行的函数式编程。 纯粹的函数式编程中没有循环，只有递归。 接下来我们来讲解以下递归。通俗来说，递归算法的实质是把问题分解成规模缩小的同类问题的子问题，然后递归调用方法来表示问题的解 递归的三个要素 一个问题的解可以分解为几个子问题的解 子问题的求解思路除了规模之外，没有任何区别 有递归终止条件 我这里列举了几道算法题目，这几道算法题目都可以用递归轻松写出来： 递归实现 sum 二叉树的遍历 走楼梯问题 汉诺塔问题 动态规划如果说递归是从问题的结果倒推，直到问题的规模缩小到寻常。 那么动态规划就是从寻常入手， 逐步扩大规模到最优子结构。 这句话需要一定的时间来消化,如果不理解，可以过一段时间再来看。 递归的解决问题非常符合人的直觉，代码写起来比较简单。但是我们通过分析（可以尝试画一个递归树），可以看出递归在缩小问题规模的同时可能会重复计算。 279.perfect-squares 中 我通过递归的方式来解决这个问题，同时内部维护了一个缓存来存储计算过的运算，那么我们可以减少很多运算。 这其实和动态规划有着异曲同工的地方。 我们结合求和问题来讲解一下, 题目是给定一个数组，求出数组中所有项的和，要求使用递归实现。 代码： 123456function sum(nums) { if (nums.length === 0) return 0; if (nums.length === 1) return nums[0]; return nums[0] + sum(nums.slice(1));} 我们用递归树来直观地看一下。 这种做法本身没有问题，但是每次执行一个函数都有一定的开销，拿 JS 引擎执行 JS 来说，每次函数执行都会进行入栈操作，并进行预处理和执行过程，所以对于内存来说是一个挑战。很容易造成爆栈。 浏览器中的 JS 引擎对于代码执行栈的长度是有限制的，超过会爆栈，抛出异常。 我们再举一个更加明显的例子，问题描述： 一个人爬楼梯，每次只能爬 1 个或 2 个台阶，假设有 n 个台阶，那么这个人有多少种不同的爬楼梯方法？ 代码： 12345function climbStairs(n) { if (n === 1) return 1; if (n === 2) return 2; return climbStairs(n - 1) + climbStairs(n - 2);} 这道题和 fibnacci 数列一摸一样，我们继续用一个递归树来直观感受以下： 可以看出这里面有很多重复计算，我们可以使用一个 hashtable 去缓存中间计算结果，从而省去不必要的计算。那么动态规划是怎么解决这个问题呢？ 答案就是“查表”。 刚才我们说了递归是从问题的结果倒推，直到问题的规模缩小到寻常。 动态规划是从寻常入手， 逐步扩大规模到最优子结构。 从刚才的两个例子，我想大家可能对前半句话有了一定的理解，我们接下来讲解下后半句。 如果爬楼梯的问题，使用动态规划，代码是这样的： 12345678910111213141516function climbStairs(n) { if (n === 1) return 1; if (n === 2) return 2; let a = 1; let b = 2; let temp; for (let i = 3; i &lt;= n; i++) { temp = a + b; a = b; b = temp; } return temp;} 动态规划的查表过程如果画成图，就是这样的： 虚线代表的是查表过程 这道题目是动态规划中最简单的问题了，因为设计到单个因素的变化，如果涉及到多个因素，就比较复杂了，比如著名的背包问题，挖金矿问题等。 对于单个因素的，我们最多只需要一个一维数组即可，对于如背包问题我们需要二维数组等更高纬度。 爬楼梯我们并没有使用一维数组，而是借助两个变量来实现的，空间复杂度是 O(1).之所以能这么做，是因为爬楼梯问题的状态转移方程只和前两个有关，因此只需要存储这两个即可。 动态规划问题有时候有很多这种讨巧的方式，但并不是所有的动态规划都可以这么讨巧，比如背包问题。 动态规划的两个要素 状态转移方程 临界条件 在上面讲解的爬楼梯问题中 123f(1) 与 f(2) 就是【边界】f(n) = f(n-1) + f(n-2) 就是【状态转移公式】 动态规划为什么要画表格动态规划问题要画表格，但是有的人不知道为什么要画，就觉得这个是必然的，必要要画表格才是动态规划。 其实动态规划本质上是将大问题转化为小问题，然后大问题的解是和小问题有关联的，换句话说大问题可以由小问题进行计算得到。 这一点是和递归一样的， 但是动态规划是一种类似查表的方法来缩短时间复杂度和空间复杂度。 画表格的目的就是去不断推导，完成状态转移， 表格中的每一个cell都是一个小问题， 我们填表的过程其实就是在解决问题的过程，我们先解决规模为寻常的情况，然后根据这个结果逐步推导，通常情况下，表格的右下角是问题的最大的规模，也就是我们想要求解的规模。 比如我们用动态规划解决背包问题， 其实就是在不断根据之前的小问题A[i - 1][j] A[i -1][w - wj]来询问： 我是应该选择它 还是不选择它 至于判断的标准很简单，就是价值最大，因此我们要做的就是对于选择和不选择两种情况分别求价值，然后取最大，最后更新cell即可。 相关问题 0091.decode-ways 0139.word-break 0198.house-robber 0309.best-time-to-buy-and-sell-stock-with-cooldown 0322.coin-change 0416.partition-equal-subset-sum 0518.coin-change-2 太多了，没有逐一列举 总结本篇文章总结了算法中比较常用的两个方法 - 递归和动态规划。 如果你只能借助一句话，那么请记住：递归是从问题的结果倒推，直到问题的规模缩小到寻常。 动态规划是从寻常入手， 逐步扩大规模到最优子结构。","link":"/2017/05/09/dynamic-programming/"},{"title":"Balanced Binary Tree","text":"Question leetcode: Balanced Binary Tree | LeetCode OJ lintcode: (93) Balanced Binary Tree Problem StatementGiven a binary tree, determine if it is height-balanced. For this problem, a height-balanced binary tree is defined as a binary tree in which the depth of the two subtrees of every node never differ by more than 1. ExampleGiven binary tree A={3,9,20,#,#,15,7}, B={3,#,20,15,7} 12345A) 3 B) 3 / \\ \\ 9 20 20 / \\ / \\ 15 7 15 7 The binary tree A is a height-balanced binary tree, but B is not. 题解1 - 递归根据题意，平衡树的定义是两子树的深度差最大不超过1，显然使用递归进行分析较为方便。既然使用递归，那么接下来就需要分析递归调用的终止条件。和之前的 Maximum Depth of Binary Tree | Algorithm 类似，NULL == root必然是其中一个终止条件，返回0；根据题意还需的另一终止条件应为「左右子树高度差大于1」，但对应此终止条件的返回值是多少？——INT_MAX or INT_MIN？想想都不合适，为何不在传入参数中传入bool指针或者bool引用咧？并以此变量作为最终返回值，此法看似可行，先来看看鄙人最开始想到的这种方法。 C++ Recursion with extra bool variable12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Definition of TreeNode: * class TreeNode { * public: * int val; * TreeNode *left, *right; * TreeNode(int val) { * this-&gt;val = val; * this-&gt;left = this-&gt;right = NULL; * } * } */class Solution {public: /** * @param root: The root of binary tree. * @return: True if this Binary tree is Balanced, or false. */ bool isBalanced(TreeNode *root) { if (NULL == root) { return true; } bool result = true; maxDepth(root, result); return result; }private: int maxDepth(TreeNode *root, bool &amp;isBalanced) { if (NULL == root) { return 0; } int leftDepth = maxDepth(root-&gt;left, isBalanced); int rightDepth = maxDepth(root-&gt;right, isBalanced); if (abs(leftDepth - rightDepth) &gt; 1) { isBalanced = false; // speed up the recursion process return INT_MAX; } return max(leftDepth, rightDepth) + 1; }}; 源码解析如果在某一次子树高度差大于1时，返回INT_MAX以减少不必要的计算过程，加速整个递归调用的过程。 初看起来上述代码好像还不错的样子，但是在看了九章的实现后，瞬间觉得自己弱爆了… 首先可以确定abs(leftDepth - rightDepth) &gt; 1肯定是需要特殊处理的，如果返回-1呢？咋一看似乎在下一步返回max(leftDepth, rightDepth) + 1时会出错，再进一步想想，我们能否不让max...这一句执行呢？如果返回了-1，其接盘侠必然是leftDepth或者rightDepth中的一个，因此我们只需要在判断子树高度差大于1的同时也判断下左右子树深度是否为-1即可都返回-1，不得不说这种处理方法要精妙的多，赞！ C++123456789101112131415161718192021222324252627282930313233343536373839/** * forked from http://www.jiuzhang.com/solutions/balanced-binary-tree/ * Definition of TreeNode: * class TreeNode { * public: * int val; * TreeNode *left, *right; * TreeNode(int val) { * this-&gt;val = val; * this-&gt;left = this-&gt;right = NULL; * } * } */class Solution {public: /** * @param root: The root of binary tree. * @return: True if this Binary tree is Balanced, or false. */ bool isBalanced(TreeNode *root) { return (-1 != maxDepth(root)); }private: int maxDepth(TreeNode *root) { if (NULL == root) { return 0; } int leftDepth = maxDepth(root-&gt;left); int rightDepth = maxDepth(root-&gt;right); if (leftDepth == -1 || rightDepth == -1 || \\ abs(leftDepth - rightDepth) &gt; 1) { return -1; } return max(leftDepth, rightDepth) + 1; }}; Java12345678910111213141516171819202122232425262728/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */public class Solution { public boolean isBalanced(TreeNode root) { return maxDepth(root) != -1; } private int maxDepth(TreeNode root) { if (root == null) return 0; int leftDepth = maxDepth(root.left); int rightDepth = maxDepth(root.right); if (leftDepth == -1 || rightDepth == -1 || Math.abs(leftDepth - rightDepth) &gt; 1) { return -1; } return 1 + Math.max(leftDepth, rightDepth); }} 源码分析抓住两个核心：子树的高度以及高度之差，返回值应该包含这两种信息。 复杂度分析遍历所有节点各一次，时间复杂度为 $$O(n)$$, 使用了部分辅助变量，空间复杂度 $$O(1)$$.","link":"/2019/03/03/balanced_binary_tree/"},{"title":"Find Minimum in Rotated Sorted Array II","text":"Question leetcode: Find Minimum in Rotated Sorted Array II | LeetCode OJ lintcode: (160) Find Minimum in Rotated Sorted Array II Problem StatementSuppose a sorted array is rotated at some pivot unknown to you beforehand. (i.e., 0 1 2 4 5 6 7 might become 4 5 6 7 0 1 2). Find the minimum element. The array may contain duplicates. ExampleGiven [4,4,5,6,7,0,1,2] return 0 题解由于此题输入可能有重复元素，因此在num[mid] == num[end]时无法使用二分的方法缩小start或者end的取值范围。此时只能使用递增start/递减end逐步缩小范围。 C++1234567891011121314151617181920212223242526272829303132class Solution {public: /** * @param num: a rotated sorted array * @return: the minimum number in the array */ int findMin(vector&lt;int&gt; &amp;num) { if (num.empty()) { return -1; } vector&lt;int&gt;::size_type start = 0; vector&lt;int&gt;::size_type end = num.size() - 1; vector&lt;int&gt;::size_type mid; while (start + 1 &lt; end) { mid = start + (end - start) / 2; if (num[mid] &gt; num[end]) { start = mid; } else if (num[mid] &lt; num[end]) { end = mid; } else { --end; } } if (num[start] &lt; num[end]) { return num[start]; } else { return num[end]; } }}; Java123456789101112131415161718192021222324252627public class Solution { /** * @param num: a rotated sorted array * @return: the minimum number in the array */ public int findMin(int[] num) { if (num == null || num.length == 0) return Integer.MIN_VALUE; int lb = 0, ub = num.length - 1; // case1: num[0] &lt; num[num.length - 1] // if (num[lb] &lt; num[ub]) return num[lb]; // case2: num[0] &gt; num[num.length - 1] or num[0] &lt; num[num.length - 1] while (lb + 1 &lt; ub) { int mid = lb + (ub - lb) / 2; if (num[mid] &lt; num[ub]) { ub = mid; } else if (num[mid] &gt; num[ub]){ lb = mid; } else { ub--; } } return Math.min(num[lb], num[ub]); }} 源码分析注意num[mid] &gt; num[ub]时应递减 ub 或者递增 lb. 复杂度分析最坏情况下 $$O(n)$$, 平均情况下 $$O(\\log n)$$.","link":"/2019/03/01/find_minimum_in_rotated_sorted_array_ii/"},{"title":"Git 与 GitHub 入门实践","text":"git配置优先级：--local &gt; --global &gt; --system 用了--global这个参数，表示你这台机器上所有的Git仓库都会使用这个配置 配置git用户名和邮箱1234git config --global user.name # 查看git config --global user.name 用户名 # 修改git config --global user.email # 查看git config --global user.email 邮箱 # 修改 仓库创建git仓库12git init 仓库名 #创建一个git仓库git init #将一个项目转化为使用git管理（创建.git目录） 示例： 目录结构： 12345678910project |------.git |--------branches |--------config #仓库的配置文件 |--------description |--------HEAD |--------hooks |--------info |--------objects |--------refs 隐藏目录.git不算工作区，而是Git的版本库 查看仓库状态1git status 远程仓库 最早，肯定只有一台机器有一个原始版本库，此后，别的机器可以“克隆”这个原始版本库，而且每台机器的版本库其实都是一样的，并没有主次之分 实际情况往往是这样，找一台电脑充当服务器的角色，每天24小时开机，其他每个人都从这个“服务器”仓库克隆一份到自己的电脑上，并且各自把各自的提交推送到服务器仓库里，也从服务器仓库中拉取别人的提交 GitHub就是提供Git仓库托管服务的，所以，只要注册一个GitHub账号，就可以免费获得Git远程仓库，即Github为我们的git仓库提供了一个远程仓库，有了这个远程仓库，妈妈再也不用担心我的硬盘了 为本地与GitHub的通信配置ssh本地git仓库和GitHub上的远程仓库之间的传输是通过SSH加密的，所以，需要一点设置： 创建ssh key： 1ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 登录你的GitHub帐号，Settings -&gt; SSH and GPG keys -&gt; new SSH key ，将id_rsa.pub的内容复制进去 为什么GitHub需要SSH Key呢？因为GitHub需要识别出你推送的提交确实是你推送的，而不是别人冒充的，而Git支持SSH协议，所以，GitHub只要知道了你的公钥，就可以确认只有你自己才能推送 让本地git仓库和远程仓库同步 在有了本地git仓库后，还需创建对应的远程仓库 在GitHub上创建远程仓库（如果已有则省略） 为本地仓库设置远程仓库信息（如果同时需要为本地仓库添加多个远程仓库（如果github+码云），则可以将origin分别换成github和gitee，推送操作时也要修改origin。添加后，远程库的名字就是origin，这是Git默认的叫法，也可以改成别的，但是origin这个名字一看就知道是远程库） 1git remote add origin https://github.com/用户名/仓库名 删除本地仓库的远程仓库信息：git remote remove origin 修改远端地址：git remote set-url 新地址 查看远程仓库信息：git remote -v 将本地git仓库push到远程仓库 1234# 由于远程库是空的，我们第一次推送master分支时，加上了-u参数,Git不但会把本地的# master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master# 分支关联起来，在以后的推送或者拉取时就可以简化命令git push [-u] origin 分支名 并不是一定要把本地分支往远程推送。哪些分支需要推送、哪些不需要呢？ master：主分支，要时刻与远程同步 dev：开发分支，团队所有成员都需要在上面工作，所有也需要与远程同步 bug：只用于在本地修复bug，就没必要推送到远程了，除非老板要看看你每周修复了几个bug 协同工作拉取分支： 1git pull git clone时，默认情况下只能看到本地的master分支。如果要在dev分支上开发，就必须创建远程origin的dev分支到本地，可以使用如下命令创建本地dev分支： 1git checkout -b dev 将本地dev分支与远程origin/dev分支关联起来： 1git branch --set-upstream dev origin/dev 使用GitHubBootstrap的官方仓库twbs/bootstrap、你在GitHub上克隆的仓库my/bootstrap，以及你自己克隆到本地电脑的仓库，他们的关系就像下图显示的那样： 如果你想修复bootstrap的一个bug，或者新增一个功能，立刻就可以开始干活，干完后，往自己的仓库推送 如果你希望bootstrap的官方库能接受你的修改，你就可以在GitHub上发起一个pull request。当然，对方是否接受你的pull request就不一定了 版本控制隐藏目录.git不算工作区，而是Git的版本库。版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区。还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD 添加或删除修改将修改添加到暂存区： 1git add 文件/目录 从暂存区删除修改： 1git rm --cached 文件/目录 以下命令可以将暂存区的修改重置，暂存区的改变会被移除到工作区： 1git reset HEAD [文件名] 以下命令可以丢弃工作区的修改： 1git checkout -- [文件名] 如果刚对一个文件进行了编辑，可以撤销文件的改变，回到编辑开始。命令其实起到“一键恢复”的作用，还可用于“误删恢复”。可以在 git reset HEAD [文件名] 后使用 提交版本如果修改了readme.txt，添加了文件LICENSE，并将2者添加到暂存区后，暂存区的状态就变成这样： 使用commit提交修改，实际上就是把暂存区的所有内容提交到当前分支： 1git commit -m '信息' commit相当于游戏里面一次存档。对应一个版本 文件删除rm做出的删除不会被暂存，git rm做出的改变会被暂存。如果使用rm删除掉，能使用git rm来暂存。git rm不在意文件已经不存在了 删除(暂存)单个文件 1git rm 删除(暂存)多个文件（一般情况下，更可能是对大量文件进行管理。可能同时会删除很多文件，不可能使用git rm一个个删除） 12# 它会变量当前目录，将所有删除暂存git add -u . 如果有文件被误删，可以使用git checkout -- 文件名恢复 工作现场保存与恢复有时候在修复bug或某项任务还未完成，但是需要紧急处理另外一个问题。此时可以先保存工作现场，当问题处理完成后，再恢复bug或任务的进度 保存工作现场：git stash 查看保存的工作现场：git stash list 恢复工作现场：git stash apply 删除stash内容：git stash drop 恢复工作现场并删除stash内容（相当于上面2步合并）：git stash pop 改动查询1234567git diff [选项] # 查看工作区中的修改git diff [选项] --staged # 查看已添加到暂存区的修改git diff [选项] HEAD # 查看当前所有未提交的修改选项： --color-words： 颜色 --stat： 不显示具体修改，只显示修改了的文件 版本回退123456git reset --hard 版本ID/HEAD形式的版本git reset --hard HEAD # 当前版本git reset --hard HEAD^ # 上一个版本git reset --hard HEAD^^ # 上上个版本git reset --hard HEAD~n # 前n个版本 如果回到过去的版本，想要回到原来新的版本： 如果终端未关，可以找到新版本的id，通过上述命令回去新版本 如果终端已关，git reflog查看版本，再通过上述命令回去新版本 查看历史提交1234567git log [选项]选项： --online：只显示提交提示信息 --stat：添加每次提交包含的文件信息 --path：查看每次提交改变的内容 --graph 加文件名可以显示具体文件相关的所有提交信息 分支管理创建与合并分支每次commit相当于一次存档，对应一个版本。Git都把它们串成一条时间线，这条时间线就是一个分支。master就是主分支。HEAD指向当前分支，而master指向主分支的最近提交。每次提交，master分支都会向前移动一步 当创建一个分支时，如dev，Git创建一个指针dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： 从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： 合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 上面的合并使用的是Fast forward。这种模式下，删除分支后，会丢掉分支信息。如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的提交，这样，从分支历史上就可以看出分支信息。通过在git merge命令中使用--no-ff选项禁用Fast forward模式。比如在合并dev时： 1git merge --no-ff -m &quot;merge with no-ff&quot; dev 由于会生成一个新的提交，所以需要使用-m指明新提交的信息。此时分支情况如下： 相关命令如下： (创建分支并)切换到新分支：git checkout -b 新分支 创建分支：git branch 新分支 切换分支：git checkout 欲切换到的分支 查看当前分支：git branch 合并某分支到当前分支：git merge 欲合并到当前分支的分支 查看历史分支情况：git log --graph --pretty=oneline --abbrev-commit 删除未合并的分支：git branch -D 分支 分支合并冲突如果两个分支修改了同一文件，合并时会发生冲突。比如master分支和feature1分支都修改了readme.txt文件，各自都有新的提交： 这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突。此时readme.txt文件会变成如下形式： 123456789Git is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，此时需要手动修改后保存。然后再使用git commit进行一次提交。分支会变成如下： 分支管理策略在实际开发中，我们应该按照几个基本原则进行分支管理 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活 干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了 所以，团队合作的分支看起来就像这样： 当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin 要查看远程库的信息，用git remote： 12$ git remoteorigin 或者，用git remote -v显示更详细的信息： 123$ git remote -vorigin git@github.com:michaelliao/learngit.git (fetch)origin git@github.com:michaelliao/learngit.git (push) 上面显示了可以抓取和推送的origin的地址。如果没有推送权限，就看不到push的地址 推送分支1git push origin 欲推送的分支 master分支是主分支，因此要时刻与远程同步 dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步 bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发","link":"/2015/02/28/git/"},{"title":"Permutation Sequence","text":"Question leetcode: Permutation Sequence | LeetCode OJ lintcode: (388) Permutation Sequence Problem StatementGiven n and k, return the k-th permutation sequence. ExampleFor n = 3, all permutations are listed as follows: &quot;123&quot; &quot;132&quot; &quot;213&quot; &quot;231&quot; &quot;312&quot; &quot;321&quot; If k = 4, the fourth permutation is &quot;231&quot; Noten will be between 1 and 9 inclusive. ChallengeO(n*k) in time complexity is easy, can you do it in O(n^2) or less? 题解和题 Permutation Index 正好相反，这里给定第几个排列的相对排名，输出排列值。和不同进制之间的转化类似，这里的『进制』为1!, 2!..., 以n=3, k=4为例，我们从高位到低位转化，直觉应该是用 k/(n-1)!, 但以 n=3,k=5 和 n=3,k=6 代入计算后发现边界处理起来不太方便，故我们可以尝试将 k 减1进行运算，后面的基准也随之变化。第一个数可以通过(k-1)/(n-1)!进行计算，那么第二个数呢？联想不同进制数之间的转化，我们可以通过求模运算求得下一个数的k-1, 那么下一个数可通过(k2 - 1)/(n-2)!求得，这里不理解的可以通过进制转换类比进行理解。和减掉相应的阶乘值是等价的。 Python12345678910111213141516171819202122class Solution: &quot;&quot;&quot; @param n: n @param k: the k-th permutation @return: a string, the k-th permutation &quot;&quot;&quot; def getPermutation(self, n, k): # generate factorial list factorial = [1] for i in xrange(1, n + 1): factorial.append(factorial[-1] * i) nums = range(1, n + 1) perm = [] for i in xrange(n): rank = (k - 1) / factorial[n - i - 1] k = (k - 1) % factorial[n - i - 1] + 1 # append and remove nums[rank] perm.append(nums[rank]) nums.remove(nums[rank]) # combine digits return &quot;&quot;.join([str(digit) for digit in perm]) C++12345678910111213141516171819202122232425262728293031323334class Solution {public: /** * @param n: n * @param k: the kth permutation * @return: return the k-th permutation */ string getPermutation(int n, int k) { // generate factorial list vector&lt;int&gt; factorial = vector&lt;int&gt;(n + 1, 1); for (int i = 1; i &lt; n + 1; ++i) { factorial[i] = factorial[i - 1] * i; } // generate digits ranging from 1 to n vector&lt;int&gt; nums; for (int i = 1; i &lt; n + 1; ++i) { nums.push_back(i); } vector&lt;int&gt; perm; for (int i = 0; i &lt; n; ++i) { int rank = (k - 1) / factorial[n - i - 1]; k = (k - 1) % factorial[n - i - 1] + 1; // append and remove nums[rank] perm.push_back(nums[rank]); nums.erase(std::remove(nums.begin(), nums.end(), nums[rank]), nums.end()); } // transform a vector&lt;int&gt; to a string std::stringstream result; std::copy(perm.begin(), perm.end(), std::ostream_iterator&lt;int&gt;(result, &quot;&quot;)); return result.str(); }}; Java1234567891011121314151617181920212223242526272829303132class Solution { /** * @param n: n * @param k: the kth permutation * @return: return the k-th permutation */ public String getPermutation(int n, int k) { if (n &lt;= 0 &amp;&amp; k &lt;= 0) return &quot;&quot;; int fact = 1; // generate nums 1 to n List&lt;Integer&gt; nums = new ArrayList&lt;Integer&gt;(); for (int i = 1; i &lt;= n; i++) { fact *= i; nums.add(i); } // get the permutation digit StringBuilder sb = new StringBuilder(); for (int i = n; i &gt;= 1; i--) { fact /= i; // take care of rank and k int rank = (k - 1) / fact; k = (k - 1) % fact + 1; // ajust the mapping of rank to num sb.append(nums.get(rank)); nums.remove(rank); } return sb.toString(); }} 源码分析源码结构分为三步走， 建阶乘数组 生成排列数字数组 从高位到低位计算排列数值 复杂度分析几个 for 循环，时间复杂度为 $$O(n)$$, 用了与 n 等长的一些数组，空间复杂度为 $$O(n)$$. Reference Permutation Sequence 解题报告 Permutation Sequence 参考程序 Java/C++/Python c++ - How to transform a vector into a string? - Stack Overflow","link":"/2019/04/30/permutation_sequence/"},{"title":"流式&#96;k-means&#96;算法","text":"&emsp;&emsp;当数据是以流的方式到达的时候，我们可能想动态的估计（estimate ）聚类的簇，通过新的到达的数据来更新聚类。spark.mllib支持流式k-means聚类，并且可以通过参数控制估计衰减（decay）(或“健忘”(forgetfulness))。这个算法使用一般地小批量更新规则来更新簇。 流式k-means算法原理&emsp;&emsp;对每批新到的数据，我们首先将点分配给距离它们最近的簇，然后计算新的数据中心，最后更新每一个簇。使用的公式如下所示： &emsp;&emsp;在上面的公式中，$c_{t}$表示前一个簇中心，$n_{t}$表示分配给这个簇的点的数量，$x_{t}$表示从当前批数据的簇中心，$m_{t}$表示当前批数据的点数量。当评价新的数据时，把衰减因子alpha当做折扣加权应用到当前的点上，用以衡量当前预测的簇的贡献度量。当alpha等于1时，所有的批数据赋予相同的权重，当alpha等于0时，数据中心点完全通过当前数据确定。 &emsp;&emsp;衰减因子alpha也可以通过halfLife参数联合时间单元（time unit）来确定，时间单元可以是一批数据也可以是一个数据点。假如数据从t时刻到来并定义了halfLife为h，在t+h时刻，应用到t时刻的数据的折扣（discount）为0.5。 &emsp;&emsp;流式k-means算法的步骤如下所示： （1）分配新的数据点到离其最近的簇； （2）根据时间单元（time unit）计算折扣（discount）值，并更新簇权重； （3）应用更新规则； （4）应用更新规则后，有些簇可能消失了，那么切分最大的簇为两个簇。 流式k-means算法源码分析&emsp;&emsp;在分步骤分析源码之前，我们先了解一下StreamingKMeans参数表达的含义。 12345class StreamingKMeans( var k: Int, //簇个数 var decayFactor: Double,//衰减因子 var timeUnit: String //时间单元) &emsp;&emsp;在上述定义中，k表示我们要聚类的个数，decayFactor表示衰减因子，用于计算折扣，timeUnit表示时间单元，时间单元既可以是一批数据（StreamingKMeans.BATCHES）也可以是单条数据（StreamingKMeans.POINTS）。 &emsp;&emsp;由于我们处理的是流式数据，所以我们在流式数据来之前要先初始化模型。有两种初始化模型的方法，一种是直接指定初始化中心点及簇权重，一种是随机初始化中心点以及簇权重。 12345678910111213//直接初始化中心点及簇权重def setInitialCenters(centers: Array[Vector], weights: Array[Double]): this.type = { model = new StreamingKMeansModel(centers, weights) this}//随机初始化中心点以及簇权重def setRandomCenters(dim: Int, weight: Double, seed: Long = Utils.random.nextLong): this.type = { val random = new XORShiftRandom(seed) val centers = Array.fill(k)(Vectors.dense(Array.fill(dim)(random.nextGaussian()))) val weights = Array.fill(k)(weight) model = new StreamingKMeansModel(centers, weights) this} &emsp;&emsp;初始化中心点以及簇权重之后，对于新到的流数据，我们使用更新规则修改中心点和权重，调整聚类情况。更新过程在update方法中实现，下面我们分步骤分析该方法。 （1）分配新到的数据到离其最近的簇，并计算更新后的簇的向量和以及点数量 123456789101112131415//选择离数据点最近的簇val closest = data.map(point =&gt; (this.predict(point), (point, 1L)))def predict(point: Vector): Int = { //返回和给定点相隔最近的中心 KMeans.findClosest(clusterCentersWithNorm, new VectorWithNorm(point))._1}// 获得更新的簇的向量和以及点数量val mergeContribs: ((Vector, Long), (Vector, Long)) =&gt; (Vector, Long) = (p1, p2) =&gt; { // y += a * x,向量相加 BLAS.axpy(1.0, p2._1, p1._1) (p1._1, p1._2 + p2._2)}val pointStats: Array[(Int, (Vector, Long))] = closest .aggregateByKey((Vectors.zeros(dim), 0L))(mergeContribs, mergeContribs) .collect() （2）获取折扣值，并用折扣值作用到权重上 1234567891011121314// 折扣val discount = timeUnit match { case StreamingKMeans.BATCHES =&gt; decayFactor case StreamingKMeans.POINTS =&gt; //所有新增点的数量和 val numNewPoints = pointStats.view.map { case (_, (_, n)) =&gt; n }.sum // x^y math.pow(decayFactor, numNewPoints)}//将折扣应用到权重上//x = a * xBLAS.scal(discount, Vectors.dense(clusterWeights)) &emsp;&emsp;上面的代码更加时间单元的不同获得不同的折扣值。当时间单元为StreamingKMeans.BATCHES时，折扣就为衰减因子；当时间单元为StreamingKMeans.POINTS时，折扣由新增数据点的个数n和衰减因子decay共同决定。折扣值为n个decay相乘。 （3）实现更新规则 12345678910111213// 实现更新规则pointStats.foreach { case (label, (sum, count)) =&gt; //获取中心点 val centroid = clusterCenters(label) //更新权重 val updatedWeight = clusterWeights(label) + count val lambda = count / math.max(updatedWeight, 1e-16) clusterWeights(label) = updatedWeight //x = a * x,即（1-lambda）*centroid BLAS.scal(1.0 - lambda, centroid) // y += a * x，即centroid +=sum*lambda/count BLAS.axpy(lambda / count, sum, centroid)} &emsp;&emsp;上面的代码对每一个簇，首先更新簇的权重，权重值为原有的权重加上新增数据点的个数。然后计算lambda，通过lambda更新中心点。lambda为新增数据的个数和更新权重的商。假设更新之前的中心点为c1，更新之后的中心点为c2，那么c2=(1-lambda)*c1+sum/count，其中sum/count为所有点的平均值。 （4）调整权重最小和最大的簇 12345678910111213141516171819202122val weightsWithIndex = clusterWeights.view.zipWithIndex//获取权重值最大的簇val (maxWeight, largest) = weightsWithIndex.maxBy(_._1)//获取权重值最小的簇val (minWeight, smallest) = weightsWithIndex.minBy(_._1)//判断权重最小的簇是否过小，如果过小，就将这两个簇重新划分为两个新的簇，权重为两者的均值if (minWeight &lt; 1e-8 * maxWeight) { logInfo(s&quot;Cluster $smallest is dying. Split the largest cluster $largest into two.&quot;) val weight = (maxWeight + minWeight) / 2.0 clusterWeights(largest) = weight clusterWeights(smallest) = weight val largestClusterCenter = clusterCenters(largest) val smallestClusterCenter = clusterCenters(smallest) var j = 0 while (j &lt; dim) { val x = largestClusterCenter(j) val p = 1e-14 * math.max(math.abs(x), 1.0) largestClusterCenter.toBreeze(j) = x + p smallestClusterCenter.toBreeze(j) = x - p j += 1 } }","link":"/2019/07/31/streaming-k-means/"},{"title":"奇异值分解","text":"奇异值分解&emsp;&emsp;在了解特征值分解之后，我们知道，矩阵A不一定是方阵。为了得到方阵，可以将矩阵A的转置乘以该矩阵。从而可以得到公式： &emsp;&emsp;现在假设存在`M*N`矩阵`A`，我们的目标是在`n`维空间中找一组正交基，使得经过`A`变换后还是正交的。假设已经找到这样一组正交基： &emsp;&emsp;A矩阵可以将这组正交基映射为如下的形式。 &emsp;&emsp;要使上面的基也为正交基，即使它们两两正交，那么需要满足下面的条件。 &emsp;&emsp;如果正交基v选择为$A^{T}A$的特征向量的话，由于$A^{T}A$是对称阵，v之间两两正交，那么 &emsp;&emsp;由于下面的公式成立 &emsp;&emsp;所以取单位向量 &emsp;&emsp;可以得到(下面的公式有误，delta_i 应该等于sqrt(lamda_i)) &emsp;&emsp;奇异值分解是一个能适用于任意的矩阵的一种分解的方法，它的形式如下： &emsp;&emsp;其中，U是一个M*M的方阵，它包含的向量是正交的，称为左奇异向量（即上文的u）。sigma是一个M*N的对角矩阵，每个对角线上的元素就是一个奇异值。V是一个N*N的矩阵，它包含的向量是正交的，称为右奇异向量（即上文的v）。 源码分析&emsp;&emsp;MLlib在RowMatrix类中实现了奇异值分解。下面是一个使用奇异值分解的例子。 123456789import org.apache.spark.mllib.linalg.Matriximport org.apache.spark.mllib.linalg.distributed.RowMatriximport org.apache.spark.mllib.linalg.SingularValueDecompositionval mat: RowMatrix = ...// Compute the top 20 singular values and corresponding singular vectors.val svd: SingularValueDecomposition[RowMatrix, Matrix] = mat.computeSVD(20, computeU = true)val U: RowMatrix = svd.U // The U factor is a RowMatrix.val s: Vector = svd.s // The singular values are stored in a local dense vector.val V: Matrix = svd.V // The V factor is a local dense matrix. 性能&emsp;&emsp;我们假设n比m小。奇异值和右奇异值向量可以通过方阵$A^{T}A$的特征值和特征向量得到。左奇异向量通过$AVS^{-1}$求得。ml实际使用的方法方法依赖计算花费。 当n很小（n&lt;100）或者k比n大(k&gt;n/2)，我们会首先计算方阵$A^{T}A$ ，然后在driver本地计算它的top特征值和特征向量。它的空间复杂度是O(n*n)，时间复杂度是O(n*n*k)。 否则，我们用分布式的方式先计算$A^{T}Av$,然后把它传给ARPACK在driver上计算top特征值和特征向量。它需要传递O(k)的数据，每个executor的空间复杂度是O(n),driver的空间复杂度是O(nk) 代码实现12345678910def computeSVD( k: Int, computeU: Boolean = false, rCond: Double = 1e-9): SingularValueDecomposition[RowMatrix, Matrix] = { // 迭代次数 val maxIter = math.max(300, k * 3) // 阈值 val tol = 1e-10 computeSVD(k, computeU, rCond, maxIter, tol, &quot;auto&quot;)} &emsp;&emsp;computeSVD(k, computeU, rCond, maxIter, tol, &quot;auto&quot;)的实现分为三步。分别是选择计算模式，$A^{T}A$的特征值分解，计算V,U,Sigma。下面分别介绍这三步。 1 选择计算模式 1234567891011121314151617181920val computeMode = mode match { case &quot;auto&quot; =&gt; if (k &gt; 5000) { logWarning(s&quot;computing svd with k=$k and n=$n, please check necessity&quot;) } if (n &lt; 100 || (k &gt; n / 2 &amp;&amp; n &lt;= 15000)) { // 满足上述条件，首先计算方阵，然后本地计算特征值，避免数据传递 if (k &lt; n / 3) { SVDMode.LocalARPACK } else { SVDMode.LocalLAPACK } } else { // 分布式实现 SVDMode.DistARPACK } case &quot;local-svd&quot; =&gt; SVDMode.LocalLAPACK case &quot;local-eigs&quot; =&gt; SVDMode.LocalARPACK case &quot;dist-eigs&quot; =&gt; SVDMode.DistARPACK} 2 特征值分解 12345678910111213141516val (sigmaSquares: BDV[Double], u: BDM[Double]) = computeMode match { case SVDMode.LocalARPACK =&gt; val G = computeGramianMatrix().toBreeze.asInstanceOf[BDM[Double]] EigenValueDecomposition.symmetricEigs(v =&gt; G * v, n, k, tol, maxIter) case SVDMode.LocalLAPACK =&gt; // breeze (v0.10) svd latent constraint, 7 * n * n + 4 * n &lt; Int.MaxValue val G = computeGramianMatrix().toBreeze.asInstanceOf[BDM[Double]] val brzSvd.SVD(uFull: BDM[Double], sigmaSquaresFull: BDV[Double], _) = brzSvd(G) (sigmaSquaresFull, uFull) case SVDMode.DistARPACK =&gt; if (rows.getStorageLevel == StorageLevel.NONE) { logWarning(&quot;The input data is not directly cached, which may hurt performance if its&quot; + &quot; parent RDDs are also uncached.&quot;) } EigenValueDecomposition.symmetricEigs(multiplyGramianMatrixBy, n, k, tol, maxIter) } &emsp;&emsp;当计算模式是SVDMode.LocalARPACK和SVDMode.LocalLAPACK时，程序实现的步骤是先获取方阵$A^{T}A$ ，在计算其特征值和特征向量。获取方阵无需赘述，我们只需要注意它无法处理列大于65535的矩阵。我们分别看这两种模式下，如何获取特征值和特征向量。 &emsp;&emsp;在SVDMode.LocalARPACK模式下，使用EigenValueDecomposition.symmetricEigs(v =&gt; G * v, n, k, tol, maxIter)计算特征值和特征向量。在SVDMode.LocalLAPACK模式下，直接使用breeze的方法计算。 &emsp;&emsp;在SVDMode.DistARPACK模式下，不需要先计算方阵，但是传入EigenValueDecomposition.symmetricEigs方法的函数不同。 1234567891011121314151617private[mllib] def multiplyGramianMatrixBy(v: BDV[Double]): BDV[Double] = { val n = numCols().toInt //v作为广播变量 val vbr = rows.context.broadcast(v) rows.treeAggregate(BDV.zeros[Double](n))( seqOp = (U, r) =&gt; { val rBrz = r.toBreeze val a = rBrz.dot(vbr.value) rBrz match { //计算y += x * a case _: BDV[_] =&gt; brzAxpy(a, rBrz.asInstanceOf[BDV[Double]], U) case _: BSV[_] =&gt; brzAxpy(a, rBrz.asInstanceOf[BSV[Double]], U) case _ =&gt; throw new UnsupportedOperationException } U }, combOp = (U1, U2) =&gt; U1 += U2) } &emsp;&emsp;特征值分解的具体分析在特征值分解中有详细分析，请参考该文了解详情。 3 计算U,V以及Sigma 1234567891011121314151617181920212223242526272829303132333435363738//获取特征值向量val sigmas: BDV[Double] = brzSqrt(sigmaSquares)val sigma0 = sigmas(0)val threshold = rCond * sigma0var i = 0// sigmas的长度可能会小于k// 所以使用 i &lt; min(k, sigmas.length) 代替 i &lt; k.if (sigmas.length &lt; k) { logWarning(s&quot;Requested $k singular values but only found ${sigmas.length} converged.&quot;)}while (i &lt; math.min(k, sigmas.length) &amp;&amp; sigmas(i) &gt;= threshold) { i += 1}val sk = iif (sk &lt; k) { logWarning(s&quot;Requested $k singular values but only found $sk nonzeros.&quot;)}//计算s，也即sigmaval s = Vectors.dense(Arrays.copyOfRange(sigmas.data, 0, sk))//计算Vval V = Matrices.dense(n, sk, Arrays.copyOfRange(u.data, 0, n * sk))//计算U// N = Vk * Sk^{-1}val N = new BDM[Double](n, sk, Arrays.copyOfRange(u.data, 0, n * sk))var i = 0var j = 0while (j &lt; sk) { i = 0 val sigma = sigmas(j) while (i &lt; n) { //对角矩阵的逆即为倒数 N(i, j) /= sigma i += 1 } j += 1}//U=A * Nval U = this.multiply(Matrices.fromBreeze(N)) 参考文献【1】强大的矩阵奇异值分解(SVD)及其应用 【2】奇异值分解(SVD)原理详解及推导 【3】A Singularly Valuable Decomposition: The SVD of a Matrix","link":"/2019/08/04/svd/"},{"title":"Unique Subsets","text":"Question leetcode: Subsets II | LeetCode OJ lintcode: (18) Unique Subsets Problem StatementGiven a list of numbers that may has duplicate numbers, return all possible subsets. ExampleIf S = [1,2,2], a solution is: [ [2], [1], [1,2,2], [2,2], [1,2], [] ] NoteEach element in a subset must be in **non-descending **order.The ordering between two subsets is free.The solution set must not contain duplicate subsets. 题解此题在上一题的基础上加了有重复元素的情况，因此需要对回溯函数进行一定的剪枝，对于排列组合的模板程序，剪枝通常可以从两个地方出发，一是在返回结果result.add之前进行剪枝，另一个则是在list.add处剪枝，具体使用哪一种需要视情况而定，哪种简单就选谁。 由于此题所给数组不一定有序，故首先需要排序。有重复元素对最终结果的影响在于重复元素最多只能出现n次(重复个数为n时)。具体分析过程如下(此分析过程改编自 九章算法)。 以 $$[1, 2_1, 2_2]$$ 为例，若不考虑重复，组合有 $$[], [1], [1, 2_1], [1, 2_1, 2_2], [1, 2_2], [2_1], [2_1, 2_2], [2_2]$$. 其中重复的有 $$[1, 2_2], [2_2]$$. 从中我们可以看出只能从重复元素的第一个持续往下添加到列表中，而不能取第二个或之后的重复元素。参考上一题Subsets的模板，能代表「重复元素的第一个」即为 for 循环中的pos变量，i == pos时，i处所代表的变量即为某一层遍历中得「第一个元素」，因此去重时只需判断i != pos &amp;&amp; s[i] == s[i - 1](不是 i + 1, 可能索引越界，而i 不等于 pos 已经能保证 i &gt;= 1). C++123456789101112131415161718192021222324252627282930313233343536class Solution {public: /** * @param S: A set of numbers. * @return: A list of lists. All valid subsets. */ vector&lt;vector&lt;int&gt; &gt; subsetsWithDup(const vector&lt;int&gt; &amp;S) { vector&lt;vector&lt;int&gt; &gt; result; if (S.empty()) { return result; } vector&lt;int&gt; list; vector&lt;int&gt; source(S); sort(source.begin(), source.end()); backtrack(result, list, source, 0); return result; }private: void backtrack(vector&lt;vector&lt;int&gt; &gt; &amp;ret, vector&lt;int&gt; &amp;list, vector&lt;int&gt; &amp;s, int pos) { ret.push_back(list); for (int i = pos; i != s.size(); ++i) { if (i != pos &amp;&amp; s[i] == s[i - 1]) { continue; } list.push_back(s[i]); backtrack(ret, list, s, i + 1); list.pop_back(); } }}; Java123456789101112131415161718192021222324252627282930class Solution { /** * @param S: A set of numbers. * @return: A list of lists. All valid subsets. */ public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; subsetsWithDup(ArrayList&lt;Integer&gt; S) { ArrayList&lt;ArrayList&lt;Integer&gt;&gt; result = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); if (S == null) return result; // Collections.sort(S); List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); dfs(S, 0, list, result); return result; } private void dfs(ArrayList&lt;Integer&gt; S, int pos, List&lt;Integer&gt; list, ArrayList&lt;ArrayList&lt;Integer&gt;&gt; result) { result.add(new ArrayList&lt;Integer&gt;(list)); for (int i = pos; i &lt; S.size(); i++) { // exlude duplicate if (i != pos &amp;&amp; S.get(i) == S.get(i - 1)) { continue; } list.add(S.get(i)); dfs(S, i + 1, list, result); list.remove(list.size() - 1); } }} 源码分析相比前一道题多了去重的判断。 复杂度分析和前一道题差不多，最坏情况下时间复杂度为 $$2^n$$. 空间复杂度为 $$O(n)$$. Reference Subsets II | 九章算法","link":"/2019/05/01/unique_subsets/"},{"title":"条件随机场CRF(三) 模型学习与维特比算法解码","text":"在CRF系列的前两篇，我们总结了CRF的模型基础与第一个问题的求解方法，本文我们关注于linear-CRF的第二个问题与第三个问题的求解。第二个问题是模型参数学习的问题，第三个问题是维特比算法解码的问题。 linear-CRF模型参数学习思路在linear-CRF模型参数学习问题中，我们给定训练数据集$X$和对应的标记序列$Y$，$K$个特征函数$f_k(x,y)$，需要学习linear-CRF的模型参数$w_k$和条件概率$P_w(y|x)$，其中条件概率$P_w(y|x)$和模型参数$w_k$满足一下关系：$$P_w(y|x) = P(y|x) = \\frac{1}{Z_w(x)}exp\\sum\\limits_{k=1}^Kw_kf_k(x,y) = \\frac{exp\\sum\\limits_{k=1}^Kw_kf_k(x,y)}{\\sum\\limits_{y}exp\\sum\\limits_{k=1}^Kw_kf_k(x,y)}$$所以我们的目标就是求出所有的模型参数$w_k$，这样条件概率$P_w(y|x)$可以从上式计算出来。 求解这个问题有很多思路，比如梯度下降法，牛顿法，拟牛顿法。同时，这个模型中$P_w(y|x)$的表达式和最大熵模型原理小结中的模型一样，也可以使用最大熵模型中使用的改进的迭代尺度法(improved iterative scaling, IIS)来求解。 下面我们只简要介绍用梯度下降法的求解思路。 linear-CRF模型参数学习之梯度下降法求解在使用梯度下降法求解模型参数之前，我们需要定义我们的优化函数，一般极大化条件分布$P_w(y|x)$的对数似然函数如下：$$L(w)= log\\prod_{x,y}P_w(y|x)^{\\overline{P}(x,y)} = \\sum\\limits_{x,y}\\overline{P}(x,y)logP_w(y|x)$$其中$\\overline{P}(x,y)$为经验分布，可以从先验知识和训练集样本中得到,这点和最大熵模型类似。为了使用梯度下降法，我们现在极小化$f(w) = -L(P_w)$如下：对$w$求导可以得到：$$\\frac{\\partial f(w)}{\\partial w} = \\sum\\limits_{x,y}\\overline{P}(x)P_w(y|x)f(x,y) - \\sum\\limits_{x,y}\\overline{P}(x,y)f(x,y)$$有了$w$的导数表达书，就可以用梯度下降法来迭代求解最优的$w$了。注意在迭代过程中，每次更新$w$后，需要同步更新$P_w(x,y)$,以用于下一次迭代的梯度计算。 梯度下降法的过程这里就不累述了，如果不熟悉梯度下降算法过程建议阅读之前写的梯度下降（Gradient Descent）小结。以上就是linear-CRF模型参数学习之梯度下降法求解思路总结。 linear-CRF模型维特比算法解码思路现在我们来看linear-CRF的第三个问题：解码。在这个问题中，给定条件随机场的条件概率$P(y|x)$和一个观测序列$x$,要求出满足$P(y|x)$最大的序列$y$。 这个解码算法最常用的还是和HMM解码类似的维特比算法。到目前为止，我已经在三个地方讲到了维特比算法，第一个是文本挖掘的分词原理中用于中文分词，第二个是隐马尔科夫模型HMM（四）维特比算法解码隐藏状态序列中用于HMM解码。第三个就是这一篇了。 维特比算法本身是一个动态规划算法，利用了两个局部状态和对应的递推公式，从局部递推到整体，进而得解。对于具体不同的问题，仅仅是这两个局部状态的定义和对应的递推公式不同而已。由于在之前已详述维特比算法，这里就是做一个简略的流程描述。 对于我们linear-CRF中的维特比算法，我们的第一个局部状态定义为$\\delta_i(l)$,表示在位置$i$标记$l$各个可能取值(1,2…m)对应的非规范化概率的最大值。之所以用非规范化概率是，规范化因子$Z(x)$不影响最大值的比较。根据$\\delta_i(l)$的定义，我们递推在位置$i+1$标记$l$的表达式为：$$\\delta_{i+1}(l) = \\max_{1 \\leq j \\leq m}{\\delta_i(j) + \\sum\\limits_{k=1}^Kw_kf_k(y_{i} =j,y_{i+1} = l,x,i)};, l=1,2,…m$$和HMM的维特比算法类似，我们需要用另一个局部状态$\\Psi_{i+1}(l)$来记录使$\\delta_{i+1}(l)$达到最大的位置$i$的标记取值,这个值用来最终回溯最优解，$\\delta_{i+1}(l)$的递推表达式为：$$\\Psi_{i+1}(l) = arg;\\max_{1 \\leq j \\leq m}{\\delta_i(j) + \\sum\\limits_{k=1}^Kw_kf_k(y_{i} =j,y_{i+1} = l,x,i)}; ,l=1,2,…m$$ linear-CRF模型维特比算法流程现在我们总结下 linear-CRF模型维特比算法流程： 输入：模型的$K$个特征函数，和对应的K个权重。观测序列$x=(x_1,x_2,…x_n)$,可能的标记个数$m$ 输出：最优标记序列$y^* =(y_1^*,y_2^*,…y_n^*)$ 初始化：$$\\delta_{1}(l) = \\sum\\limits_{k=1}^Kw_kf_k(y_{0} =start,y_{1} = l,x,i)};, l=1,2,…m$$$$\\Psi_{1}(l) = start;, l=1,2,…m$$ 对于$i=1,2…n-1$,进行递推：$$\\delta_{i+1}(l) = \\max_{1 \\leq j \\leq m}{\\delta_i(j) + \\sum\\limits_{k=1}^Kw_kf_k(y_{i} =j,y_{i+1} = l,x,i)};, l=1,2,…m$$$$\\Psi_{i+1}(l) = arg;\\max_{1 \\leq j \\leq m}{\\delta_i(j) + \\sum\\limits_{k=1}^Kw_kf_k(y_{i} =j,y_{i+1} = l,x,i)}; ,l=1,2,…m$$ 终止：$$y_n^* = arg;\\max_{1 \\leq j \\leq m}\\delta_n(j)$$ 回溯：$$y_i^* = \\Psi_{i+1}(y_{i+1}^*);, i=n-1,n-2,…1$$最终得到最优标记序列$y^* =(y_1^*,y_2^*,…y_n^*)$ linear-CRF模型维特比算法实例下面用一个具体的例子来描述 linear-CRF模型维特比算法，例子的模型和CRF系列第一篇中一样，都来源于《统计学习方法》。 假设输入的都是三个词的句子，即$X=(X_1,X_2,X_3)$,输出的词性标记为$Y=(Y_1,Y_2,Y_3)$,其中$Y \\in {1(名词)，2(动词)}$ 这里只标记出取值为1的特征函数如下：$$t_1 =t_1(y_{i-1} = 1, y_i =2,x,i), i =2,3,;;\\lambda_1=1 \\t_2 =t_2(y_1=1,y_2=1,x,2);;\\lambda_2=0.6 \\t_3 =t_3(y_2=2,y_3=1,x,3);;\\lambda_3=1 \\t_4 =t_4(y_1=2,y_2=1,x,2);;\\lambda_4=1 \\t_5 =t_5(y_2=2,y_3=2,x,3);;\\lambda_5=0.2 \\s_1 =s_1(y_1=1,x,1);;\\mu_1 =1 \\s_2 =s_2( y_i =2,x,i), i =1,2,;;\\mu_2=0.5 \\s_3 =s_3( y_i =1,x,i), i =2,3,;;\\mu_3=0.8 \\s_4 =s_4(y_3=2,x,3);;\\mu_4 =0.5$$求标记(1,2,2)的最可能的标记序列。 首先初始化:$$\\delta_1(1) = \\mu_1s_1 = 1;;;\\delta_1(2) = \\mu_2s_2 = 0.5;;;\\Psi_{1}(1) =\\Psi_{1}(2) = start$$接下来开始递推，先看位置2的：$$\\delta_2(1) = max{\\delta_1(1) + t_2\\lambda_2+\\mu_3s_3, \\delta_1(2) + t_4\\lambda_4+\\mu_3s_3 } = max{1+0.6+0.8,0.5+1+0.8} =2.4;;;\\Psi_{2}(1) =1$$$$\\delta_2(2) = max{\\delta_1(1) + t_1\\lambda_1+\\mu_2s_2, \\delta_1(2) + \\mu_2s_2} = max{1+1+0.5,0.5+0.5} =2.5;;;\\Psi_{2}(2) =1$$再看位置3的：$$\\delta_3(1) = max{\\delta_2(1) +\\mu_3s_3, \\delta_2(2) + t_3\\lambda_3+\\mu_3s_3} = max{2.4+0.8,2.5+1+0.8} =4.3$$$$\\Psi_{3}(1) =2$$$$\\delta_3(2) = max{\\delta_2(1) +t_1\\lambda_1 + \\mu_4s_4, \\delta_2(2) + t_5\\lambda_5+\\mu_4s_4} = max{2.4+1+0.5,2.5+0.2+0.5} =3.9$$$$\\Psi_{3}(2) =1$$最终得到$y_3^* =\\arg;max{\\delta_3(1), \\delta_3(2)}$,递推回去，得到：$$y_2^* = \\Psi_3(1) =2;;y_1^* = \\Psi_2(2) =1$$即最终的结果为(1,2,1),即标记为(名词，动词，名词)。 linear-CRF vs HMMlinear-CRF模型和HMM模型有很多相似之处，尤其是其三个典型问题非常类似，除了模型参数学习的问题求解方法不同以外，概率估计问题和解码问题使用的算法思想基本也是相同的。同时，两者都可以用于序列模型，因此都广泛用于自然语言处理的各个方面。 现在来看看两者的不同点。最大的不同点是linear-CRF模型是判别模型，而HMM是生成模型，即linear-CRF模型要优化求解的是条件概率$P(y|x)$,则HMM要求解的是联合分布$P(x,y)$。第二，linear-CRF是利用最大熵模型的思路去建立条件概率模型，对于观测序列并没有做马尔科夫假设。而HMM是在对观测序列做了马尔科夫假设的前提下建立联合分布的模型。 最后想说的是，只有linear-CRF模型和HMM模型才是可以比较讨论的。但是linear-CRF是CRF的一个特例，CRF本身是一个可以适用于很复杂条件概率的模型，因此理论上CRF的使用范围要比HMM广泛的多。 以上就是CRF系列的所有内容。","link":"/2020/03/05/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%B8%89-%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E8%A7%A3%E7%A0%81/"},{"title":"条件随机场CRF(二) 前向后向算法评估标记序列概率","text":"在条件随机场CRF(一)中我们总结了CRF的模型，主要是linear-CRF的模型原理。本文就继续讨论linear-CRF需要解决的三个问题：评估，学习和解码。这三个问题和HMM是非常类似的，本文关注于第一个问题：评估。第二个和第三个问题会在下一篇总结。 linear-CRF的三个基本问题在隐马尔科夫模型HMM中，我们讲到了HMM的三个基本问题，而linear-CRF也有三个类似的的基本问题。不过和HMM不同，在linear-CRF中，我们对于给出的观测序列$x$是一直作为一个整体看待的，也就是不会拆开看$(x_1,x_2,…)$，因此linear-CRF的问题模型要比HMM简单一些，如果你很熟悉HMM，那么CRF的这三个问题的求解就不难了。 linear-CRF第一个问题是评估，即给定 linear-CRF的条件概率分布$P(y|x)$, 在给定输入序列$x$和输出序列$y$时，计算条件概率$P(y_i|x)$和$P(y_{i-1}，y_i|x)$以及对应的期望. 本文接下来会详细讨论问题一。 linear-CRF第二个问题是学习，即给定训练数据集$X$和$Y$，学习linear-CRF的模型参数$w_k$和条件概率$P_w(y|x)$，这个问题的求解比HMM的学习算法简单的多，普通的梯度下降法，拟牛顿法都可以解决。 linear-CRF第三个问题是解码，即给定 linear-CRF的条件概率分布$P(y|x)$,和输入序列$x$, 计算使条件概率最大的输出序列$y$。类似于HMM，使用维特比算法可以很方便的解决这个问题。 linear-CRF的前向后向概率概述要计算条件概率$P(y_i|x)$和$P(y_{i-1}，y_i|x)$，我们也可以使用和HMM类似的方法，使用前向后向算法来完成。首先我们来看前向概率的计算。 我们定义$\\alpha_i(y_i|x)$表示序列位置𝑖的标记是$y_i$ 时，在位置$i$之前的部分标记序列的非规范化概率。之所以是非规范化概率是因为我们不想加入一个不影响结果计算的规范化因子$Z(x)$在分母里面。 在条件随机场CRF(一)第八节中，我们定义了下式： $$M_i(y_{i-1},y_i |x) = exp(\\sum\\limits_{k=1}^Kw_kf_k(y_{i-1},y_i, x,i))$$这个式子定义了在给定$y_{i-1}$时，从$y_{i-1}$转移到$y_i$的非规范化概率。 这样，我们很容易得到序列位置$i+1$的标记是$y_{i+1}$时，在位置$i+1$之前的部分标记序列的非规范化概率$\\alpha_{i+1}(y_{i+1}|x)$的递推公式：$$\\alpha_{i+1}(y_{i+1}|x) = \\alpha_i(y_i|x)M_{i+1}(y_{i+1},y_i|x) ;; i=1,2,…,n+1$$在起点处，我们定义：$$\\alpha_0(y_0|x)= \\begin{cases} 1 &amp; {y_0 =start}\\ 0 &amp; {else} \\end{cases}$$假设我们可能的标记总数是$m$, 则$y_i$的取值就有$m$个，我们用$\\alpha_i(x)$表示这$m$个值组成的前向向量如下：$$\\alpha_i(x) = (\\alpha_i(y_i=1|x), \\alpha_i(y_i=2|x), … \\alpha_i(y_i=m|x))^T$$同时用矩阵$M_i(x)$表示由$M_i(y_{i-1},y_i |x) $形成的$m \\times m$阶矩阵：$$M_i(x) = \\Big[ M_i(y_{i-1},y_i |x)\\Big]$$这样递推公式可以用矩阵乘积表示：$$\\alpha_{i+1}^T(x) = \\alpha_i^T(x)M_{i+1}(x)$$同样的。我们定义$\\beta_i(y_i|x)$表示序列位置$i$的标记是$y_i$时，在位置$i$之后的从$i+1$到$n$的部分标记序列的非规范化概率。 这样，我们很容易得到序列位置$i+1$的标记是$y_{i+1}$时，在位置$i$之后的部分标记序列的非规范化概率$\\beta_{i}(y_{i}|x)$的递推公式：$$\\beta_{i}(y_{i}|x) = M_{i+1}(y_i,y_{i+1}|x)\\beta_{i+1}(y_{i+1}|x)$$在终点处，我们定义：$$\\beta_{n+1}(y_{n+1}|x)= \\begin{cases} 1 &amp; {y_{n+1} =stop}\\ 0 &amp; {else} \\end{cases}$$如果用向量表示，则有：$$\\beta_i(x) = M_{i+1}(x)\\beta_{i+1}(x)$$由于规范化因子$Z(x)$的表达式是：$$Z(x) = \\sum\\limits_{c=1}^m\\alpha_{n}(y_c|x) = \\sum\\limits_{c=1}^m\\beta_{1}(y_c|x)$$也可以用向量来表示$Z(x)$:$$Z(x) = \\alpha_{n}^T(x) \\bullet \\mathbf{1} = \\mathbf{1}^T \\bullet \\beta_{1}(x)$$其中，$\\mathbf{1}$是$m$维全1向量。 linear-CRF的前向后向概率计算有了前向后向概率的定义和计算方法，我们就很容易计算序列位置$i$的标记是$y_i$时的条件概率$P(y_i|x)$:$$P(y_i|x) = \\frac{\\alpha_i^T(y_i|x)\\beta_i(y_i|x)}{Z(x)} = \\frac{\\alpha_i^T(y_i|x)\\beta_i(y_i|x)}{ \\alpha_{n}^T(x) \\bullet \\mathbf{1}}$$也容易计算序列位置𝑖的标记是$y_i$，位置$i-1$的标记是$y_{i-1}$时的条件概率$P(y_{i-1},y_i|x)$:$$P(y_{i-1},y_i|x) = \\frac{\\alpha_{i-1}^T(y_{i-1}|x)M_i(y_{i-1},y_i|x)\\beta_i(y_i|x)}{Z(x)} = \\frac{\\alpha_{i-1}^T(y_{i-1}|x)M_i(y_{i-1},y_i|x)\\beta_i(y_i|x)}{ \\alpha_{n}^T(x) \\bullet \\mathbf{1}}$$ linear-CRF的期望计算有了上一节计算的条件概率，我们也可以很方便的计算联合分布$P(x,y)$与条件分布$P(y|x)$的期望。 特征函数$f_k(x,y)$关于条件分布$P(y|x)$的期望表达式是：同样可以计算联合分布$P(x,y)$的期望：假设一共有$K$个特征函数，则$k=1,2,…K$ linear-CRF前向后向算法总结以上就是linear-CRF的前向后向算法，个人觉得比HMM简单的多，因此大家如果理解了HMM的前向后向算法，这一篇是很容易理解的。 注意到我们上面的非规范化概率$M_{i+1}(y_{i+1},y_i|x)$起的作用和HMM中的隐藏状态转移概率很像。但是这儿的概率是非规范化的，也就是不强制要求所有的状态的概率和为1。而HMM中的隐藏状态转移概率也规范化的。从这一点看，linear-CRF对序列状态转移的处理要比HMM灵活。","link":"/2020/03/04/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%BA%8C-%E5%89%8D%E5%90%91%E5%90%8E%E5%90%91%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E6%A0%87%E8%AE%B0%E5%BA%8F%E5%88%97%E6%A6%82%E7%8E%87/"},{"title":"第一篇 监督学习","text":"笔记摘要 统计学习或机器学习一般包括监督学习、无监督学习、强化学习，有时还包括半监督学习、主动学习监督学习 监督学习指从标注数据中学习预测模型的机器学习问题，其本质是学习输入到输出的映射的统计规律。 输入变量$X$和输出变量$Y$有不同的类型，可以是连续或是离散的。根据输入输出变量的不同类型，对预测任务给予不同的名称：输入与输出均为连续变量的预测问题称为回归问题；输出变量为有限个离散变量的预测问题称为分类问题；输入与输出变量均为变量序列的预测问题称为标注问题。 无监督学习 无监督学习指从无标注数据中学习预测模型的机器学习问题，其本质是学习数据中的统计规律或内在结构。 无监督学习旨在从假设空间中选出在给定评价标准下的最优模型，模型可以实现对数据的聚类、降维或是概率估计。强化学习 强化学习指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题，其本质是学习最优的序贯决策。 智能系统的目标不是短期奖励的最大化，而是长期累积奖励的最大化。强化学习过程中，系统不断地试错，以达到学习最优策略地目的。 半监督学习与主动学习 半监督学习指利用标注数据和未标注数据学习预测模型地机器学习问题。其旨在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习效果。 主动学习是指机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型的机器学习问题。主动学习的目标是找出对学习最有帮助的实例让教师标注，以较小的标注代价达到较好的学习效果。 这两种学习更接近监督学习。 实现统计学习方法的步骤 得到一个有限的训练数据集合 确定包含所有可能的模型的假设空间，即学习模型的集合 确定模型选择的准则，即学习的策略 实现求解最优模型的算法，即学习的算法 通过学习方法选择最优的模型 利用学习的最优模型对新数据进行预测或分析 在上述步骤中涵盖了统计学习方法三要素：模型，策略，算法 在监督学习过程中，模型就是所要学习的条件概率分布或者决策函数。注意书中的这部分描述，整理了一下到表格里： 假设空间$\\mathcal F$ 输入空间$\\mathcal X$ 输出空间$\\mathcal Y$ 参数空间 决策函数 $\\mathcal F ={f$|$Y=f_{\\theta}(x), \\theta \\in \\bf R \\it ^n}$ 变量 变量 $\\bf R\\it ^n$ 条件概率分布 $\\mathcal F ={P$|$P_\\theta(Y$|$X), \\theta \\in \\bf R \\it ^n}$ 随机变量 随机变量 $\\bf R\\it ^n$ 损失函数与风险函数 损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。 损失函数(loss function)或代价函数(cost function)定义为给定输入$X$的预测值$f(X)$和真实值$Y$之间的非负实值函数，记作$L(Y,f(X))$。 风险函数(risk function)或期望损失(expected loss)和模型的泛化误差的形式是一样的$R_{exp}(f)=E_p[L(Y, f(X))]=\\int_{\\mathcal X\\times\\mathcal Y}L(y,f(x))P(x,y), {\\rm d}x{\\rm d}y$上式是模型$f(X)$关于联合分布$P(X,Y)$的平均意义下的损失(期望损失)，但是因为$P(X,Y)$是未知的，所以前面的用词是期望，以及平均意义下的。这个表示其实就是损失的均值，反映了对整个数据的预测效果的好坏。 经验风险(empirical risk)或经验损失(empirical loss) $R_{emp}(f)=\\frac{1}{N}\\sum^{N}_{i=1}L(y_i,f(x_i))$ 上式是模型$f$关于训练样本集的平均损失。根据大数定律，当样本容量N趋于无穷大时，经验风险趋于期望风险。 结构风险(structural risk) $R_{srm}(f)=\\frac{1}{N}\\sum_{i=1}^{N}L(y_i,f(x_i))+\\lambda J(f)$ 其中$J(f)$为模型复杂度, $\\lambda \\geqslant 0$是系数，用以权衡经验风险和模型复杂度。 常用损失函数损失函数数值越小，模型就越好 0-1损失 $L(Y,f(X))=\\begin{cases}1, Y \\neq f(X) \\0, Y=f(X) \\end{cases}$ 平方损失 $L(Y,f(X))=(Y-f(X))^2$ 绝对损失 $L(Y,f(X))=|Y-f(X)|$ 对数损失$L(Y,P(Y|X))=−logP(Y|X)$ ERM与SRM经验风险最小化(ERM)与结构风险最小化(SRM) 极大似然估计是经验风险最小化的一个例子。当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化等价于极大似然估计，下面习题1.2中给出了证明。 结构风险最小化等价于正则化 贝叶斯估计中的最大后验概率估计是结构风险最小化的一个例子。当模型是条件概率分布，损失函数是对数损失函数，模型复杂度由模型的先验概率表示时，结构风险最小化等价于最大后验概率估计。 算法 算法是指学习模型的具体计算方法。统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么杨的计算方法来求解最优模型。 模型评估与选择 训练误差和测试误差是模型关于数据集的平均损失。 注意：统计学习方法具体采用的损失函数未必是评估时使用的损失函数。 过拟合是指学习时选择的模型所包含的参数过多，以至出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。可以说模型选择旨在避免过拟合并提高模型的预测能力。 正则化与交叉验证 模型选择的典型方法是正则化.。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化就越大。比如，正则化项可以是模型参数向量的范数。 $L(w)=\\frac{1}{N}\\sum_{i=1}^{N}(f(x_i;w)-y_i)^2+\\frac{\\lambda}{2}|w|^2$ $|w|$表示向量$w$的$L_2$范数 正则化符合奥卡姆剃刀原理：如无必要，勿增实体。在应用于模型选择中时，可以理解为：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单的才是最好的模型，也是应该选择的模型。 交叉验证的基本想法时重复地利用数据；把给定地数据进行切分，将切分的数据集组合为训练集和测试集，在此基础上反复地进行训练、测试以及模型选择。 主要有简单交叉验证，S折交叉验证，留一交叉验证三种。 在算法学习的过程中，测试集可能是固定的，但是验证集和训练集可能是变化的。比如S折交叉验证的情况下，分成S折之后，其中的S-1折作为训练集，1折作为验证集，计算这S个模型每个模型的平均测试误差，最后选择平均测试误差最小的模型。这个过程中用来验证模型效果的那一折数据就是验证集。 生成模型与判别模型监督学习方法可分为生成方法(generative approach)与判别方法(discriminative approach) 生成方法(generative approach) 可以还原出联合概率分布$P(X,Y)$ 收敛速度快, 当样本容量增加时, 学到的模型可以更快收敛到真实模型 当存在隐变量时仍可以用 判别方法(discriminative approach) 直接学习条件概率$P(Y|X)$或者决策函数$f(X)$ 直接面对预测, 往往学习准确率更高 可以对数据进行各种程度的抽象, 定义特征并使用特征, 可以简化学习问题 习题解答 1.1 说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学方法三要素 伯努利模型是定义在取值为0与1的随机变量上的概率分布。统计学分为两派：经典统计学派和贝叶斯统计学派。两者的不同主要是，经典统计学派认为模型已定，参数未知，参数是固定的，只是还不知道；贝叶斯统计学派是通过观察到的现象对概率分布中的主观认定不断进行修正。 极大似然估计用的是经典统计学派的策略，贝叶斯估计用的是贝叶斯统计学派的策略；为了得到使经验风险最小的参数值，使用的算法都是对经验风险求导，使导数为0。 定义随机变量$A$为一次伯努利试验的结果，$A$的取值为${0,1}$，概率分布为$P(A)$： $$P(A=1)=θ，P(A=0)=1-θ$$ * 极大似然估计 $$L(θ)=\\prod_{i=1}^nP(A_i)=θ^k(1-θ)^{n-k}$$$$θ=\\arg\\max_{θ}L(θ)=\\frac{k}{n}$$上述估计通过取对数求导得到，$A_i$为第$i$次随机试验 贝叶斯估计$$P(θ|A_1,A_2,…，A_n)=\\frac{P(A_1,A_2,…，A_n|θ)P(θ)}{P(A_1,A_2,…，A_n)}$$ 根据观察到的结果修正$θ$，也就是假设$θ$是随机变量，$θ$服从β分布，有很多个可能的取值，我们要取的值是在已知观察结果的条件下使$θ$出现概率最大的值。上式分母是不变的，求分子最大就可以。 $$\\begin{aligned}\\theta&amp;=arg\\max \\limits_\\theta {P(A_1,A_2,…,A_n|\\theta)P(\\theta)} \\&amp;= arg\\max \\limits_\\theta {\\prod_{i=1}^{n}P(A_i|\\theta)P(\\theta)} \\&amp;=arg \\max \\limits_\\theta {\\theta^k(1-\\theta)^{n-k}\\theta^{a-1}(1-\\theta)^{b-1}} \\&amp;=\\frac{k+(a-1)}{n+(a-1)+(b-1)}\\end{aligned}$$ β分布是一个作为伯努利分布和二项式分布的共轭先验分布的密度函数，是指一组定义在$(0,1)$区间的连续概率分布，有两个参数α，β&gt;0。选定参数后就可以确定$\\theta$。 统计学习方法的三要素为模型，策略，算法。 1.2 通过经验风险最小化推导极大似然估计。证明模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。 模型是条件概率分布：$P_θ(Y|X)$，损失函数是对数损失函数：$L(Y,P_θ(Y|X))=−logP_θ(Y|X)$经验风险为：$$ \\begin{aligned}R_{emp}(f)&amp;=\\frac{1}{N}\\sum_{i=1}^{N}L(y_i,f(x_i)) \\&amp;=\\frac{1}{N}\\sum_{i=1}^{N}-logP(y_i|x_i) \\&amp;=-\\frac{1}{N}\\sum_{i=1}^{N}logP(y_i|x_i)\\end{aligned}$$ 极大似然估计的似然函数为：$$L(\\theta)=\\prod_DP_{\\theta}(Y|X)$$ * 取对数$$log(L(\\theta))=\\sum_DlogP_{\\theta}(Y|X)$$$$arg\\max_\\theta\\sum_DlogP_{\\theta}(Y|X)=arg\\min_{\\theta}\\sum_D-logP_{\\theta}(Y|X)$$ 因此，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。","link":"/2021/05/23/%E7%AC%AC%E4%B8%80%E7%AF%87-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"title":"经典网络解读","text":"LeNet-5模型介绍​ LeNet-5是由$LeCun$ 提出的一种用于识别手写数字和机器印刷字符的卷积神经网络（Convolutional Neural Network，CNN）$^{[1]}$，其命名来源于作者$LeCun$的名字，5则是其研究成果的代号，在LeNet-5之前还有LeNet-4和LeNet-1鲜为人知。LeNet-5阐述了图像中像素特征之间的相关性能够由参数共享的卷积操作所提取，同时使用卷积、下采样（池化）和非线性映射这样的组合结构，是当前流行的大多数深度图像识别网络的基础。 模型结构 ​ 图4.1 LeNet-5网络结构图 ​ 如图4.1所示，LeNet-5一共包含7层（输入层不作为网络结构），分别由2个卷积层、2个下采样层和3个连接层组成，网络的参数配置如表4.1所示，其中下采样层和全连接层的核尺寸分别代表采样范围和连接矩阵的尺寸（如卷积核尺寸中的$“5\\times5\\times1/1,6”$表示核大小为$5\\times5\\times1$、步长为$1​$且核个数为6的卷积核）。 ​ 表4.1 LeNet-5网络参数配置 网络层 输入尺寸 核尺寸 输出尺寸 可训练参数量 卷积层$C_1$ $32\\times32\\times1$ $5\\times5\\times1/1,6$ $28\\times28\\times6$ $(5\\times5\\times1+1)\\times6$ 下采样层$S_2$ $28\\times28\\times6$ $2\\times2/2$ $14\\times14\\times6$ $(1+1)\\times6$ $^*$ 卷积层$C_3$ $14\\times14\\times6$ $5\\times5\\times6/1,16$ $10\\times10\\times16$ $1516^*$ 下采样层$S_4$ $10\\times10\\times16$ $2\\times2/2$ $5\\times5\\times16$ $(1+1)\\times16$ 卷积层$C_5$$^*$ $5\\times5\\times16$ $5\\times5\\times16/1,120$ $1\\times1\\times120$ $(5\\times5\\times16+1)\\times120$ 全连接层$F_6$ $1\\times1\\times120$ $120\\times84$ $1\\times1\\times84$ $(120+1)\\times84$ 输出层 $1\\times1\\times84$ $84\\times10$ $1\\times1\\times10$ $(84+1)\\times10$ ​ $^*$ 在LeNet中，下采样操作和池化操作类似，但是在得到采样结果后会乘以一个系数和加上一个偏置项，所以下采样的参数个数是$(1+1)\\times6​$而不是零。 ​ $^*$ $C_3$卷积层可训练参数并未直接连接$S_2$中所有的特征图（Feature Map），而是采用如图4.2所示的采样特征方式进行连接（稀疏连接），生成的16个通道特征图中分别按照相邻3个特征图、相邻4个特征图、非相邻4个特征图和全部6个特征图进行映射，得到的参数个数计算公式为$6\\times(25\\times3+1)+6\\times(25\\times4+1)+3\\times(25\\times4+1)+1\\times(25\\times6+1)=1516$，在原论文中解释了使用这种采样方式原因包含两点：限制了连接数不至于过大（当年的计算能力比较弱）;强制限定不同特征图的组合可以使映射得到的特征图学习到不同的特征模式。 ​ 图4.2 $S_2$与$C_3$之间的特征图稀疏连接 ​ $^*$ $C_5$卷积层在图4.1中显示为全连接层，原论文中解释这里实际采用的是卷积操作，只是刚好在$5\\times5$卷积后尺寸被压缩为$1\\times1​$，输出结果看起来和全连接很相似。 模型特性 卷积网络使用一个3层的序列组合：卷积、下采样（池化）、非线性映射（LeNet-5最重要的特性，奠定了目前深层卷积网络的基础） 使用卷积提取空间特征 使用映射的空间均值进行下采样 使用$tanh$或$sigmoid$进行非线性映射 多层神经网络（MLP）作为最终的分类器 层间的稀疏连接矩阵以避免巨大的计算开销 AlexNet模型介绍​ AlexNet是由$Alex$ $Krizhevsky$提出的首个应用于图像分类的深层卷积神经网络，该网络在2012年ILSVRC（ImageNet Large Scale Visual Recognition Competition）图像分类竞赛中以15.3%的top-5测试错误率赢得第一名$^{[2]}$。AlexNet使用GPU代替CPU进行运算，使得在可接受的时间范围内模型结构能够更加复杂，它的出现证明了深层卷积神经网络在复杂模型下的有效性，使CNN在计算机视觉中流行开来，直接或间接地引发了深度学习的热潮。 模型结构 ​ 图4.3 AlexNet网络结构图 ​ 如图4.3所示，除去下采样（池化层）和局部响应规范化操作（Local Responsible Normalization, LRN），AlexNet一共包含8层，前5层由卷积层组成，而剩下的3层为全连接层。网络结构分为上下两层，分别对应两个GPU的操作过程，除了中间某些层（$C_3$卷积层和$F_{6-8}$全连接层会有GPU间的交互），其他层两个GPU分别计算结 果。最后一层全连接层的输出作为$softmax$的输入，得到1000个图像分类标签对应的概率值。除去GPU并行结构的设计，AlexNet网络结构与LeNet十分相似，其网络的参数配置如表4.2所示。 ​ 表4.2 AlexNet网络参数配置 网络层 输入尺寸 核尺寸 输出尺寸 可训练参数量 卷积层$C_1$ $^*$ $224\\times224\\times3$ $11\\times11\\times3/4,48(\\times2_{GPU})$ $55\\times55\\times48(\\times2_{GPU})$ $(11\\times11\\times3+1)\\times48\\times2$ 下采样层$S_{max}$$^*$ $55\\times55\\times48(\\times2_{GPU})$ $3\\times3/2(\\times2_{GPU})$ $27\\times27\\times48(\\times2_{GPU})$ 0 卷积层$C_2$ $27\\times27\\times48(\\times2_{GPU})$ $5\\times5\\times48/1,128(\\times2_{GPU})$ $27\\times27\\times128(\\times2_{GPU})$ $(5\\times5\\times48+1)\\times128\\times2$ 下采样层$S_{max}$ $27\\times27\\times128(\\times2_{GPU})$ $3\\times3/2(\\times2_{GPU})$ $13\\times13\\times128(\\times2_{GPU})$ 0 卷积层$C_3$ $^*$ $13\\times13\\times128\\times2_{GPU}$ $3\\times3\\times256/1,192(\\times2_{GPU})$ $13\\times13\\times192(\\times2_{GPU})$ $(3\\times3\\times256+1)\\times192\\times2$ 卷积层$C_4$ $13\\times13\\times192(\\times2_{GPU})$ $3\\times3\\times192/1,192(\\times2_{GPU})$ $13\\times13\\times192(\\times2_{GPU})$ $(3\\times3\\times192+1)\\times192\\times2$ 卷积层$C_5$ $13\\times13\\times192(\\times2_{GPU})$ $3\\times3\\times192/1,128(\\times2_{GPU})$ $13\\times13\\times128(\\times2_{GPU})$ $(3\\times3\\times192+1)\\times128\\times2$ 下采样层$S_{max}$ $13\\times13\\times128(\\times2_{GPU})$ $3\\times3/2(\\times2_{GPU})$ $6\\times6\\times128(\\times2_{GPU})$ 0 全连接层$F_6$ $^*$ $6\\times6\\times128\\times2_{GPU}$ $9216\\times2048(\\times2_{GPU})$ $1\\times1\\times2048(\\times2_{GPU})$ $(9216+1)\\times2048\\times2$ 全连接层$F_7$ $1\\times1\\times2048\\times2_{GPU}$ $4096\\times2048(\\times2_{GPU})$ $1\\times1\\times2048(\\times2_{GPU})$ $(4096+1)\\times2048\\times2$ 全连接层$F_8$ $1\\times1\\times2048\\times2_{GPU}$ $4096\\times1000$ $1\\times1\\times1000$ $(4096+1)\\times1000\\times2$ 卷积层$C_1$输入为$224\\times224\\times3$的图片数据，分别在两个GPU中经过核为$11\\times11\\times3$、步长（stride）为4的卷积卷积后，分别得到两条独立的$55\\times55\\times48$的输出数据。 下采样层$v$实际上是嵌套在卷积中的最大池化操作，但是为了区分没有采用最大池化的卷积层单独列出来。在$C_{1-2}$卷积层中的池化操作之后（ReLU激活操作之前），还有一个LRN操作，用作对相邻特征点的归一化处理。 卷积层$C_3$的输入与其他卷积层不同，$13\\times13\\times192\\times2_{GPU}$表示汇聚了上一层网络在两个GPU上的输出结果作为输入，所以在进行卷积操作时通道上的卷积核维度为384。 全连接层$F_{6-8}$中输入数据尺寸也和$C_3$类似，都是融合了两个GPU流向的输出结果作为输入。 模型特性 所有卷积层都使用ReLU作为非线性映射函数，使模型收敛速度更快 在多个GPU上进行模型的训练，不但可以提高模型的训练速度，还能提升数据的使用规模 使用LRN对局部的特征进行归一化，结果作为ReLU激活函数的输入能有效降低错误率 重叠最大池化（overlapping max pooling），即池化范围z与步长s存在关系$z&gt;s$（如$S_{max}$中核尺度为$3\\times3/2$），避免平均池化（average pooling）的平均效应 使用随机丢弃技术（dropout）选择性地忽略训练中的单个神经元，避免模型的过拟合 ZFNet模型介绍​ ZFNet是由$Matthew$ $D. Zeiler$和$Rob$ $Fergus$在AlexNet基础上提出的大型卷积网络，在2013年ILSVRC图像分类竞赛中以11.19%的错误率获得冠军（实际上原ZFNet所在的队伍并不是真正的冠军，原ZFNet以13.51%错误率排在第8，真正的冠军是$Clarifai$这个队伍，而$Clarifai$这个队伍所对应的一家初创公司的CEO又是$Zeiler$，而且$Clarifai$对ZFNet的改动比较小，所以通常认为是ZFNet获得了冠军）$^{[3-4]}​$。ZFNet实际上是微调（fine-tuning）了的AlexNet，并通过反卷积（Deconvolution）的方式可视化各层的输出特征图，进一步解释了卷积操作在大型网络中效果显著的原因。 模型结构 ​ 图4.4 ZFNet网络结构图（原始结构图与AlexNet风格结构图） ​ 如图4.4所示，ZFNet与AlexNet类似，都是由8层网络组成的卷积神经网络，其中包含5层卷积层和3层全连接层。两个网络结构最大的不同在于，ZFNet第一层卷积采用了$7\\times7\\times3/2$的卷积核替代了AlexNet中第一层卷积核$11\\times11\\times3/4$的卷积核。图4.5中ZFNet相比于AlexNet在第一层输出的特征图中包含更多中间频率的信息，而AlexNet第一层输出的特征图大多是低频或高频的信息，对中间频率特征的缺失导致后续网络层次如图4.5（c）能够学习到的特征不够细致，而导致这个问题的根本原因在于AlexNet在第一层中采用的卷积核和步长过大。 ​ 图4.5 （a）ZFNet第一层输出的特征图（b）AlexNet第一层输出的特征图（c）AlexNet第二层输出的特征图（d）ZFNet第二层输出的特征图 ​ 表4.3 ZFNet网络参数配置​| 网络层 | 输入尺寸 | 核尺寸 | 输出尺寸 | 可训练参数量 || :——————-: | :———————————-: | :————————————–: | :———————————-: | :————————————-: || 卷积层$C_1$ $^*$ | $224\\times224\\times3$ | $7\\times7\\times3/2,96$ | $110\\times110\\times96$ | $(7\\times7\\times3+1)\\times96$ || 下采样层$S_{max}$ | $110\\times110\\times96$ | $3\\times3/2$ | $55\\times55\\times96$ | 0 || 卷积层$C_2$ $^*$ | $55\\times55\\times96$ | $5\\times5\\times96/2,256$ | $26\\times26\\times256$ | $(5\\times5\\times96+1)\\times256$ || 下采样层$S_{max}$ | $26\\times26\\times256$ | $3\\times3/2$ | $13\\times13\\times256$ | 0 || 卷积层$C_3$ | $13\\times13\\times256$ | $3\\times3\\times256/1,384$ | $13\\times13\\times384$ | $(3\\times3\\times256+1)\\times384$ || 卷积层$C_4$ | $13\\times13\\times384$ | $3\\times3\\times384/1,384$ | $13\\times13\\times384$ | $(3\\times3\\times384+1)\\times384$ || 卷积层$C_5$ | $13\\times13\\times384$ | $3\\times3\\times384/1,256$ | $13\\times13\\times256$ | $(3\\times3\\times384+1)\\times256$ || 下采样层$S_{max}$ | $13\\times13\\times256$ | $3\\times3/2$ | $6\\times6\\times256$ | 0 || 全连接层$F_6$ | $6\\times6\\times256$ | $9216\\times4096$ | $1\\times1\\times4096$ | $(9216+1)\\times4096$ || 全连接层$F_7$ | $1\\times1\\times4096$ | $4096\\times4096$ | $1\\times1\\times4096$ | $(4096+1)\\times4096$ || 全连接层$F_8$ | $1\\times1\\times4096$ | $4096\\times1000$ | $1\\times1\\times1000$ | $(4096+1)\\times1000$ | 卷积层$C_1$与AlexNet中的$C_1$有所不同，采用$7\\times7\\times3/2$的卷积核代替$11\\times11\\times3/4​$，使第一层卷积输出的结果可以包含更多的中频率特征，对后续网络层中多样化的特征组合提供更多选择，有利于捕捉更细致的特征。 卷积层$C_2$采用了步长2的卷积核，区别于AlexNet中$C_2$的卷积核步长，所以输出的维度有所差异。 模型特性​ ZFNet与AlexNet在结构上几乎相同，此部分虽属于模型特性，但准确地说应该是ZFNet原论文中可视化技术的贡献。 可视化技术揭露了激发模型中每层单独的特征图。 可视化技术允许观察在训练阶段特征的演变过程且诊断出模型的潜在问题。 可视化技术用到了多层解卷积网络，即由特征激活返回到输入像素空间。 可视化技术进行了分类器输出的敏感性分析，即通过阻止部分输入图像来揭示那部分对于分类是重要的。 可视化技术提供了一个非参数的不变性来展示来自训练集的哪一块激活哪个特征图，不仅需要裁剪输入图片，而且自上而下的投影来揭露来自每块的结构激活一个特征图。 可视化技术依赖于解卷积操作，即卷积操作的逆过程，将特征映射到像素上。 Network in Network模型介绍​ Network In Network (NIN)是由$Min Lin$等人提出，在CIFAR-10和CIFAR-100分类任务中达到当时的最好水平，因其网络结构是由三个多层感知机堆叠而被成为NIN$^{[5]}$。NIN以一种全新的角度审视了卷积神经网络中的卷积核设计，通过引入子网络结构代替纯卷积中的线性映射部分，这种形式的网络结构激发了更复杂的卷积神经网络的结构设计，其中下一节中介绍的GoogLeNet的Inception结构就是来源于这个思想。 模型结构​ 图 4.6 NIN网络结构图 ​ NIN由三层的多层感知卷积层（MLPConv Layer）构成，每一层多层感知卷积层内部由若干层的局部全连接层和非线性激活函数组成，代替了传统卷积层中采用的线性卷积核。在网络推理（inference）时，这个多层感知器会对输入特征图的局部特征进行划窗计算，并且每个划窗的局部特征图对应的乘积的权重是共享的，这两点是和传统卷积操作完全一致的，最大的不同在于多层感知器对局部特征进行了非线性的映射，而传统卷积的方式是线性的。NIN的网络参数配置表4.4所示（原论文并未给出网络参数，表中参数为编者结合网络结构图和CIFAR-100数据集以$3\\times3$卷积为例给出）。 ​ 表4.4 NIN网络参数配置（结合原论文NIN结构和CIFAR-100数据给出） 网络层 输入尺寸 核尺寸 输出尺寸 参数个数 局部全连接层$L_{11}$ $^*$ $32\\times32\\times3$ $(3\\times3)\\times16/1$ $30\\times30\\times16$ $(3\\times3\\times3+1)\\times16$ 全连接层$L_{12}$ $^*$ $30\\times30\\times16$ $16\\times16$ $30\\times30\\times16$ $((16+1)\\times16)$ 局部全连接层$L_{21}$ $30\\times30\\times16$ $(3\\times3)\\times64/1$ $28\\times28\\times64$ $(3\\times3\\times16+1)\\times64$ 全连接层$L_{22}$ $28\\times28\\times64$ $64\\times64$ $28\\times28\\times64$ $((64+1)\\times64)$ 局部全连接层$L_{31}$ $28\\times28\\times64$ $(3\\times3)\\times100/1$ $26\\times26\\times100$ $(3\\times3\\times64+1)\\times100$ 全连接层$L_{32}$ $26\\times26\\times100$ $100\\times100$ $26\\times26\\times100$ $((100+1)\\times100)$ 全局平均采样$GAP$ $^*$ $26\\times26\\times100$ $26\\times26\\times100/1$ $1\\times1\\times100$ $0$ 局部全连接层$L_{11}$实际上是对原始输入图像进行划窗式的全连接操作，因此划窗得到的输出特征尺寸为$30\\times30$（$\\frac{32-3_k+1}{1_{stride}}=30$）全连接层$L_{12}$是紧跟$L_{11}$后的全连接操作，输入的特征是划窗后经过激活的局部响应特征，因此仅需连接$L_{11}$和$L_{12}$的节点即可，而每个局部全连接层和紧接的全连接层构成代替卷积操作的多层感知卷积层（MLPConv）。全局平均采样层或全局平均池化层$GAP$（Global Average Pooling）将$L_{32}$输出的每一个特征图进行全局的平均池化操作，直接得到最后的类别数，可以有效地减少参数量。 模型特点 使用多层感知机结构来代替卷积的滤波操作，不但有效减少卷积核数过多而导致的参数量暴涨问题，还能通过引入非线性的映射来提高模型对特征的抽象能力。 使用全局平均池化来代替最后一个全连接层，能够有效地减少参数量（没有可训练参数），同时池化用到了整个特征图的信息，对空间信息的转换更加鲁棒，最后得到的输出结果可直接作为对应类别的置信度。 VGGNet模型介绍​ VGGNet是由牛津大学视觉几何小组（Visual Geometry Group, VGG）提出的一种深层卷积网络结构，他们以7.32%的错误率赢得了2014年ILSVRC分类任务的亚军（冠军由GoogLeNet以6.65%的错误率夺得）和25.32%的错误率夺得定位任务（Localization）的第一名（GoogLeNet错误率为26.44%）$^{[5]}$，网络名称VGGNet取自该小组名缩写。VGGNet是首批把图像分类的错误率降低到10%以内模型，同时该网络所采用的$3\\times3$卷积核的思想是后来许多模型的基础，该模型发表在2015年国际学习表征会议（International Conference On Learning Representations, ICLR）后至今被引用的次数已经超过1万4千余次。 模型结构 ​ 图 4.7 VGG16网络结构图 ​ 在原论文中的VGGNet包含了6个版本的演进，分别对应VGG11、VGG11-LRN、VGG13、VGG16-1、VGG16-3和VGG19，不同的后缀数值表示不同的网络层数（VGG11-LRN表示在第一层中采用了LRN的VGG11，VGG16-1表示后三组卷积块中最后一层卷积采用卷积核尺寸为$1\\times1$，相应的VGG16-3表示卷积核尺寸为$3\\times3$），本节介绍的VGG16为VGG16-3。图4.7中的VGG16体现了VGGNet的核心思路，使用$3\\times3$的卷积组合代替大尺寸的卷积（2个$3\\times3卷积即可与$$5\\times5$卷积拥有相同的感受视野），网络参数设置如表4.5所示。 ​ 表4.5 VGG16网络参数配置 网络层 输入尺寸 核尺寸 输出尺寸 参数个数 卷积层$C_{11}$ $224\\times224\\times3$ $3\\times3\\times64/1$ $224\\times224\\times64$ $(3\\times3\\times3+1)\\times64$ 卷积层$C_{12}$ $224\\times224\\times64$ $3\\times3\\times64/1$ $224\\times224\\times64$ $(3\\times3\\times64+1)\\times64$ 下采样层$S_{max1}$ $224\\times224\\times64$ $2\\times2/2$ $112\\times112\\times64$ $0$ 卷积层$C_{21}$ $112\\times112\\times64$ $3\\times3\\times128/1$ $112\\times112\\times128$ $(3\\times3\\times64+1)\\times128$ 卷积层$C_{22}$ $112\\times112\\times128$ $3\\times3\\times128/1$ $112\\times112\\times128$ $(3\\times3\\times128+1)\\times128$ 下采样层$S_{max2}$ $112\\times112\\times128$ $2\\times2/2$ $56\\times56\\times128$ $0$ 卷积层$C_{31}$ $56\\times56\\times128$ $3\\times3\\times256/1$ $56\\times56\\times256$ $(3\\times3\\times128+1)\\times256$ 卷积层$C_{32}$ $56\\times56\\times256$ $3\\times3\\times256/1$ $56\\times56\\times256$ $(3\\times3\\times256+1)\\times256$ 卷积层$C_{33}$ $56\\times56\\times256$ $3\\times3\\times256/1$ $56\\times56\\times256$ $(3\\times3\\times256+1)\\times256$ 下采样层$S_{max3}$ $56\\times56\\times256$ $2\\times2/2$ $28\\times28\\times256$ $0$ 卷积层$C_{41}$ $28\\times28\\times256$ $3\\times3\\times512/1$ $28\\times28\\times512$ $(3\\times3\\times256+1)\\times512$ 卷积层$C_{42}$ $28\\times28\\times512$ $3\\times3\\times512/1$ $28\\times28\\times512$ $(3\\times3\\times512+1)\\times512$ 卷积层$C_{43}$ $28\\times28\\times512$ $3\\times3\\times512/1$ $28\\times28\\times512$ $(3\\times3\\times512+1)\\times512$ 下采样层$S_{max4}$ $28\\times28\\times512$ $2\\times2/2$ $14\\times14\\times512$ $0$ 卷积层$C_{51}$ $14\\times14\\times512$ $3\\times3\\times512/1$ $14\\times14\\times512$ $(3\\times3\\times512+1)\\times512$ 卷积层$C_{52}$ $14\\times14\\times512$ $3\\times3\\times512/1$ $14\\times14\\times512$ $(3\\times3\\times512+1)\\times512$ 卷积层$C_{53}$ $14\\times14\\times512$ $3\\times3\\times512/1$ $14\\times14\\times512$ $(3\\times3\\times512+1)\\times512$ 下采样层$S_{max5}$ $14\\times14\\times512$ $2\\times2/2$ $7\\times7\\times512$ $0$ 全连接层$FC_{1}$ $7\\times7\\times512$ $(7\\times7\\times512)\\times4096$ $1\\times4096$ $(7\\times7\\times512+1)\\times4096$ 全连接层$FC_{2}$ $1\\times4096$ $4096\\times4096$ $1\\times4096$ $(4096+1)\\times4096$ 全连接层$FC_{3}$ $1\\times4096$ $4096\\times1000$ $1\\times1000$ $(4096+1)\\times1000$ 模型特性 整个网络都使用了同样大小的卷积核尺寸$3\\times3$和最大池化尺寸$2\\times2$。 $1\\times1$卷积的意义主要在于线性变换，而输入通道数和输出通道数不变，没有发生降维。 两个$3\\times3$的卷积层串联相当于1个$5\\times5$的卷积层，感受野大小为$5\\times5$。同样地，3个$3\\times3$的卷积层串联的效果则相当于1个$7\\times7$的卷积层。这样的连接方式使得网络参数量更小，而且多层的激活函数令网络对特征的学习能力更强。 VGGNet在训练时有一个小技巧，先训练浅层的的简单网络VGG11，再复用VGG11的权重来初始化VGG13，如此反复训练并初始化VGG19，能够使训练时收敛的速度更快。 在训练过程中使用多尺度的变换对原始数据做数据增强，使得模型不易过拟合。 GoogLeNet模型介绍​ GoogLeNet作为2014年ILSVRC在分类任务上的冠军，以6.65%的错误率力压VGGNet等模型，在分类的准确率上面相比过去两届冠军ZFNet和AlexNet都有很大的提升。从名字GoogLeNet可以知道这是来自谷歌工程师所设计的网络结构，而名字中GoogLeNet更是致敬了LeNet$^{[0]}$。GoogLeNet中最核心的部分是其内部子网络结构Inception，该结构灵感来源于NIN，至今已经经历了四次版本迭代（Inception$_{v1-4}$）。 ​ 图 4.8 Inception性能比较图 模型结构​ 图 4.9 GoogLeNet网络结构图​ 如图4.9中所示，GoogLeNet相比于以前的卷积神经网络结构，除了在深度上进行了延伸，还对网络的宽度进行了扩展，整个网络由许多块状子网络的堆叠而成，这个子网络构成了Inception结构。图4.9为Inception的四个版本：$Inception_{v1}​$在同一层中采用不同的卷积核，并对卷积结果进行合并;$Inception_{v2}​$组合不同卷积核的堆叠形式，并对卷积结果进行合并;$Inception_{v3}​$则在$v_2​$基础上进行深度组合的尝试;$Inception_{v4}​$结构相比于前面的版本更加复杂，子网络中嵌套着子网络。 $Inception_{v1}$ $Inception_{v2}$ $Inception_{v3}$ $Inception_{v4}$ ​ 图 4.10 Inception$_{v1-4}$结构图 ​ 表 4.6 GoogLeNet中Inception$_{v1}$网络参数配置 网络层 输入尺寸 核尺寸 输出尺寸 参数个数 卷积层$C_{11}$ $H\\times{W}\\times{C_1}$ $1\\times1\\times{C_2}/2$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $(1\\times1\\times{C_1}+1)\\times{C_2}$ 卷积层$C_{21}$ $H\\times{W}\\times{C_2}$ $1\\times1\\times{C_2}/2$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $(1\\times1\\times{C_2}+1)\\times{C_2}$ 卷积层$C_{22}$ $H\\times{W}\\times{C_2}$ $3\\times3\\times{C_2}/1$ $H\\times{W}\\times{C_2}/1$ $(3\\times3\\times{C_2}+1)\\times{C_2}$ 卷积层$C_{31}$ $H\\times{W}\\times{C_1}$ $1\\times1\\times{C_2}/2$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $(1\\times1\\times{C_1}+1)\\times{C_2}$ 卷积层$C_{32}$ $H\\times{W}\\times{C_2}$ $5\\times5\\times{C_2}/1$ $H\\times{W}\\times{C_2}/1$ $(5\\times5\\times{C_2}+1)\\times{C_2}$ 下采样层$S_{41}$ $H\\times{W}\\times{C_1}$ $3\\times3/2$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $0$ 卷积层$C_{42}$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $1\\times1\\times{C_2}/1$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $(3\\times3\\times{C_2}+1)\\times{C_2}$ 合并层$M$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}(\\times4)$ 拼接 $\\frac{H}{2}\\times\\frac{W}{2}\\times({C_2}\\times4)$ $0$ 模型特性 采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合； 之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了； 网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。但是，使用5x5的卷积核仍然会带来巨大的计算量。 为此，文章借鉴NIN2，采用1x1卷积核来进行降维。 为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？ 评测对比：为了让自己的结果更有说服力，在发表自己成果的时候会同一个标准的baseline及在baseline上改进而进行比较，常见的比如各种检测分割的问题都会基于VGG或者Resnet101这样的基础网络。 时间和精力有限：在科研压力和工作压力中，时间和精力只允许大家在有限的范围探索。 模型创新难度大：进行基本模型的改进需要大量的实验和尝试，并且需要大量的实验积累和强大灵感，很有可能投入产出比比较小。 资源限制：创造一个新的模型需要大量的时间和计算资源，往往在学校和小型商业团队不可行。 在实际的应用场景中，其实是有大量的非标准模型的配置。 参考文献[1] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, november 1998. [2] A. Krizhevsky, I. Sutskever and G. E. Hinton. ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems 25. Curran Associates, Inc. 1097–1105. [3] LSVRC-2013. http://www.image-net.org/challenges/LSVRC/2013/results.php [4] M. D. Zeiler and R. Fergus. Visualizing and Understanding Convolutional Networks. European Conference on Computer Vision. [5] M. Lin, Q. Chen, and S. Yan. Network in network. Computing Research Repository, abs/1312.4400, 2013. [6] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale Image Recognition. International Conference on Machine Learning, 2015. [7] Bharath Raj. a-simple-guide-to-the-versions-of-the-inception-network, 2018. [8] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi. Inception-v4, Inception-ResNet andthe Impact of Residual Connections on Learning, 2016. [9] Sik-Ho Tsang. review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification, 2018. [10] Zbigniew Wojna, Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens. Rethinking the Inception Architecture for Computer Vision, 2015. [11] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. Going deeper with convolutions, 2014.","link":"/2019/10/28/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E8%A7%A3%E8%AF%BB/"},{"title":"生成对抗网络（GAN）","text":"GAN基本概念如何通俗理解GAN？​ 生成对抗网络(GAN, Generative adversarial network)自从2014年被Ian Goodfellow提出以来，掀起来了一股研究热潮。GAN由生成器和判别器组成，生成器负责生成样本，判别器负责判断生成器生成的样本是否为真。生成器要尽可能迷惑判别器，而判别器要尽可能区分生成器生成的样本和真实样本。 ​ 在GAN的原作[1]中，作者将生成器比喻为印假钞票的犯罪分子，判别器则类比为警察。犯罪分子努力让钞票看起来逼真，警察则不断提升对于假钞的辨识能力。二者互相博弈，随着时间的进行，都会越来越强。那么类比于图像生成任务，生成器不断生成尽可能逼真的假图像。判别器则判断图像是否是真实的图像，还是生成的图像，二者不断博弈优化。最终生成器生成的图像使得判别器完全无法判别真假。 GAN的形式化表达​ 上述例子只是简要介绍了一下GAN的思想，下面对于GAN做一个形式化的，更加具体的定义。通常情况下，无论是生成器还是判别器，我们都可以用神经网络来实现。那么，我们可以把通俗化的定义用下面这个模型来表示： ​ 上述模型左边是生成器G，其输入是$z$，对于原始的GAN，$z$是由高斯分布随机采样得到的噪声。噪声$z$通过生成器得到了生成的假样本。 ​ 生成的假样本与真实样本放到一起，被随机抽取送入到判别器D，由判别器去区分输入的样本是生成的假样本还是真实的样本。整个过程简单明了，生成对抗网络中的“生成对抗”主要体现在生成器和判别器之间的对抗。 GAN的目标函数是什么？​ 对于上述神经网络模型，如果想要学习其参数，首先需要一个目标函数。GAN的目标函数定义如下：$$ \\mathop {\\min }\\limits_G \\mathop {\\max }\\limits_D V(D,G) = {\\rm E}{x\\sim{p{data}(x)}}[\\log D(x)] + {\\rm E}_{z\\sim{p_z}(z)}[\\log (1 - D(G(z)))] $$​ 这个目标函数可以分为两个部分来理解： ​ 第一部分：判别器的优化通过$\\mathop {\\max}\\limits_D V(D,G)$实现，$V(D,G)$为判别器的目标函数，其第一项${\\rm E}{x\\sim{p{data}(x)}}[\\log D(x)]$表示对于从真实数据分布 中采用的样本 ,其被判别器判定为真实样本概率的数学期望。对于真实数据分布 中采样的样本，其预测为正样本的概率当然是越接近1越好。因此希望最大化这一项。第二项${\\rm E}_{z\\sim{p_z}(z)}[\\log (1 - D(G(z)))]$表示：对于从噪声$P_z(z)​$分布当中采样得到的样本，经过生成器生成之后得到的生成图片，然后送入判别器，其预测概率的负对数的期望，这个值自然是越大越好，这个值越大， 越接近0，也就代表判别器越好。 ​ 第二部分：生成器的优化通过$\\mathop {\\min }\\limits_G({\\mathop {\\max }\\limits_D V(D,G)})$来实现。注意，生成器的目标不是$\\mathop {\\min }\\limits_GV(D,G)$，即生成器不是最小化判别器的目标函数，二是最小化判别器目标函数的最大值，判别器目标函数的最大值代表的是真实数据分布与生成数据分布的JS散度(详情可以参阅附录的推导)，JS散度可以度量分布的相似性，两个分布越接近，JS散度越小。 GAN的目标函数和交叉熵有什么区别？​ 判别器目标函数写成离散形式即为:$$V(D,G)=-\\frac{1}{m}\\sum_{i=1}^{i=m}logD(x^i)-\\frac{1}{m}\\sum_{i=1}^{i=m}log(1-D(\\tilde{x}^i))$$ ​ 可以看出，这个目标函数和交叉熵是一致的，即判别器的目标是最小化交叉熵损失，生成器的目标是最小化生成数据分布和真实数据分布的JS散度。 [1]: Goodfellow, Ian, et al. “Generative adversarial nets.” Advances in neural information processing systems. 2014. GAN的Loss为什么降不下去？​ 对于很多GAN的初学者在实践过程中可能会纳闷，为什么GAN的Loss一直降不下去。GAN到底什么时候才算收敛？其实，作为一个训练良好的GAN，其Loss就是降不下去的。衡量GAN是否训练好了，只能由人肉眼去看生成的图片质量是否好。不过，对于没有一个很好的评价是否收敛指标的问题，也有许多学者做了一些研究，后文提及的WGAN就提出了一种新的Loss设计方式，较好的解决了难以判断收敛性的问题。下面我们分析一下GAN的Loss为什么降不下去？​ 对于判别器而言，GAN的Loss如下：$$ \\mathop {\\min }\\limits_G \\mathop {\\max }\\limits_D V(D,G) = {\\rm E}{x\\sim{p{data}(x)}}[\\log D(x)] + {\\rm E}_{z\\sim{p_z}(z)}[\\log (1 - D(G(z)))] $$​​ 从$\\mathop {\\min }\\limits_G \\mathop {\\max }\\limits_D V(D,G)​$可以看出，生成器和判别器的目的相反，也就是说两个生成器网络和判别器网络互为对抗，此消彼长。不可能Loss一直降到一个收敛的状态。 对于生成器，其Loss下降快，很有可能是判别器太弱，导致生成器很轻易的就”愚弄”了判别器。 对于判别器，其Loss下降快，意味着判别器很强，判别器很强则说明生成器生成的图像不够逼真，才使得判别器轻易判别，导致Loss下降很快。 ​ 也就是说，无论是判别器，还是生成器。loss的高低不能代表生成器的好坏。一个好的GAN网络，其GAN Loss往往是不断波动的。 ​ 看到这里可能有点让人绝望，似乎判断模型是否收敛就只能看生成的图像质量了。实际上，后文探讨的WGAN，提出了一种新的loss度量方式，让我们可以通过一定的手段来判断模型是否收敛。 生成式模型、判别式模型的区别？​ 对于机器学习模型，我们可以根据模型对数据的建模方式将模型分为两大类，生成式模型和判别式模型。如果我们要训练一个关于猫狗分类的模型，对于判别式模型，只需要学习二者差异即可。比如说猫的体型会比狗小一点。而生成式模型则不一样，需要学习猫张什么样，狗张什么样。有了二者的长相以后，再根据长相去区分。具体而言： 生成式模型：由数据学习联合概率分布P(X,Y), 然后由P(Y|X)=P(X,Y)/P(X)求出概率分布P(Y|X)作为预测的模型。该方法表示了给定输入X与产生输出Y的生成关系 判别式模型：由数据直接学习决策函数Y=f(X)或条件概率分布P(Y|X)作为预测模型，即判别模型。判别方法关心的是对于给定的输入X，应该预测什么样的输出Y。 ​ 对于上述两种模型，从文字上理解起来似乎不太直观。我们举个例子来阐述一下，对于性别分类问题，分别用不同的模型来做： ​ 1）如果用生成式模型：可以训练一个模型，学习输入人的特征X和性别Y的关系。比如现在有下面一批数据： Y（性别） 0 1 X（特征） 0 1/4 3/4 1 3/4 1/4 ​ 这个数据可以统计得到，即统计人的特征X=0,1….的时候，其类别为Y=0,1的概率。统计得到上述联合概率分布P(X, Y)后，可以学习一个模型，比如让二维高斯分布去拟合上述数据，这样就学习到了X，Y的联合分布。在预测时，如果我们希望给一个输入特征X，预测其类别，则需要通过贝叶斯公式得到条件概率分布才能进行推断：$$P(Y|X)={\\frac{P(X,Y)}{P(X)}}={\\frac{P(X,Y)}{P(X|Y)P(Y)}}$$​ 2）如果用判别式模型：可以训练一个模型，输入人的特征X，这些特征包括人的五官，穿衣风格，发型等。输出则是对于性别的判断概率，这个概率服从一个分布，分布的取值只有两个，要么男，要么女，记这个分布为Y。这个过程学习了一个条件概率分布P(Y|X)，即输入特征X的分布已知条件下，Y的概率分布。 ​ 显然，从上面的分析可以看出。判别式模型似乎要方便很多，因为生成式模型要学习一个X，Y的联合分布往往需要很多数据，而判别式模型需要的数据则相对少，因为判别式模型更关注输入特征的差异性。不过生成式既然使用了更多数据来生成联合分布，自然也能够提供更多的信息，现在有一个样本（X,Y）,其联合概率P（X,Y）经过计算特别小，那么可以认为这个样本是异常样本。这种模型可以用来做outlier detection。 什么是mode collapsing?​ 某个模式(mode)出现大量重复样本，例如：​ 上图左侧的蓝色五角星表示真实样本空间，黄色的是生成的。生成样本缺乏多样性，存在大量重复。比如上图右侧中，红框里面人物反复出现。 如何解决mode collapsing？方法一：针对目标函数的改进方法 ​ 为了避免前面提到的由于优化maxmin导致mode跳来跳去的问题，UnrolledGAN采用修改生成器loss来解决。具体而言，UnrolledGAN在更新生成器时更新k次生成器，参考的Loss不是某一次的loss，是判别器后面k次迭代的loss。注意，判别器后面k次迭代不更新自己的参数，只计算loss用于更新生成器。这种方式使得生成器考虑到了后面k次判别器的变化情况，避免在不同mode之间切换导致的模式崩溃问题。此处务必和迭代k次生成器，然后迭代1次判别器区分开[8]。DRAGAN则引入博弈论中的无后悔算法，改造其loss以解决mode collapse问题[9]。前文所述的EBGAN则是加入VAE的重构误差以解决mode collapse。 方法二：针对网络结构的改进方法 ​ Multi agent diverse GAN(MAD-GAN)采用多个生成器，一个判别器以保障样本生成的多样性。具体结构如下： ​ 相比于普通GAN，多了几个生成器，且在loss设计的时候，加入一个正则项。正则项使用余弦距离惩罚三个生成器生成样本的一致性。 ​ MRGAN则添加了一个判别器来惩罚生成样本的mode collapse问题。具体结构如下： ​ 输入样本$x​$通过一个Encoder编码为隐变量$E(x)​$，然后隐变量被Generator重构，训练时，Loss有三个。$D_M​$和$R​$（重构误差）用于指导生成real-like的样本。而$D_D​$则对$E(x)​$和$z​$生成的样本进行判别，显然二者生成样本都是fake samples，所以这个判别器主要用于判断生成的样本是否具有多样性，即是否出现mode collapse。 方法三：Mini-batch Discrimination ​ Mini-batch discrimination在判别器的中间层建立一个mini-batch layer用于计算基于L1距离的样本统计量，通过建立该统计量，实现了一个batch内某个样本与其他样本有多接近。这个信息可以被判别器利用到，从而甄别出哪些缺乏多样性的样本。对生成器而言，则要试图生成具有多样性的样本。 GAN的生成能力评价如何客观评价GAN的生成能力？​ 最常见评价GAN的方法就是主观评价。主观评价需要花费大量人力物力，且存在以下问题： 评价带有主管色彩，有些bad case没看到很容易造成误判 如果一个GAN过拟合了，那么生成的样本会非常真实，人类主观评价得分会非常高，可是这并不是一个好的GAN。 因此，就有许多学者提出了GAN的客观评价方法。 Inception Score​ 对于一个在ImageNet训练良好的GAN，其生成的样本丢给Inception网络进行测试的时候，得到的判别概率应该具有如下特性： 对于同一个类别的图片，其输出的概率分布应该趋向于一个脉冲分布。可以保证生成样本的准确性。 对于所有类别，其输出的概率分布应该趋向于一个均匀分布，这样才不会出现mode dropping等，可以保证生成样本的多样性。 ​ 因此，可以设计如下指标：$$IS(P_g)=e^{E_{x\\sim P_g}[KL(p_M(y|x)\\Vert{p_M(y)})]}$$​ 根据前面分析，如果是一个训练良好的GAN，$p_M(y|x)$趋近于脉冲分布，$p_M(y)$趋近于均匀分布。二者KL散度会很大。Inception Score自然就高。实际实验表明，Inception Score和人的主观判别趋向一致。IS的计算没有用到真实数据，具体值取决于模型M的选择。 ​ 特点：可以一定程度上衡量生成样本的多样性和准确性，但是无法检测过拟合。Mode Score也是如此。不推荐在和ImageNet数据集差别比较大的数据上使用。 Mode Score​ Mode Score作为Inception Score的改进版本，添加了关于生成样本和真实样本预测的概率分布相似性度量一项。具体公式如下：$$MS(P_g)=e^{E_{x\\sim P_g}[KL(p_M(y|x)\\Vert{p_M(y)})-KL(p_M(y)\\Vert p_M(y^*))]}$$ Kernel MMD (Maximum Mean Discrepancy)计算公式如下：$$MMD^2(P_r,P_g)=E_{x_r\\sim{P_r},x_g\\sim{P_g}}[\\lVert\\Sigma_{i=1}^{n1}k(x_r)-\\Sigma_{i=1}^{n2}k(x_g)\\rVert]$$​ 对于Kernel MMD值的计算，首先需要选择一个核函数$k$，这个核函数把样本映射到再生希尔伯特空间(Reproducing Kernel Hilbert Space, RKHS) ，RKHS相比于欧几里得空间有许多优点，对于函数内积的计算是完备的。将上述公式展开即可得到下面的计算公式：$$MMD^2(P_r,P_g)=E_{x_r,x_r{‘}\\sim{P_r},x_g,x_g{‘}\\sim{P_g}}[k(x_r,x_r{‘})-2k(x_r,x_g)+k(x_g,x_g{‘})]$$MMD值越小，两个分布越接近。 特点：可以一定程度上衡量模型生成图像的优劣性，计算代价小。推荐使用。 Wasserstein distance​ Wasserstein distance在最优传输问题中通常也叫做推土机距离。这个距离的介绍在WGAN中有详细讨论。公式如下：$$WD(P_r,P_g)=min_{\\omega\\in\\mathbb{R}^{m\\times n}}\\Sigma_{i=1}^n\\Sigma_{i=1}^m\\omega_{ij}d(x_i^r,x_j^g)$$ $$s.t. \\Sigma_{i=1}^mw_{i,j}=p_r(x_i^r), \\forall i;\\Sigma_{j=1}^nw_{i,j}=p_g(x_j^g), \\forall j$$ ​ Wasserstein distance可以衡量两个分布之间的相似性。距离越小，分布越相似。 特点：如果特征空间选择合适，会有一定的效果。但是计算复杂度为$O(n^3)​$太高 Fréchet Inception Distance (FID)​ FID距离计算真实样本，生成样本在特征空间之间的距离。首先利用Inception网络来提取特征，然后使用高斯模型对特征空间进行建模。根据高斯模型的均值和协方差来进行距离计算。具体公式如下：$$FID(\\mathbb P_r,\\mathbb P_g)=\\lVert\\mu_r-\\mu_g\\rVert+Tr(C_r+C_g-2(C_rC_g)^{1/2})$$$\\mu,C​$分别代表协方差和均值。 ​ 特点：尽管只计算了特征空间的前两阶矩，但是鲁棒，且计算高效。 Nearest Neighbor classifier​ 使用留一法，结合1-NN分类器（别的也行）计算真实图片，生成图像的精度。如果二者接近，则精度接近50%，否则接近0%。对于GAN的评价问题，作者分别用正样本的分类精度，生成样本的分类精度去衡量生成样本的真实性，多样性。 对于真实样本$x_r$，进行1-NN分类的时候，如果生成的样本越真实。则真实样本空间$\\mathbb R$将被生成的样本$x_g$包围。那么$x_r$的精度会很低。 对于生成的样本$x_g​$，进行1-NN分类的时候，如果生成的样本多样性不足。由于生成的样本聚在几个mode，则$x_g​$很容易就和$x_r​$区分，导致精度会很高。 特点：理想的度量指标，且可以检测过拟合。 其他评价方法​ AIS，KDE方法也可以用于评价GAN，但这些方法不是model agnostic metrics。也就是说，这些评价指标的计算无法只利用：生成的样本，真实样本来计算。 其他常见的生成式模型有哪些？什么是自回归模型：pixelRNN与pixelCNN？​ 自回归模型通过对图像数据的概率分布$p_{data}(x)$进行显式建模，并利用极大似然估计优化模型。具体如下：$$p_{data}(x)=\\prod_{i=1}^np(x_i|x_1,x_2,…,x_{i-1})$$​ 上述公式很好理解，给定$x_1,x_2,…,x_{i-1}$条件下，所有$p(x_i)$的概率乘起来就是图像数据的分布。如果使用RNN对上述依然关系建模，就是pixelRNN。如果使用CNN，则是pixelCNN。具体如下[5]： ​ 显然，不论是对于pixelCNN还是pixelRNN，由于其像素值是一个个生成的，速度会很慢。语音领域大火的WaveNet就是一个典型的自回归模型。 什么是VAE？​ PixelCNN/RNN定义了一个易于处理的密度函数，我们可以直接优化训练数据的似然；对于变分自编码器我们将定义一个不易处理的密度函数，通过附加的隐变量$z$对密度函数进行建模。 VAE原理图如下[6]： ​ 在VAE中，真实样本$X$通过神经网络计算出均值方差（假设隐变量服从正太分布），然后通过采样得到采样变量$Z$并进行重构。VAE和GAN均是学习了隐变量$z$到真实数据分布的映射。但是和GAN不同的是： GAN的思路比较粗暴，使用一个判别器去度量分布转换模块（即生成器）生成分布与真实数据分布的距离。 VAE则没有那么直观，VAE通过约束隐变量$z$服从标准正太分布以及重构数据实现了分布转换映射$X=G(z)$ 生成式模型对比 自回归模型通过对概率分布显式建模来生成数据 VAE和GAN均是：假设隐变量$z$服从某种分布，并学习一个映射$X=G(z)$，实现隐变量分布$z$与真实数据分布$p_{data}(x)$的转换。 GAN使用判别器去度量映射$X=G(z)$的优劣，而VAE通过隐变量$z$与标准正太分布的KL散度和重构误差去度量。 GAN的改进与优化如何生成指定类型的图像——条件GAN​ 条件生成对抗网络（CGAN, Conditional Generative Adversarial Networks）作为一个GAN的改进，其一定程度上解决了GAN生成结果的不确定性。如果在Mnist数据集上训练原始GAN，GAN生成的图像是完全不确定的，具体生成的是数字1，还是2，还是几，根本不可控。为了让生成的数字可控，我们可以把数据集做一个切分，把数字0~9的数据集分别拆分开训练9个模型，不过这样太麻烦了，也不现实。因为数据集拆分不仅仅是分类麻烦，更主要在于，每一个类别的样本少，拿去训练GAN很有可能导致欠拟合。因此，CGAN就应运而生了。我们先看一下CGAN的网络结构：​ 从网络结构图可以看到，对于生成器Generator，其输入不仅仅是随机噪声的采样z，还有欲生成图像的标签信息。比如对于mnist数据生成，就是一个one-hot向量，某一维度为1则表示生成某个数字的图片。同样地，判别器的输入也包括样本的标签。这样就使得判别器和生成器可以学习到样本和标签之间的联系。Loss如下：$$ \\mathop {\\min }\\limits_G \\mathop {\\max }\\limits_D V(D,G) = {\\rm E}{x\\sim{p{data}(x)}}[\\log D(x|y)] + {\\rm E}_{z\\sim{p_z}(z)}[\\log (1 - D(G(z|y)))] $$​ Loss设计和原始GAN基本一致，只不过生成器，判别器的输入数据是一个条件分布。在具体编程实现时只需要对随机噪声采样z和输入条件y做一个级联即可。 CNN与GAN——DCGAN​ 前面我们聊的GAN都是基于简单的神经网络\b构建的。可是对于视觉问题，如果使用原始的基于DNN的GAN，则会出现许多问题。如果输入GAN的随机噪声为100维的随机噪声，输出图像为256x256大小。也就是说，要将100维的信息映射为65536维。如果单纯用DNN来实现，\b那么整个模型参数会非常巨大，而且学习难度很大（低维度映射到高维度需要添加许多信息）。因此，DCGAN就出现了。具体而言，DCGAN将传统GAN的生成器，判别器均采用GAN实现，且使用了一下tricks： 将pooling层convolutions替代，其中，在discriminator上用strided convolutions替代，在generator上用fractional-strided convolutions替代。 在generator和discriminator上都使用batchnorm。 移除全连接层，global pooling增加了模型的稳定性，但伤害了收敛速度。 在generator的除了输出层外的所有层使用ReLU，输出层采用tanh。 在discriminator的所有层上使用LeakyReLU。 网络结构图如下： 如何理解GAN中的输入随机噪声？​ 为了了解输入随机噪声每一个维度代表的含义，作者做了一个非常有趣的工作。即在隐空间上，假设知道哪几个变量控制着某个物体，那么僵这几个变量挡住是不是就可以将生成图片中的某个物体消失？论文中的实验是这样的：首先，生成150张图片，包括有窗户的和没有窗户的，然后使用一个逻辑斯底回归函数来进行分类，对于权重不为0的特征，认为它和窗户有关。将其挡住，得到新的生成图片，结果如下：此外，将几个输入噪声进行算数运算，\b可以得到语义上进行算数运算的非常有趣的结果。类似于word2vec。 GAN为什么容易训练崩溃？​ 所谓GAN的训练崩溃，指的是训练过程中，生成器和判别器存在一方压倒另一方的情况。GAN原始判别器的Loss在判别器达到最优的时候，等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；\b可是如果不把判别器训练到最优，那么生成器优化的目标就失去了意义。因此需要我们小心的平衡二者，要把判别器训练的不好也不坏才行。否则就会出现训练崩溃，得不到想要的结果 WGAN如何解决训练崩溃问题？​ WGAN作者提出了使用Wasserstein距离，以解决GAN网络训练过程难以判断收敛性的问题。Wasserstein距离定义如下:$$ L={\\rm E}{x\\sim{p{data}}(x)}[f_w(x)] - {\\rm E}_{x\\sim{p_g}(x)}[f_w(x)] $$通过最小化Wasserstein距离，得到了WGAN的Loss： WGAN生成器Loss：$- {\\rm E}_{x\\sim{p_g}(x)}[f_w(x)]​$ WGAN判别器Loss：$L=-{\\rm E}{x\\sim{p{data}}(x)}[f_w(x)] + {\\rm E}_{x\\sim{p_g}(x)}[f_w(x)]$ 从公式上GAN似乎总是让人摸不着头脑，在代码实现上来说，其实就以下几点： 判别器最后一层去掉sigmoid 生成器和判别器的loss不取log 每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c WGAN-GP：带有梯度正则的WGAN​ 实际实验过程发现，WGAN没有那么好用，主要原因在于WAGN进行梯度截断。梯度截断将导致判别网络趋向于一个二值网络，造成模型容量的下降。于是作者提出使用梯度惩罚来替代梯度裁剪。公式如下：由于上式是对每一个梯度进行惩罚，所以不适合使用BN，因为它会引入同个batch中不同样本的相互依赖关系。如果需要的话，可以选择Layer Normalization。实际训练过程中，就可以通过Wasserstein距离来度量模型收敛程度了：上图纵坐标是Wasserstein距离，横坐标是迭代次数。可以看出，随着迭代的进行，Wasserstein距离趋于收敛，生成图像也趋于稳定。 ​ 由于上式是对每一个梯度进行惩罚，所以不适合使用BN，因为它会引入同个batch中不同样本的相互依赖关系。如果需要的话，可以选择Layer Normalization。实际训练过程中，就可以通过Wasserstein距离来度量模型收敛程度了：​ 上图纵坐标是Wasserstein距离，横坐标是迭代次数。可以看出，随着迭代的进行，Wasserstein距离趋于收敛，生成图像也趋于稳定。 LSGAN​ LSGAN（Least Squares GAN）这篇文章主要针对标准GAN的稳定性和图片生成质量不高做了一个改进。作者将原始GAN的交叉熵损失采用最小二乘损失替代。LSGAN的Loss：$$ \\mathop{\\min }\\limits_DJ(D)=\\mathop{\\min}\\limits_D[{\\frac{1}{2}}{\\rm E}{x\\sim{p{data}}(x)}[D(x)-a]^2 + {\\frac{1}{2}}{\\rm E}_{z\\sim{p_z}(z)}[D(G(z))-b]^2] $$ $$\\mathop{\\min }\\limits_GJ(G)=\\mathop{\\min}\\limits_G{\\frac{1}{2}}{\\rm E}_{z\\sim{p_z}(z)}[D(G(z))-c]^2$$ ​ 实际实现的时候非常简单，最后一层去掉sigmoid，并且计算Loss的时候用平方误差即可。之所以这么做，作者在原文给出了一张图:![LSGAN交叉熵与最小二乘损失对比图](./img/ch7/lsgan loss compare.png)​ 上面是作者给出的基于交叉熵损失以及最小二乘损失的Loss函数。横坐标代表Loss函数的输入，纵坐标代表输出的Loss值。可以看出，随着输入的增大，sigmoid交叉熵损失很快趋于0，容易导致梯度饱和问题。如果使用右边的Loss设计，则只在x=0点处饱和。因此使用LSGAN可以很好的解决交叉熵损失的问题。 如何尽量避免GAN的训练崩溃问题？ 归一化图像输入到（-1，1）之间；Generator最后一层使用tanh激活函数 生成器的Loss采用：min (log 1-D)。因为原始的生成器Loss存在梯度消失问题；训练生成器的时候，考虑反转标签，real=fake, fake=real 不要在均匀分布上采样，应该在高斯分布上采样 一个Mini-batch里面必须只有正样本，或者负样本。不要混在一起；如果用不了Batch Norm，可以用Instance Norm 避免稀疏梯度，即少用ReLU，MaxPool。可以用LeakyReLU替代ReLU，下采样可以用Average Pooling或者Convolution + stride替代。上采样可以用PixelShuffle, ConvTranspose2d + stride 平滑标签或者给标签加噪声；平滑标签，即对于正样本，可以使用0.7-1.2的随机数替代；对于负样本，可以使用0-0.3的随机数替代。 给标签加噪声：即训练判别器的时候，随机翻转部分样本的标签。 如果可以，请用DCGAN或者混合模型：KL+GAN，VAE+GAN。 使用LSGAN，WGAN-GP Generator使用Adam，Discriminator使用SGD 尽快发现错误；比如：判别器Loss为0，说明训练失败了；如果生成器Loss稳步下降，说明判别器没发挥作用 不要试着通过比较生成器，判别器Loss的大小来解决训练过程中的模型坍塌问题。比如：While Loss D &gt; Loss A:Train DWhile Loss A &gt; Loss D:Train A 如果有标签，请尽量利用标签信息来训练 给判别器的输入加一些噪声，给G的每一层加一些人工噪声。 多训练判别器，尤其是加了噪声的时候 对于生成器，在训练，测试的时候使用Dropout GAN的应用（图像翻译）什么是图像翻译？​ GAN作为一种强有力的生成模型，其应用十分广泛。最为常见的应用就是图像翻译。所谓图像翻译，指从一副图像到另一副图像的转换。可以类比机器翻译，一种语言转换为另一种语言。常见的图像翻译任务有： 图像去噪 图像超分辨 图像补全 风格迁移 … 本节将介绍一个经典的图像翻译网络及其改进。图像翻译可以分为有监督图像翻译和\b无监督图像翻译： 有监督图像翻译：原始\b域与目标域存在一一对应数据 无监督图像翻译：原始\b域与目标域不存在一一对应数据 有监督图像翻译：pix2pix​ 在这篇paper里面，作者提出的框架十分简洁优雅（好用的算法总是简洁优雅的）。相比以往算法的大量专家知识，手工复杂的loss。这篇paper非常粗暴，使用CGAN处理了一系列的转换问题。下面是一些转换示例： ​ 上面展示了许多有趣的结果，比如分割图$\\longrightarrow$街景图，边缘图$\\longrightarrow$真实图。对于第一次看到的时候还是很惊艳的，那么这个是怎么做到的呢？我们可以设想一下，如果是我们，我们自己会如何设计这个网络？ 直观的想法？ ​ 最直接的想法就是，设计一个CNN网络，直接建立输入-输出的映射，就像图像去噪问题一样。可是对于上面的问题，这样做会带来一个问题。生成图像质量不清晰。 ​ 拿左上角的分割图$\\longrightarrow$街景图为例，语义分割图的每个标签比如“汽车”可能对应不同样式，颜色的汽车。那么模型学习到的会是所有不同汽车的评均，这样会造成模糊。 如何解决生成图像的模糊问题？ ​ 这里作者想了一个办法，即加入GAN的Loss去惩罚模型。GAN相比于传统生成式模型可以较好的生成高分辨率图片。思路也很简单，在上述直观想法的基础上加入一个判别器，判断输入图片是否是真实样本。模型示意图如下： ​ 上图模型和CGAN有所不同，但它是一个CGAN，只不过输入只有一个，这个输入就是条件信息。原始的CGAN需要输入随机噪声，以及条件。这里之所有没有输入噪声信息，是因为在实际实验中，如果输入噪声和条件，噪声往往被淹没在条件C当中，所以这里直接省去了。 其他图像翻译的tricks从上面两点可以得到最终的Loss由两部分构成： 输出和标签信息的L1 Loss。 GAN Loss 测试也使用Dropout，以使输出多样化$$G^*=arg\\mathop {\\min }\\limits_G \\mathop {\\max }\\limits_D \\Gamma_{cGAN}(G,D)+\\lambda\\Gamma_{L1}(G)$$ ​ 采用L1 Loss而不是L2 Loss的理由很简单，L1 Loss相比于L2 Loss保边缘（L2 Loss基于高斯先验，L1 Loss基于拉普拉斯先验）。 ​ GAN Loss为LSGAN的最小二乘Loss，并使用PatchGAN(进一步保证生成图像的清晰度)。PatchGAN将图像换分成很多个Patch，并对每一个Patch使用判别器进行判别（实际代码实现有更取巧的办法），将所有Patch的Loss求平均作为最终的Loss。 如何生成高分辨率图像和高分辨率视频？​ pix2pix提出了一个通用的图像翻译框架。对于高分辨率的图像生成以及高分辨率的视频生成，则需要利用更好的网络结构以及更多的先验只是。pix2pixHD提出了一种多尺度的生成器以及判别器等方式从而生成高分辨率图像。Vid2Vid则在pix2pixHD的基础上利用光流，时序约束生成了高分辨率视频。 有监督的图像翻译的缺点？​ 许多图像翻译算法如前面提及的pix2pix系列，需要一一对应的图像。可是在许多应用场景下，往往没有这种一一对应的强监督信息。比如说以下一些应用场景：以第一排第一幅图为例，要找到这种一一配对的数据是不现实的。因此，无监督图像翻译算法就被引入了。 无监督图像翻译：CycleGAN模型结构 ​ 总体思路如下，假设有两个域的数据，记为A，B。对于上图第一排第一幅图A域就是普通的马，B域就是斑马。由于A-&gt;B的转换缺乏监督信息，于是，作者提出采用如下方法进行转换： a. A-&gt;fake_B-&gt;rec_Ab. B-&gt;fake_A-&gt;rec_B ​ 对于A域的所有图像，学习一个网络G_B，该网络可以生成B。对于B域的所有图像，也学习一个网络G_A，该网络可以生成G_B。 ​ 训练过程分成两步，首先对于A域的某张图像，送入G_B生成fake_B，然后对fake_B送入G_A，得到重构后的A图像rec_A。对于B域的某一张图像也是类似。重构后的图像rec_A/rec_B可以和原图A/B做均方误差，实现了有监督的训练。此处值得注意的是A-&gt;fake_B(B-&gt;fake_A)和fake_A-&gt;rec_B(fake_B-&gt;rec_A)的网络是一模一样的。下图是形象化的网络结构图：​ cycleGAN的生成器采用U-Net，判别器采用LS-GAN。 Loss设计 ​ 总的Loss就是X域和Y域的GAN Loss，以及Cycle consistency loss：$$L(G,F,D_X,D_Y)=L_{GAN}(G,D_Y,X,Y)+L_{GAN}(F,D_X,Y,X)+\\lambda L_{cycle}(G,F)$$整个过程End to end训练，效果非常惊艳，利用这一框架可以完成非常多有趣的任务 多领域的无监督图像翻译：StarGANcycleGAN模型较好的解决了无监督图像转换问题，可是这种单一域的图像转换还存在一些问题： 要针对每一个域训练一个模型，效率太低。举例来说，我希望可以将橘子转换为红苹果和青苹果。对于cycleGAN而言，需要针对红苹果，青苹果分别训练一个模型。 对于每一个域都需要搜集大量数据，太麻烦。还是以橘子转换为红苹果和青苹果为例。不管是红苹果还是青苹果，都是苹果，只是颜色不一样而已。这两个任务信息是可以共享的，没必要分别训练两个模型。而且针对红苹果，青苹果分别取搜集大量数据太费事。 starGAN则提出了一个多领域的无监督图像翻译框架，实现了多个领域的图像转换，且对于不同领域的数据可以混合在一起训练，提高了数据利用率 GAN的应用（文本生成）GAN为什么不适合文本任务？​ GAN在2014年被提出之后，在图像生成领域取得了广泛的研究应用。然后在文本领域却一直没有很惊艳的效果。主要在于文本数据是离散数据，而GAN在应用于离散数据时存在以下几个问题： GAN的生成器梯度来源于判别器对于正负样本的判别。然而，对于文本生成问题，RNN输出的是一个概率序列，然后取argmax。这会导致生成器Loss不可导。还可以站在另一个角度理解，由于是argmax，所以参数更新一点点并不会改变argmax的结果，这也使得GAN不适合离散数据。 GAN只能评估整个序列的loss，但是无法评估半句话，或者是当前生成单词对后续结果好坏的影响。 如果不加argmax，那么由于生成器生成的都是浮点数值，而ground truth都是one-hot encoding，那么判别器只要判别生成的结果是不是0/1序列组成的就可以了。这容易导致训练崩溃。 seqGAN用于文本生成​ seqGAN在GAN的框架下，结合强化学习来做文本生成。 模型示意图如下： 在文本生成任务，seqGAN相比较于普通GAN区别在以下几点： 生成器不取argmax。 每生成一个单词，则根据当前的词语序列进行蒙特卡洛采样生成完成的句子。然后将句子送入判别器计算reward。 根据得到的reward进行策略梯度下降优化模型。 GAN在其他领域的应用数据增广​ GAN的良好生成特性近年来也开始被用于数据增广。以行人重识别为例，有许多GAN用于数据增广的工作[1-4]。行人重识别问题一个难点在于不同摄像头下拍摄的人物环境，角度差别非常大，导致存在较大的Domain gap。因此，可以考虑使用GAN来产生不同摄像头下的数据进行数据增广。以论文[1]为例，本篇paper提出了一个cycleGAN用于数据增广的方法。具体模型结构如下： ​ 对于每一对摄像头都训练一个cycleGAN，这样就可以实现将一个摄像头下的数据转换成另一个摄像头下的数据，但是内容（人物）保持不变。在CVPR19中，[9]进一步提升了图像的生成质量，进行了“淘宝换衣”式的高质量图像生成（如下图），提供了更高质量的行人训练数据。 图像超分辨与图像补全​ 图像超分辨与补全均可以作为图像翻译问题，该类问题的处理办法也大都是训练一个端到端的网络，输入是原始图片，输出是超分辨率后的图片，或者是补全后的图片。文献[5]利用GAN作为判别器，使得超分辨率模型输出的图片更加清晰，更符合人眼主管感受。日本早稻田大学研究人员[6]提出一种全局+局部一致性的GAN实现图像补全，使得修复后的图像不仅细节清晰，且具有整体一致性。 语音领域​ 相比于图像领域遍地开花，GAN在语音领域则应用相对少了很多。这里零碎的找一些GAN在语音领域进行应用的例子作为介绍。文献[7]提出了一种音频去噪的SEGAN，缓解了传统方法支持噪声种类稀少，泛化能力不强的问题。Donahue利用GAN进行语音增强，提升了ASR系统的识别率。 参考文献[1] Zheng Z , Zheng L , Yang Y . Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in Vitro[C]// 2017 IEEE International Conference on Computer Vision (ICCV). IEEE Computer Society, 2017. [2] Zhong Z , Zheng L , Zheng Z , et al. Camera Style Adaptation for Person Re-identification[J]. 2017. [3] Deng W , Zheng L , Ye Q , et al. Image-Image Domain Adaptation with Preserved Self-Similarity and Domain-Dissimilarity for Person Re-identification[J]. 2017. [4] Wei L , Zhang S , Gao W , et al. Person Transfer GAN to Bridge Domain Gap for Person Re-Identification[J]. CVPR, 2017. [5] Ledig C , Theis L , Huszar F , et al. Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network[J]. CVPR, 2016. [6] Iizuka S , Simo-Serra E , Ishikawa H . Globally and locally consistent image completion[J]. ACM Transactions on Graphics, 2017, 36(4):1-14. [7] Pascual S , Bonafonte A , Serrà, Joan. SEGAN: Speech Enhancement Generative Adversarial Network[J]. 2017. [8] Donahue C , Li B , Prabhavalkar R . Exploring Speech Enhancement with Generative Adversarial Networks for Robust Speech Recognition[J]. 2017. [9] Zheng, Z., Yang, X., Yu, Z., Zheng, L., Yang, Y., &amp; Kautz, J. Joint discriminative and generative learning for person re-identification. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)[C]. 2019.","link":"/2019/10/14/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%EF%BC%88GAN%EF%BC%89/"},{"title":"Google Go语言 语法笔记","text":"包 Package包的声明 Declare 使用package关键字声明当前源文件所在的包包声明语句是所有源文件的第一行非注释语句包名称中不能包含空白字符包名推荐与源文件所在的目录名称保持一致每个目录中只能定义一个package 12345package cxy // 声明一个名为“cxy”的包package 我的包 // 声明一个名为“我的包”的包package main // main包, 程序启动执行的入口包 错误的包声明 12345package &quot;mypkg&quot; // 错误package a/b/c // 错误pakcage a.b.c // 错误 包的导入 Import 导入包路径是对应包在$GOROOT/pkg/$GOOS_$GOARCH/、$GOPATH/pkg/$GOOS_$GOARCH/或当前路径中的相对路径 1234567// 导入$GOROOT/$GOOS_$GOARCH/中的相对路径包(官方标准库)import &quot;fmt&quot;import &quot;math/rand&quot;// 导入$GOPATH/$GOOS_$GOARCH/中的相对路径包import &quot;github.com/user/project/pkg&quot;import &quot;code.google.com/p/project/pkg&quot; 导入当前包的相对路径包例如有Go目录如下：$GOPATH/src ├─x0 │ ├─y0 │ │ └─z0 │ └─y1 │ └─z1 └─x1 └─y2 123import &quot;./y0/z0&quot; // x0包中导入子包 z0包import &quot;../y0/z0&quot; // y1包中导入子包 z0包import &quot;x0/y1/z1&quot; // y2包中导入 z1包 错误的导入包路径 123import a/b/c // 错误import &quot;a.b.c&quot; // 错误import a.b.c // 错误 用圆括号组合导入包路径 123456import (&quot;fmt&quot;; &quot;math&quot;)import ( &quot;fmt&quot; &quot;math&quot;) 导入包可以定义别名，防止同名称的包冲突 123456789import ( &quot;a/b/c&quot; c1 &quot;x/y/c&quot; // 将导入的包c定义别名为 c1 格式化 &quot;fmt&quot; // 将导入的包fmt定义别名为 格式化 m &quot;math&quot; // 将导入的包math定义别名为 m) 引用包名是导入包路径的最后一个目录中定义的唯一包的名称定义的包名与目录同名时，直接引用即可 12345// 引用普通名称的导入包c.hello()// 引用定义别名的包格式化.Println(m.Pi) 定义的包名与所在目录名称不同时，导入包路径仍为目录所在路径，引用包名为定义的包名称 123// 源文件路径: $GOPATH/src/proj/my-util/util.go// 定义包名: utilpackage util 12345// 导入util包路径import &quot;proj/my-util&quot;// 引用util包util.doSomething() 静态导入，在导入的包路径之前增加一个小数点. 12345// 类似C中的include 或Java中的import staticimport . &quot;fmt&quot;// 然后像使用本包元素一样使用fmt包中可见的元素，不需要通过包名引用Println(&quot;no need package name&quot;) 导入包但不直接使用该包，在导入的包路径之前增加一个下划线_ 123456// 如果当前go源文件中未引用过log包，将会导致编译错误import &quot;log&quot; // 错误import . &quot;log&quot; // 静态导入未使用同样报错// 在包名前面增加下划线表示导入包但是不直接使用它，被导入的包中的init函数会在导入的时候执行import _ &quot;github.com/go-sql-driver/mysql&quot; 包内元素的可见性 Accessability 名称首字符为Unicode包含的大写字母的元素是被导出的，对外部包是可见的首字为非大写字母的元素只对本包可见(同包跨源文件可以访问，子包不能访问) 1234567891011var In int // In is exportedvar in byte // in is unexportedvar ȸȹ string // ȸȹ is unexportedconst Ȼom bool = false // Ȼom is exportedconst ѧѩ uint8 = 1 // ѧѩ is unexportedtype Ĩnteger int // Ĩnteger is exportedtype ブーリアン *bool // ブーリアン is unexportedfunc Ӭxport() {...} // Ӭxport is exportedfunc įnner() {...} // įnner is unexportedfunc (me *Integer) ⱱalueOf(s string) int {...} // ⱱalueOf is unexportedfunc (i ブーリアン) Ȿtring() string {...} // Ȿtring is exported internal包（内部包） Go1.4+internal包及其子包中的导出元素只能被与internal同父包的其他包访问 例如有Go目录如下：$GOPATH/src ├─x0 │ ├─internal │ │ └─z0 │ └─y0 │ └─z1 └─x1 └─y1 x0，y0，z1包中可以访问internal，z0包中的可见元素x1，y1包中不能导入internal，z0包 规范导入包路径Canonical import paths Go1.4+包声明语句后面添加标记注释，用于标识这个包的规范导入路径。 1package pdf // import &quot;rsc.io/pdf&quot; 如果使用此包的代码的导入的路径不是规范路径，go命令会拒绝编译。例如有 rsc.io/pdf 的一个fork路径 github.com/rsc/pdf如下程序代码导入路径时使用了非规范的路径则会被go拒绝编译 1import &quot;github.com/rsc/pdf&quot; 数据类型 Data Type基础数据类型 Basic data type 基本类型包含：数值类型，布尔类型，字符串 类型 取值范围 默认零值 类型 取值范围 默认零值 int int32,int64 0 uint uint32,uint64 0 int8 -27 ~ 27-1 0 uint8,byte 0 ~ 28-1 0 int16 -215 ~ 215-1 0 uint16 0 ~ 216-1 0 int32,rune -231 ~ 231-1 0 uint32 0 ~ 232-1 0 int64 -263 ~ 263-1 0 uint64 0 ~ 264-1 0 float32 IEEE-754 32-bit 0.0 float64 IEEE-754 64-bit 0.0 complex64 float32+float32i 0 + 0i complex128 float64+float64i 0 + 0i bool true,false false string “” ~ “∞” “”,`` uintptr uint32,uint64 0 error - nil byte 是 uint8 的别名 `rune` 是 `int32` 的别名，代表一个Unicode码点 `int`与`int32`或`int64`是不同的类型，只是根据架构对应32/64位值 `uint`与`uint32`或`uint64`是不同的类型，只是根据架构对应32/64位值 变量 Variable 变量声明, 使用var关键字Go中只能使用var 声明变量，无需显式初始化值 12345var i int // i = 0var s string // s = &quot;&quot; (Go中的string是值类型，默认零值是空串 &quot;&quot; 或 ``，不存在nil(null)值)var e error // e = nil, error是Go的内建接口类型。 关键字的顺序错误或缺少都是编译错误的 123var int a // 编译错误a int // 编译错误int a // 编译错误 var 语句可以声明一个变量列表，类型在变量名之后 12345678910var a,b,c int // a = 0, b = 0, c = 0var ( a int // a = 0 b string // b = &quot;&quot; c uint // c = 0)var ( a,b,c int d string) 变量定义时初始化赋值，每个变量对应一个值 12var a int = 0var a, b int = 0, 1 变量定义并初始化时可以省略类型，Go自动根据初始值推导变量的类型 12var a = 'A' // a int32var a,b = 0, &quot;B&quot; // a int, b string 使用组合符号:=定义并初始化变量，根据符号右边表达式的值的类型声明变量并初始化它的值:= 不能在函数外使用，函数外的每个语法块都必须以关键字开始 12345a := 3 // a inta, b, c := 8, '呴', true // a int, b int32, c boolc := `formatted string` // c stringc := 1 + 2i // c complex128 常量 Constant 常量可以是字符、字符串、布尔或数值类型的值，数值常量是高精度的值 12345678910const x int = 3const y,z int = 1,2const ( a byte = 'A' b string = &quot;B&quot; c bool = true d int = 4 e float32 = 5.1 f complex64 = 6 + 6i) 根据常量值自动推导类型 12345const a = 0 // a intconst ( b = 2.3 // b float64 c = true // c bool) 常量组内定义时复用表达式常量组内定义的常量只有名称时，其值会根据上一次最后出现的常量表达式计算相同的类型与值 12345678910const ( a = 3 // a = 3 b // b = 3 c // c = 3 d = len(&quot;asdf&quot;) // d = 4 e // e = 4 f // f = 4 g,h,i = 7,8,9 // 复用表达式要一一对应 x,y,z // x = 7, y = 8, z = 9) 自动递增枚举常量 iotaiota的枚举值可以赋值给数值兼容类型每个常量单独声明时，iota不会自动递增 1234const a int = iota // a = 0const b int = iota // b = 0const c byte = iota // c = 0const d uint64 = iota // d = 0 常量组合声明时，iota每次引用会逐步自增，初始值为0，步进值为1 1234567const ( a uint8 = iota // a = 0 b int16 = iota // b = 1 c rune = iota // c = 2 d float64 = iota // d = 3 e uintptr = iota // e = 4) 即使iota不是在常量组内第一个开始引用，也会按组内常量数量递增 1234567const ( a = &quot;A&quot; b = 'B' c = iota // c = 2 d = &quot;D&quot; e = iota // e = 4) 枚举的常量都为同一类型时，可以使用简单序列格式(组内复用表达式). 12345const ( a = iota // a int32 = 0 b // b int32 = 1 c // c int32 = 2) 枚举序列中的未指定类型的常量会跟随序列前面最后一次出现类型定义的类型 12345678const ( a byte = iota // a uint8 = 0 b // b uint8 = 1 c // c uint8 = 2 d rune = iota // d int32 = 3 e // e int32 = 4 f // f int32 = 5) iota自增值只在一个常量定义组合中有效，跳出常量组合定义后iota初始值归0 123456789const ( a = iota // a int32 = 0 b // b int32 = 1 c // c int32 = 2)const ( e = iota // e int32 = 0 (iota重新初始化并自增) f // f int32 = 1) 定制iota序列初始值与步进值 (通过组合内复用表达式实现) 123456const ( a = (iota + 2) * 3 // a int32 = 6 (a=(0+2)*3) 初始值为6,步进值为3 b // b int32 = 9 (b=(1+2)*3) c // c int32 = 12 (c=(2+2)*3) d // d int32 = 15 (d=(3+2)*3)) 数组 Array 数组声明带有长度信息且长度固定，数组是值类型默认零值不是nil，传递参数时会进行复制。声明定义数组时中括号[ ]在类型名称之前，赋值引用元素时中括号[ ]在数组变量名之后。 1234567var a [3]int = [3]int{0, 1, 2} // a = [0 1 2]var b [3]int = [3]int{} // b = [0 0 0]var c [3]intc = [3]int{}c = [3]int{0,0,0} // c = [0 0 0]d := [3]int{} // d = [0 0 0]fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, d, d, len(d), cap(d)) // [3]int [3]int{0, 0, 0} 3 3 使用...自动计算数组的长度 12345678var a = [...]int{0, 1, 2}// 多维数组只能自动计算最外围数组长度x := [...][3]int{{0, 1, 2}, {3, 4, 5}}y := [...][2][2]int{{{0,1},{2,3}},{{4,5},{6,7}}}// 通过下标访问数组元素println(y[1][1][0]) // 6 初始化指定索引的数组元素，未指定初始化的元素保持默认零值 12var a = [3]int{2:3}var b = [...]string{2:&quot;c&quot;, 3:&quot;d&quot;} 切片 Slice slice 切片是对一个数组上的连续一段的引用，并且同时包含了长度和容量信息因为是引用类型，所以未初始化时的默认零值是nil，长度与容量都是0 12345678var a []intfmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, a, a, len(a), cap(a)) // []int []int(nil) 0 0// 可用类似数组的方式初始化slicevar d []int = []int{0, 1, 2}fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, d, d, len(d), cap(d)) // []int []int{0, 1, 2} 3 3var e = []string{2:&quot;c&quot;, 3:&quot;d&quot;} 使用内置函数make初始化slice，第一参数是slice类型，第二参数是长度，第三参数是容量(省略时与长度相同) 12345678var b = make([]int, 0)fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, b, b, len(b), cap(b)) // []int []int{} 0 0var c = make([]int, 3, 10)fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, c, c, len(c), cap(c)) // []int []int{} 3 10var a = new([]int)fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, a, a, len(*a), cap(*a)) // *[]int &amp;[]int(nil) 0 0 基于slice或数组重新切片，创建一个新的 slice 值指向相同的数组重新切片支持两种格式： 2个参数 slice[beginIndex:endIndex]需要满足条件：0 &lt;= beginIndex &lt;= endIndex &lt;= cap(slice)截取从开始索引到结束索引-1 之间的片段新slice的长度：length=(endIndex - beginIndex)新slice的容量：capacity=(cap(slice) - beginIndex)beginIndex的值可省略，默认为0endIndex 的值可省略，默认为len(slice) 123456s := []int{0, 1, 2, 3, 4}a := s[1:3] // a: [1 2], len: 2, cap: 4b := s[:4] // b: [0 1 2 3], len: 4, cap: 5c := s[1:] // c: [1 2 3 4], len: 4, cap: 4d := s[1:1] // d: [], len: 0, cap: 4e := s[:] // e: [0 1 2 3 4], len: 5, cap: 5 3个参数 slice[beginIndex:endIndex:capIndex] Go1.2+需要满足条件：0 &lt;= beginIndex &lt;= endIndex &lt;= capIndex &lt;= cap(slice)新slice的长度：length=(endIndex - beginIndex)新slice的容量：capacity=(capIndex - beginIndex)beginIndex的值可省略，默认为0 123s := make([]int, 5, 10)a := s[9:10:10] // a: [0], len: 1, cap: 1b := s[:3:5] // b: [0 0 0], len: 3, cap: 5 向slice中追加/修改元素 123456789s := []string{}s = append(s, &quot;a&quot;) // 添加一个元素s = append(s, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) // 添加一列元素t = []string{&quot;e&quot;, &quot;f&quot;, &quot;g&quot;}s = append(s, t...} // 添加另一个切片t的所有元素s = append(s, t[:2]...} // 添加另一个切片t的部分元素s[0] = &quot;A&quot; // 修改切片s的第一个元素s[len(s)-1] = &quot;G&quot; // 修改切片s的最后一个元素 向slice指定位置插入元素，从slice中删除指定的元素因为slice引用指向底层数组，数组的长度不变元素是不能插入/删除的插入的原理就是从插入的位置将切片分为两部分依次将首部、新元素、尾部拼接为一个新的切片删除的原理就是排除待删除元素后用其他元素重新构造一个数组 12345678910111213141516171819202122func insertSlice(s []int, i int, elements ...int) []int { // x := append(s[:i], append(elements, s[i:]...)...) x := s[:i] x = append(x, elements...) x = append(x, s[i:]...) return x}func deleteByAppend() { i := 3 s := []int{1, 2, 3, 4, 5, 6, 7} // delete the fourth element(index is 3), using append s = append(s[:i], s[i+1:]...)}func deleteByCopy() { i := 3 s := []int{1, 2, 3, 4, 5, 6, 7} // delete the fourth element(index is 3), using copy copy(s[i:], s[i+1:]) s = s[:len(s)-1]} 字典/映射 Map map是引用类型，使用内置函数 make进行初始化，未初始化的map零值为 nil长度为0，并且不能赋值元素 1234567var m map[int]intm[0] = 0 // × runtime error: assignment to entry in nil mapfmt.Printf(&quot;type: %T\\n&quot;, m) // map[int]intfmt.Printf(&quot;value: %#v\\n&quot;, m) // map[int]int(nil)fmt.Printf(&quot;value: %v\\n&quot;, m) // map[]fmt.Println(&quot;is nil: &quot;, nil == m) // truefmt.Println(&quot;length: &quot;, len(m)) // 0，if m is nil, len(m) is zero. 使用内置函数make初始化map 1234567var m map[int]int = make(map[int]int)m[0] = 0 // 插入或修改元素fmt.Printf(&quot;type: %T\\n&quot;, m) // map[int]intfmt.Printf(&quot;value: %#v\\n&quot;, m) // map[int]int(0:0)fmt.Printf(&quot;value: %v\\n&quot;, m) // map[0:0]fmt.Println(&quot;is nil: &quot;, nil == m) // falsefmt.Println(&quot;length: &quot;, len(m)) // 1 直接赋值初始化map 12345678m := map[int]int{0:0,1:1, // 最后的逗号是必须的}n := map[string]S{&quot;a&quot;:S{0,1},&quot;b&quot;:{2,3}, // 类型名称可省略} map的使用：读取、添加、修改、删除元素 1234567m[0] = 3 // 修改m中key为0的值为3m[4] = 8 // 添加到m中key为4值为8a := n[&quot;a&quot;] // 获取n中key为“a“的值b, ok := n[&quot;c&quot;] // 取值, 并通过ok(bool)判断key对应的元素是否存在.delete(n, &quot;a&quot;) // 使用内置函数delete删除key为”a“对应的元素. 结构体 Struct 结构体类型struct是一个字段的集合 1234type S struct { A int B, c string} 结构体初始化通过结构体字段的值作为列表来新分配一个结构体。 1var s S = S{0, &quot;1&quot;, &quot;2&quot;} 使用 Name: 语法可以仅列出部分字段(字段名的顺序无关) 1var s S = S{B: &quot;1&quot;, A: 0} 结构体是值类型，传递时会复制值，其默认零值不是nil 123var a Svar b = S{}fmt.Println(a == b) // true 结构体组合将一个命名类型作为匿名字段嵌入一个结构体嵌入匿名字段支持命名类型、命名类型的指针和接口类型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package maintype ( A struct { v int } // 定义结构体B，嵌入结构体A作为匿名字段 B struct { A } // 定义结构体C，嵌入结构体A的指针作为匿名字段 C struct { *A })func (a *A) setV(v int) { a.v = v}func (a A) getV() int { return a.v}func (b B) getV() string { return &quot;B&quot;}func (c *C) getV() bool { return true}func main() { a := A{} b := B{} // 初始化结构体B，其内匿名字段A默认零值是A{} c := C{&amp;A{}} // 初始化结构体C，其内匿名指针字段*A默认零值是nil，需要初始化赋值 println(a.v) // 结构体A嵌入B，A内字段自动提升到B println(b.v) // 结构体指针*A嵌入C，*A对应结构体内字段自动提升到C println(c.v) a.setV(3) b.setV(5) c.setV(7) println(a.getV(), b.A.getV(), c.A.getV()) println(a.getV(), b.getV(), c.getV())} 匿名结构体匿名结构体声明时省略了type关键字，并且没有名称 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package mainimport &quot;fmt&quot;type Integer int// 声明变量a为空的匿名结构体类型var a struct{}// 声明变量b为包含一个字段的匿名结构体类型var b struct{ x int }// 声明变量c为包含两个字段的匿名结构体类型var c struct { u int v bool}func main() { printa(a) b.x = 1 fmt.Printf(&quot;bx: %#v\\n&quot;, printb(b)) // bx: struct { y uint8 }{y:0x19} printc(c) // 声明d为包含3个字段的匿名结构体并初始化部分字段 d := struct { x int y complex64 z string }{ z: &quot;asdf&quot;, x: 111, } d.y = 22 + 333i fmt.Printf(&quot;d: %#v\\n&quot;, d) // d: struct { x int; y complex64; z string }{x:111, y:(22+333i), z:&quot;asdf&quot;} // 声明变量e为包含两个字段的匿名结构体类型 // 包含1个匿名结构体类型的命名字段和1个命名类型的匿名字段 e := struct { a struct{ x int } // 结构体组合嵌入匿名字段只支持命名类型 Integer }{} e.Integer = 444 fmt.Printf(&quot;e: %#v\\n&quot;, e) // e: struct { a struct { x int }; main.Integer }{a:struct { x int }{x:0}, Integer:444}}// 函数参数为匿名结构体类型时，传入参数类型声明必须保持一致func printa(s struct{}) { fmt.Printf(&quot;a: %#v\\n&quot;, s) // a: struct {}{}}// 函数入参和返回值都支持匿名结构体类型func printb(s struct{ x int }) (x struct{ y byte }) { fmt.Printf(&quot;b: %#v\\n&quot;, s) // b: struct { x int }{x:1} x.y = 25 return}func printc(s struct {u int; v bool }) { fmt.Printf(&quot;c: %#v\\n&quot;, s) // c: struct { u int; v bool }{u:0, v:false}} 指针 Pointer 通过取地址操作符&amp;获取指向值/引用对象的指针。 1234567var i int = 1pi := &amp;i // 指向数值的指针a := []int{0, 1, 2}pa := &amp;a // 指向引用对象的指针var s *S = &amp;S{0, &quot;1&quot;, &quot;2&quot;} // 指向值对象的指针 内置函数new(T)分配了一个零初始化的 T 值，并返回指向它的指针 12var i = new(int)var s *S = new(S) 使用*读取/修改指针指向的值 12345678func main() { i := new(int) *i = 3 println(i, *i) // 0xc208031f80 3 i = new(int) println(i, *i) // 0xc208031f78 0} 指针使用点号来访问结构体字段结构体字段/方法可以通过结构体指针来访问，通过指针间接的访问是透明的。 12fmt.Println(s.A)fmt.Println((*s).A) 指针的指针 123456789101112func main() { var i int var p *int var pp **int var ppp ***int var pppp ****int println(i, p, pp, ppp, pppp) // 0 0x0 0x0 0x0 0x0 i, p, pp, ppp, pppp = 123, &amp;i, &amp;p, &amp;pp, &amp;ppp println(i, p, pp, ppp, pppp) // 123 0xc208031f68 0xc208031f88 0xc208031f80 0xc208031f78 println(i, *p, **pp, ***ppp, ****pppp) // 123 123 123 123 123} 跨层指针元素的使用在指针引用多层对象时，指针是针对引用表达式的最后一位元素。 1234567891011package atype X struct { A Y}type Y struct { B Z}type Z struct { C int} 12345678910111213141516package mainimport ( &quot;a&quot; &quot;fmt&quot;)func main() { var x = a.X{} var p = &amp;x fmt.Println(&quot;x: &quot;, x) // x: {{{0}}} println(&quot;p: &quot;, p) // p: 0xc208055f20 fmt.Println(&quot;*p: &quot;, *p) // *p: {{{0}}} println(&quot;x.A.B.C: &quot;, x.A.B.C) // x.A.B.C: 0 // println(&quot;*p.A.B.C: &quot;, *p.A.B.C) // invalid indirect of p.A.B.C (type int) println(&quot;(*p).A.B.C: &quot;, (*p).A.B.C) // (*p).A.B.C: 0} Go的指针没有指针运算，但是 道高一尺，魔高一丈Go语言中的指针运算利用unsafe操作未导出变量 通道 Channel channel用于两个goroutine之间传递指定类型的值来同步运行和通讯。操作符&lt;-用于指定channel的方向，发送或接收。如果未指定方向，则为双向channel。 123var c0 chan int // 可用来发送和接收int类型的值var c1 chan&lt;- int // 可用来发送int类型的值var c2 &lt;-chan int // 可用来接收int类型的值 channel是引用类型，使用make函数来初始化。未初始化的channel零值是nil，且不能用于发送和接收值。 12c0 := make(chan int) // 不带缓冲的int类型channelc1 := make(chan *int, 10) // 带缓冲的*int类型指针channel 无缓冲的channe中有值时发送方会阻塞，直到接收方从channel中取出值。带缓冲的channel在缓冲区已满时发送方会阻塞，直到接收方从channel中取出值。接收方在channel中无值会一直阻塞。 通过channel发送一个值时，&lt;-作为二元操作符使用， 1c0 &lt;- 3 通过channel接收一个值时，&lt;-作为一元操作符使用。 1i := &lt;-c1 关闭channel，只能用于双向或只发送类型的channel只能由 发送方调用close函数来关闭channel接收方取出已关闭的channel中发送的值后，后续再从channel中取值时会以非阻塞的方式立即返回channel传递类型的零值。 12345678910111213141516171819202122232425ch := make(chan string, 1)// 发送方，发送值后关闭channelch &lt;- &quot;hello&quot;close(ch)// 接收方，取出发送的值fmt.Println(&lt;-ch) // 输出： “hello”// 再次从已关闭的channel中取值，返回channel传递类型的零值fmt.Println(&lt;-ch) // 输出： 零值，空字符串“”// 接收方判断接收到的零值是由发送方发送的还是关闭channel返回的默认值s, ok := &lt;-chif ok { fmt.Println(&quot;Receive value from sender:&quot;, s)} else { fmt.Println(&quot;Get zero value from closed channel&quot;)}// 向已关闭的通道发送值会产生运行时恐慌panicch &lt;- &quot;hi&quot;// 再次关闭已经关闭的通道也会产生运行时恐慌panicclose(ch) 使用for range语句依次读取发送到channel的值，直到channel关闭。 12345678910111213141516171819package mainimport &quot;fmt&quot;func main() { // 无缓冲和有缓冲的channel的range用法相同 var ch = make(chan int) // make(chan int, 2) 或 make(chan int , 100) go func() { for i := 0; i &lt; 5; i++ { ch &lt;- i } close(ch) }() // channel中无发送值且未关闭时会阻塞 for x := range ch { fmt.Println(x) }} 下面方式与for range用法效果相同 12345678910loop: for { select { case x, ok := &lt;-c: if !ok { break loop } fmt.Println(x) } } 接口 Interface 接口类型是由一组方法定义的集合。接口类型的值可以存放实现这些方法的任何值。 123type Abser interface { Abs() float64} 类型通过实现定义的方法来实现接口， 不需要显式声明实现某接口。 12345678type MyFloat float64func (f MyFloat) Abs() float64 { if f &lt; 0 { return float64(-f) } return float64(f)} 接口组合 12345678910111213141516171819202122232425262728293031323334353637383940type Reader interface { Read(b []byte) (n int)}type Writer interface { Write(b []byte) (n int)}// 接口ReadWriter组合了Reader和Writer两个接口type ReadWriter interface { Reader Writer}type File struct { // ...}func (f *File) Read(b []byte) (n int) { println(&quot;Read&quot;, len(b),&quot;bytes data.&quot;) return len(b)}func (f *File) Write(b []byte) (n int) { println(&quot;Write&quot;, len(b),&quot;bytes data.&quot;) return len(b)}func main() { // *File 实现了Read方法和Write方法，所以实现了Reader接口和Writer接口以及组合接口ReadWriter var f *File = &amp;File{} var r Reader = f var w Writer = f var rw ReadWriter = f bs := []byte(&quot;asdf&quot;) r.Read(bs) rw.Read(bs) w.Write(bs) rw.Write(bs)} 内置接口类型error是一个用于表示错误情况的常规接口，其零值nil表示没有错误所有实现了Error方法的类型都能表示为一个错误 123type error interface { Error() string} 自定义类型 Go中支持自定义的类型可基于： 基本类型、数组类型、切片类型、字典类型、函数类型、结构体类型、通道类型、接口类型以及自定义类型的类型 12345678910111213141516171819202122232425262728type ( A int B int8 C int16 D rune E int32 F int64 G uint H byte I uint16 J uint32 K uint64 L float32 M float64 N complex64 O complex128 P uintptr Q bool R string S [3]uint8 T []complex128 U map[string]uintptr V func(i int) (b bool) W struct {a, b int} X chan int Y interface {} Z A) 以及支持以上所有支持类型的指针类型 12345678910111213141516171819202122232425262728type ( A *int B *int8 C *int16 D *rune E *int32 F *int64 G *uint H *byte I *uint16 J *uint32 K *uint64 L *float32 M *float64 N *complex64 O *complex128 P *uintptr Q *bool R *string S *[3]uint8 T *[]complex128 U *map[string]uintptr V *func(i int) (b bool) W *struct {a, b int} X *chan int Y *interface {} Z *A) 类型别名 Go1.9+ 1234567891011121314151617181920type ( A struct{} B struct{} // 定义两个结构相同的类型A，B C = A // 定义类型A的别名)func main() { var ( a A b B c C ) // 因为类型名不同，所以a和b不是相同类型，此处编译错误 fmt.Println(a == b) // invalid operation: a == b (mismatched types A and B) fmt.Println(a == c) // true a = C{} c = A{} fmt.Println(c == a) // true} 强制类型转换 数据类型转换语法规则 12// T 为新的数据类型newDataTypeVariable = T(oldDataTypeVariable) 数值类型转换 123var i int = 123var f = float64(i)var u = uint(f) 接口类型转换任意类型的数据都可以转换为其类型已实现的接口类型 1234567type I interface{}var x int = 123var y = I(x) var s struct{a string}var t = I(s) 结构体类型转换 Go1.8+如果两个结构体包含的所有字段的名称和类型相同(忽略字段的标签差异)，则可以互相强制转换类型。 12345678910type T1 struct { X int `json:&quot;foo&quot;`}type T2 struct { X int `json:&quot;bar&quot;`}var v1 = T1{X: 123}var v2 = T2(v1) 语句 Statement分号/括号 ; { Go是采用语法解析器自动在每行末尾增加分号，所以在写代码的时候可以省略分号。 Go编程中只有几个地方需要手工增加分号：for循环使用分号把初始化、条件和遍历元素分开。if/switch的条件判断带有初始化语句时使用分号分开初始化语句与判断语句。在一行中有多条语句时，需要增加分号。 控制语句(if，for，switch，select)、函数、方法 的左大括号不能单独放在一行， 语法解析器会在大括号之前自动插入一个分号，导致编译错误。 条件语句 if if语句 小括号 ( )是可选的，而大括号 { } 是必须的。 123456789101112131415161718192021if (i &lt; 0) // 编译错误. println(i)if i &lt; 0 // 编译错误. println(i)if (i &lt; 0) { // 编译通过. println(i)}if (i &lt; 0 || i &gt; 10) { println(i)}if i &lt; 0 { println(i)} else if i &gt; 5 &amp;&amp; i &lt;= 10 { println(i)} else { println(i)} 可以在条件之前执行一个简单的语句，由这个语句定义的变量的作用域仅在 if / else if / else 范围之内 123456789101112131415if (i := 0; i &lt; 1) { // 编译错误. println(i)}if i := 0; (i &lt; 1) { // 编译通过. println(i)}if i := 0; i &lt; 0 { // 使用gofmt格式化代码会自动移除代码中不必要的小括号( ) println(i)} else if i == 0 { println(i)} else { println(i)} if语句作用域范围内定义的变量会覆盖外部同名变量，与方法函数内局部变量覆盖全局变量同理 12345a, b := 0, 1if a, b := 3, 4; a &gt; 1 &amp;&amp; b &gt; 2 { println(a, b) // 3 4}println(a, b) // 0 1 if判断语句类型断言 12345678910111213141516171819202122232425262728package mainfunc f0() int {return 333}func main() { x := 9 checkType(x) checkType(f0)}func checkType(x interface{}) { // 断言传入的x为int类型，并获取值 if i, ok := x.(int); ok { println(&quot;int: &quot;, i) // int: 0 } if f, ok := x.(func() int); ok { println(&quot;func: &quot;, f()) // func: 333 } // 如果传入x类型为int，则可以直接获取其值 a := x.(int) println(a) // 如果传入x类型不是byte，则会产生恐慌panic b := x.(byte) println(b)} 分支选择 switch switch存在分支选择对象时，case分支支持单个常量、常量列表 12345678switch x {case 0: println(&quot;single const&quot;)case 1, 2, 3: println(&quot;const list&quot;)default: println(&quot;default&quot;)} 分支选择对象之前可以有一个简单语句，case语句的大括号可以省略 1234567891011switch x *= 2; x {case 4: { println(&quot;single const&quot;)}case 5, 6, 7: { println(&quot;const list&quot;)}default: { println(&quot;default&quot;)}} switch只有一个简单语句，没有分支选择对象时，case分支支持逻辑表达式语句 12345678switch x /= 3; {case x == 8: println(&quot;expression&quot;)case x &gt;= 9: println(&quot;expression&quot;)default: println(&quot;default&quot;)} switch没有简单语句，没有分支选择对象时，case分支支持逻辑表达式语句 12345678switch {case x == 10: println(&quot;expression&quot;)case x &gt;= 11: println(&quot;expression&quot;)default: println(&quot;default&quot;)} switch类型分支，只能在switch语句中使用的.(type)获取对象的类型。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package mainimport ( &quot;fmt&quot; &quot;code.google.com/p/go.crypto/openpgp/errors&quot;)func main() { var ( a = 0.1 b = 2+3i c = &quot;asdf&quot; d = [...]byte{1, 2, 3} e = []complex128{1+2i} f = map[string]uintptr{&quot;a&quot;: 0} g = func(int) bool {return true} h = struct { a, b int }{} i = &amp;struct {}{} j chan int k chan &lt;- bool l &lt;-chan string m errors.SignatureError ) values := []interface{}{nil, a, b, &amp;c, d, e, f, g, &amp;g, h, &amp;h, i, j, k, l, m} for _, v := range values { typeswitch(v) }}func typeswitch(x interface{}) { // switch x.(type) { // 不使用类型值时 switch i := x.(type) { case nil: fmt.Println(&quot;x is nil&quot;) case int, int8, int16, rune, int64, uint, byte, uint16, uint32, uint64, float32, float64, complex64, complex128, uintptr, bool, string: fmt.Printf(&quot;basic type : %T\\n&quot;, i) case *int, *int8, *int16, *rune, *int64, *uint, *byte, *uint16, *uint32, *uint64, *float32, *float64, *complex64, *complex128, *uintptr, *bool, *string: fmt.Printf(&quot;basic pointer type : %T\\n&quot;, i) case [3]byte, []complex128, map[string]uintptr: fmt.Printf(&quot;collection type : %T\\n&quot;, i) case func(i int) (b bool), *func(): fmt.Printf(&quot;function type : %T\\n&quot;, i) case struct {a, b int}, *struct {}: fmt.Printf(&quot;struct type : %T\\n&quot;, i) case chan int, chan &lt;- bool, &lt;-chan string: fmt.Printf(&quot;channel type : %T\\n&quot;, i) case error, interface{a(); b()}: fmt.Printf(&quot;interface type : %T\\n&quot;, i) default: fmt.Printf(&quot;other type : %T\\n&quot;, i) }}// output: // x is nil// basic type : float64// basic type : complex128// basic pointer type : *string// collection type : [3]uint8// collection type : []complex128// collection type : map[string]uintptr// function type : func(int) bool// other type : *func(int) bool// struct type : struct { a int; b int }// other type : *struct { a int; b int }// struct type : *struct {}// channel type : chan int// channel type : chan&lt;- bool// channel type : &lt;-chan string// interface type : errors.SignatureError switch中每个case分支默认带有break效果，一个分支执行后就跳出switch，不会自动向下执行其他case。使用fallthrough强制向下继续执行后面的case代码。在类型分支中不允许使用fallthrough语句 12345678910111213141516171819switch {case false: println(&quot;case 1&quot;) fallthroughcase true: println(&quot;case 2&quot;) fallthroughcase false: println(&quot;case 3&quot;) fallthroughcase true: println(&quot;case 4&quot;)case false: println(&quot;case 5&quot;) fallthroughdefault: println(&quot;default case&quot;)}// 输出：case 2 case 3 case 4 循环语句 for Go只有一种循环结构：for 循环。可以让前置(初始化)、中间(条件)、后置(迭代)语句为空，或者全为空。 12345678910for i := 0; i &lt; 10; i++ {...}for i := 0; i &lt; 10; {...} // 省略迭代语句for i := 0; ; i++; {...} // 省略条件语句for ; i &lt; 10; i++ {...} // 省略初始化语句for i := 0; ; {...} // 省略条件和迭代语句, 分号不能省略for ; i &lt; 10; {...} // 省略初始化和迭代语句, 分号可省略for ; ; i++ {...} // 省略初始化和条件语句, 分号不能省略for i &lt; 10 {...}for ; ; {...} // 分号可省略for {...} for语句中小括号 ( )是可选的，而大括号 { } 是必须的。 123for (i := 0; i &lt; 10; i++) {...} // 编译错误.for i := 0; (i &lt; 10); i++ {...} // 编译通过.for (i &lt; 10) {...} // 编译通过. Go的for each循环for range 12345678910111213a := [5]int{2, 3, 4, 5, 6}for k, v := range a { fmt.Println(k, v) // 输出：0 2, 1 3, 2 4, 3 5, 4 6}for k := range a { fmt.Println(k) // 输出：0 1 2 3 4}for _ = range a { fmt.Println(&quot;print without care about the key and value&quot;)} Go1.4+ 123for range a { fmt.Println(&quot;new syntax – print without care about the key and value&quot;)} 循环的继续、中断、跳转 123456789for k, v := range s { if v == 3 { continue // 结束本次循环，进入下一次循环中 } else if v == 5 { break // 结束整个for循环 } else { goto SOMEWHERE // 跳转到标签指定的代码处 }} for range只支持遍历数组、数组指针、slice、string、map、channel类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package mainimport &quot;fmt&quot;func main() { var arr = [...]int{33, 22, 11, 0} // 遍历数组，取一位值时为索引值 for k := range arr { fmt.Printf(&quot;%d, &quot;, k) // 0, 1, 2, 3, } fmt.Println() // 遍历数组，取两位值时，第一位为索引值，第二位为元素值 for k, v := range arr { fmt.Printf(&quot;%d %d, &quot;, k, v) // 0 33, 1 22, 2 11, 3 0, } fmt.Println() // 遍历数组指针，取一位值时为索引值 for k := range &amp;arr { fmt.Printf(&quot;%d, &quot;, k) // 0, 1, 2, 3, } fmt.Println() // 遍历数组指针，取两位值时，第一位为索引值，第二位为元素值 for k, v := range &amp;arr { fmt.Printf(&quot;%d %d, &quot;, k, v) // 0 33, 1 22, 2 11, 3 0, } fmt.Println() var slc = []byte{44, 55, 66, 77} // 遍历切片，取一位值时为索引值 for k := range slc { fmt.Printf(&quot;%d, &quot;, k) // 0, 1, 2, 3, } fmt.Println() // 遍历切片，取两位值时，第一位为索引值，第二位为元素值 for k, v := range slc { fmt.Printf(&quot;%d %d, &quot;, k, v) // 0 44, 1 55, 2 66, 3 77, } fmt.Println() var str = &quot;abc一二3&quot; // 遍历字符串，取一位值时为字节索引值 for k := range str { fmt.Printf(&quot;%d, &quot;, k) // 0, 1, 2, 3, 6, 9, } fmt.Println() // 遍历字符串，取两位值时，第一位为字节索引值，第二位为Unicode字符 for k, v := range str { fmt.Printf(&quot;%d %d %s, &quot;, k, v, string(v)) // 0 97 a, 1 98 b, 2 99 c, 3 19968 一, 6 20108 二, 9 51 3, } fmt.Println() var mp = map[int]string{5:&quot;A&quot;, 9:&quot;B&quot;} // 遍历map，取一位值时为键key for k := range mp { fmt.Printf(&quot;%d, &quot;, k) // 9, 5, } fmt.Println() // 遍历map，取两位值时，第一位为键key，第二位为元素值value for k, v := range mp { fmt.Printf(&quot;%d %s, &quot;, k, v) // 5 A, 9 B, } fmt.Println() var ch = make(chan int) go func() { for i := 0; i &lt; 5; i++ { ch &lt;- i } close(ch) }() // 遍历channel时，只能取一位值，为发送方发送到channel中的值 for x := range ch { fmt.Printf(&quot;%d &quot;, x) // 0 1 2 3 4 }} 通道选择 select select用于当前goroutine从一组可能的通讯中选择一个进一步处理。如果任意一个通讯都可以进一步处理，则从中随机选择一个，执行对应的语句。否则在没有默认分支(default case)时，select语句则会阻塞，直到其中一个通讯完成。select 的 case 里的操作语句只能是IO操作 123456789ch1, ch2 := make(chan int), make(chan int)// 因为没有值发送到select中的任一case的channel中，此select将会阻塞select {case &lt;-ch1: println(&quot;channel 1&quot;)case &lt;-ch2: println(&quot;channel 2&quot;)} 1234567891011ch1, ch2 := make(chan int), make(chan int)// 因为没有值发送到select中的任一case的channel中，此select将会执行default分支select {case &lt;-ch1: println(&quot;channel 1&quot;)case &lt;-ch2: println(&quot;channel 2&quot;)default: println(&quot;default&quot;)} select只会执行一次case分支的逻辑，与for组合使用实现多次遍历分支 12345678910111213func main() { for { select { case &lt;-time.Tick(time.Second): println(&quot;Tick&quot;) case &lt;-time.After(5 * time.Second): println(&quot;Finish&quot;) default: println(&quot;default&quot;) time.Sleep(5e8) } }} 延迟执行 defer defer语句调用函数，将调用的函数加入defer栈，栈中函数在defer所在的主函数返回时执行，执行顺序是先进后出/后进先出。 1234567891011121314package mainfunc main() { defer print(0) defer print(1) defer print(2) defer print(3) defer print(4) for i := 5; i &lt;= 9; i++ { defer print(i) } // 输出：9876543210} defer在函数返回后执行，可以修改函数返回值 123456789101112package mainfunc main() { println(f()) // 返回： 15}func f() (i int) { defer func() { i *= 5 }() return 3} defer用于释放资源 释放锁 12mu.Lock()defer mu.Unlock() 关闭channel 12ch &lt;- &quot;hello&quot;defer close(ch) 关闭IO流 12f, err := os.Open(&quot;file.xxx&quot;)defer f.Close() 关闭数据库连接 12345db, err := sql.Open(&quot;mysql&quot;,&quot;user:password@tcp(127.0.0.1:3306)/hello&quot;)if err != nil { log.Fatal(err)}defer db.Close() defer用于恐慌的截获panic用于产生恐慌，recover用于截获恐慌，recover只能在defer语句中使用, 直接调用recover是无效的。 123456789101112131415161718func main() { f() fmt.Println(&quot;main normal...&quot;)}func f() { defer func() { if r := recover(); r != nil { fmt.Println(&quot;catch:&quot;, r) } }() p() fmt.Println(&quot;normal...&quot;)}func p() { panic(&quot;exception...&quot;)} 跳转语句 goto goto用于在一个函数内部运行跳转到指定标签的代码处，不能跳转到其他函数中定义的标签。 goto模拟循环 1234567891011package mainfunc main() { i := 0loop: i++ if i &lt; 5 { goto loop } println(i)} goto模拟continue，break 12345678910111213141516func main() { i, sum := 0, 0head: for ; i &lt;= 10; i++ { if i &lt; 5 { i++ // 此处必须单独调用一次，因为goto跳转时不会执行for循环的自增语句 goto head // continue } if i &gt; 9 { goto tail // break } sum += i }tail: println(sum) // 输出：35} 注意：任何时候都不建议使用goto 阻塞语句 永久阻塞语句 12345678// 向一个未初始化的channel中写入数据会永久阻塞(chan int)(nil) &lt;- 0// 从一个未初始化的channel中读取数据会永久阻塞&lt;-(chan struct{})(nil)for range (chan struct{})(nil){}// select无任何选择分支会永久阻塞select{} 函数 Function函数声明 Declare 使用关键字func声明函数，函数可以没有参数或接受多个参数 12345func f0() {/*...*/}func f1(a int) {/*...*/}func f2(a int, b byte) {/*...*/} 在函数参数类型之前使用...声明该参数为可变数量的参数可变参数只能声明为函数的最后一个参数。 123func f3(a ...int) {/*...*/}func f4(a int, b bool, c ...string) {/*...*/} 函数可以返回任意数量的返回值 1234567891011func f0() { return}func f1() int { return 0}func f2() (int, string) { return 0, &quot;A&quot;} 函数返回结果参数，可以像变量那样命名和使用 123456func f() (a int, b string) { a = 1 b = &quot;B&quot; return // 即使return后面没有跟变量，关键字在函数结尾也是必须的 // 或者 return a, b} 当两个或多个连续的函数命名参数是同一类型，则除了最后一个类型之外，其他都可以省略 12345func f0(a,b,c int) {/*...*/}func f1() (a,b,c int) {/*...*/}func f2(a,b int, c,d byte) (x,y int, z,s bool) {/*...*/} 函数闭包 Closure 匿名函数、闭包、函数值Go中函数作为第一类对象，可以作为值对象赋值给变量可以在函数体外/内定义匿名函数，命名函数不能嵌套定义到函数体内，只能定义在函数体外 123456789101112131415161718192021222324252627package maintype Myfunc func(i int) intfunc f0(name string){ println(name)}func main() { var a = f0 a(&quot;hello&quot;) // hello var f1 Myfunc = func(i int) int { return i } fmt.Println(f1(3)) // 3 var f2 func() int = func() int { return 0 } fmt.Println(f2()) // 0 // 省略部分关键字 var f3 func() = func() {/*...*/} var f4 = func() {/*...*/} f5 := func() {/*...*/}} 内建函数 Builtin func append 1func append(slice []Type, elems ...Type) []Type 内建函数append将元素追加到切片的末尾。若它有足够的容量，其目标就会重新切片以容纳新的元素。否则，就会分配一个新的基本数组。append返回更新后的切片，因此必须存储追加后的结果。 12slice = append(slice, elem1, elem2)slice = append(slice, anotherSlice...) 作为特例，可以向一个字节切片append字符串，如下： 1slice = append([]byte(&quot;hello &quot;), &quot;world&quot;...) func cap 1func cap(v Type) int 内建函数cap返回 v 的容量，这取决于具体类型： 数组：v中元素的数量，与 len(v) 相同 数组指针：*v中元素的数量，与len(v) 相同 切片：切片的容量（底层数组的长度）；若 v为nil，cap(v) 即为零 信道：按照元素的单元，相应信道缓存的容量；若v为nil，cap(v)即为零 func close 1func close(c chan&lt;- Type) 内建函数close关闭信道，该通道必须为双向的或只发送的。它应当只由发送者执行，而不应由接收者执行，其效果是在最后发送的值被接收后停止该通道。在最后的值从已关闭的信道中被接收后，任何对其的接收操作都会无阻塞的成功。对于已关闭的信道，语句： 1x, ok := &lt;-c // ok值为false func complex 1func complex(r, i FloatType) ComplexType 使用实部r和虚部i生成一个复数。 12c := complex(1, 2)fmt.Println(c) // (1+2i) func copy 1func copy(dst, src []Type) int 内建函数copy将元素从来源切片复制到目标切片中，也能将字节从字符串复制到字节切片中。copy返回被复制的元素数量，它会是 len(src) 和 len(dst) 中较小的那个。来源和目标的底层内存可以重叠。 12345678910111213a, b, c := []byte{1, 2, 3}, make([]byte, 2), 0fmt.Println(&quot;a:&quot;, a, &quot; b:&quot;, b, &quot; c: &quot;, c) // a: [1 2 3] b: [0 0] c: 0c = copy(b, a)fmt.Println(&quot;a:&quot;, a, &quot; b:&quot;, b, &quot; c: &quot;, c) // a: [1 2 3] b: [1 2] c: 2b = make([]byte, 5)c = copy(b, a)fmt.Println(&quot;a:&quot;, a, &quot; b:&quot;, b, &quot; c: &quot;, c) // a: [1 2 3] b: [1 2 3 0 0] c: 3s := &quot;ABCD&quot;c = copy(b, s)fmt.Println(&quot;s:&quot;, s, &quot; b:&quot;, b, &quot; c: &quot;, c) // s: ABCD b: [65 66 67 68 0] c: 4 func delete 1func delete(m map[Type]Type1, key Type) 内建函数delete按照指定的键将元素从映射中删除。若m为nil或无此元素，delete不进行操作。 123456789m := map[int]string{ 0: &quot;A&quot;, 1: &quot;B&quot;, 2: &quot;C&quot;,}delete(m, 1)fmt.Println(m) // map[2:C 0:A]delete(m, 3) // 此行代码执行没有任何操作，也不会报错。 func imag 1func imag(c ComplexType) FloatType 返回复数c的虚部。 12c := 2+5ifmt.Println(imag(c)) // 5 func len 1func len(v Type) int 内建函数len返回 v 的长度，这取决于具体类型： 数组：v中元素的数量 数组指针：*v中元素的数量（v为nil时panic） 切片、映射：v中元素的数量；若v为nil，len(v)即为零 字符串：v中字节的数量，计算字符数量使用utf8.RuneCountInString() 通道：通道缓存中队列（未读取）元素的数量；若v为 nil，len(v)即为零 func make 1func make(Type, size IntegerType) Type 内建函数make分配并初始化一个类型为切片、映射、或通道的对象。其第一个实参为类型，而非值。make的返回类型与其参数相同，而非指向它的指针。其具体结果取决于具体的类型： 切片：size指定了其长度。该切片的容量等于其长度。切片支持第二个整数实参可用来指定不同的容量；它必须不小于其长度，因此 make([]int, 0, 10) 会分配一个长度为0，容量为10的切片。 映射：初始分配的创建取决于size，但产生的映射长度为0。size可以省略，这种情况下就会分配一个小的起始大小。 通道：通道的缓存根据指定的缓存容量初始化。若 size为零或被省略，该信道即为无缓存的。 func new 1func new(Type) *Type 内建函数new分配内存。其第一个实参为类型，而非值。其返回值为指向该类型的新分配的零值的指针。 func panic 1func panic(v interface{}) 内建函数panic停止当前Go程的正常执行。当函数F调用panic时，F的正常执行就会立刻停止。F中defer的所有函数先入后出执行后，F返回给其调用者G。G如同F一样行动，层层返回，直到该Go程中所有函数都按相反的顺序停止执行。之后，程序被终止，而错误情况会被报告，包括引发该恐慌的实参值，此终止序列称为恐慌过程。 func print 1func print(args ...Type) 内建函数print以特有的方法格式化参数并将结果写入标准错误，用于自举和调试。 func println 1func println(args ...Type) println类似print，但会在参数输出之间添加空格，输出结束后换行。 func real 1func real(c ComplexType) FloatType 返回复数c的实部。 123456789 c := 2+5i fmt.Println(real(c)) // 2 ``` - `func recover` ```go func recover() interface{} 内建函数recover允许程序管理恐慌过程中的Go程。在defer的函数中，执行recover调用会取回传至panic调用的错误值，恢复正常执行，停止恐慌过程。若recover在defer的函数之外被调用，它将不会停止恐慌过程序列。在此情况下，或当该Go程不在恐慌过程中时，或提供给panic的实参为nil时，recover就会返回nil。 初始化函数 init init函数是用于程序执行前做包的初始化工作的函数init函数的声明没有参数和返回值 123func init() { // ...} 一个package或go源文件可以包含零个或多个init函数 1234567891011121314package mainfunc main() {}func init() { println(&quot;init1...&quot;)}func init() { println(&quot;init2...&quot;)}func init() { println(&quot;init3...&quot;)} init函数被自动调用，在main函数之前执行，不能在其他函数中调用，显式调用会报错该函数未定义。 1234567func init() { println(&quot;init...&quot;)}func main() { init() // undefined: init} 所有init函数都会被自动调用，调用顺序如下： 同一个go文件的init函数调用顺序是 从上到下的 同一个package中按go源文件名字符串比较 从小到大顺序调用各文件中的init函数 不同的package，如果不相互依赖的，按照main包中 先import的后调用的顺序调用其包中的init函数 如果package存在依赖，则先调用最早被依赖的package中的init函数 方法 Method 通过指定函数的接收者receiver,将函数绑定到一个类型或类型的指针上,使这个函数成为该类型的方法。只能对命名类型和命名类型的指针编写方法。只能在定义命名类型的那个包编写其方法。不能对接口类型和接口类型的指针编写方法。方法的接收者receiver是类型的值时，编译器会隐式的生成一个同名方法，其接收者receiver为该类型的指针，反过来却不会。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package maintype A struct { x, y int}// 定义结构体的方法，'_'表示方法内忽略使用结构体、字段及其他方法func (_ A) echo_A() { println(&quot;(_ A)&quot;)}// 同上func (A) echoA(s string) { println(&quot;(A)&quot;, s)}// 定义结构体指针的方法，'_'表示方法内忽略使用结构体指针、字段及其他方法func (_ *A) echo_жA() { println(&quot;(_ *A)&quot;)}// 同上func (*A) echoжA(s string) { println(&quot;(*A)&quot;, s)}// 定义结构体的方法，方法内可以引用结构体、字段及其他方法func (a A) setX(x int) { a.x = x}// 定义结构体指针的方法，方法内可以引用结构体、结构体指针、字段及其他方法func (a *A) setY(y int) { a.y = y}func main() { var a A // a = A{} a.setX(3) a.setY(6) println(a.x, a.y) // 0 6 a.echo_A() // (_ A) a.echoA(&quot;a&quot;) // (A) a a.echo_жA() // (_ *A) a.echoжA(&quot;a&quot;) // (*A) a // 以下是定义在结构体值上的方法原型，通过调用结构体类型上定义的函数，传入结构体的值 A.echo_A(a) // (_ A) A.echoA(a, &quot;a&quot;) // (A) a // A.echo_жA(a) // A.echo_жA未定义 // A.echoжA(a) // A.echoжA未定义 A.setX(a, 4) // A.setY(a, 7) // A.setY未定义 println(a.x) // 0 b := &amp;a b.setX(2) b.setY(5) println(b.x, b.y) // 0 5 b.echo_A() // (_ A) b.echoA(&quot;b&quot;) // (A) b b.echo_жA() // (_ *A) b.echoжA(&quot;b&quot;) // (*A) b // 以下是定义在结构体指针上的方法原型，通过调用结构体类型指针上定义的函数，传入结构体的指针 (*A).echo_A(b) // (_ A) (*A).echoA(b, &quot;b&quot;) // (A) b (*A).echo_жA(b) // (_ *A) (*A).echoжA(b, &quot;b&quot;) // (*A) b (*A).setX(b, 1) (*A).setY(b, 8) println(b.x, b.y) // 0 8 // 调用结构体空指针上的方法，以下注释掉的代码都是空指针错误 var c *A // c = nil // c.setX(2) // c.setY(5) // println(c.x, c.y) // c.echo_A() // c.echoA() c.echo_жA() // (_ *A) c.echoжA(&quot;c&quot;) // (*A) c // (*A).echo_A(c) // (*A).echoA(c) (*A).echo_жA(c) // (_ *A) (*A).echoжA(c, &quot;c&quot;) // (*A) c // (*A).setX(c, 1) // (*A).setY(c, 8) // println(c.x, c.y)} 结构体中组合匿名字段时，匿名字段的方法会向外传递，其规则如下：匿名字段为值类型时：值的方法会传递给结构体的值，指针的方法会传递给结构体的指针；匿名字段为指针类型时：指针的方法会传递给值和指针；匿名字段为接口类型时：方法会传递给值和指针； Go中有匿名函数，但是没有匿名方法 并发 Concurrency 协程goroutine是由Go运行时环境管理的轻量级线程。使用关键字go调用一个函数/方法，启动一个新的协程goroutine 1234567891011121314151617package mainimport ( &quot;time&quot;)func say(i int) { println(&quot;goroutine:&quot;, i)}func main() { for i := 1; i &lt;= 5; i++ { go say(i) } say(0) time.Sleep(5 * time.Second)} 主协程goroutine输出0，其他由go启动的几个子协程分别输出1～5 goroutine: 0 goroutine: 1 goroutine: 2 goroutine: 3 goroutine: 4 goroutine: 5 goroutine 在相同的地址空间中运行，因此访问共享内存必须进行同步。 12345678910111213141516171819202122232425package mainimport ( &quot;sync&quot; &quot;time&quot;)var mu sync.Mutexvar i intfunc main() { for range [5]byte{} { go Add() } time.Sleep(5*time.Second) println(i)}func Add() { // 使用互斥锁防止多个协程goroutine同时修改共享变量 // 只能限制同时访问此方法修改变量，在方法外修改则限制是无效的 mu.Lock() defer mu.Unlock() i++} 使用通道channel进行同步 12345678910111213141516171819202122package mainimport ( &quot;time&quot;)var i intvar ch = make(chan byte, 1)func main() { for range [5]byte{} { go Add() } time.Sleep(5*time.Second) println(i)}func Add() { ch &lt;- 0 i++ &lt;-ch} 使用channel在不同的goroutine之间通信 1234567891011121314151617181920212223242526// 上一个例子只是将channel用作同步开关，稍做修改即可在不同goroutine间通信package mainimport ( &quot;time&quot;)var i intvar ch = make(chan int, 1)func main() { for range [5]byte{} { go Add() } ch &lt;- i time.Sleep(5*time.Second) i = &lt;-ch println(i)}func Add() { // 从channel中接收的值是来自其他goroutine发送的 x := &lt;-ch x++ ch &lt;- x} 测试 Testing Go中自带轻量级的测试框架testing和自带的go test命令来实现单元测试和基准测试 单元测试 Unit 有如下待测试testgo包，一段简单的求和代码 1234567891011121314package testgoimport &quot;math&quot;func Sum(min, max int) (sum int) { if min &lt; 0 || max &lt; 0 || max &gt; math.MaxInt32 || min &gt; max { return 0 } for ; min &lt;= max; min++ { sum += min } return} 测试源文件名必须是_test.go结尾的，go test的时候才会执行到相应的代码必须import testing包所有的测试用例函数必须以Test开头测试用例按照源码中编写的顺序依次执行测试函数TestXxx()的参数是*testing.T，可以使用该类型来记录错误或者是测试状态测试格式：func TestXxx (t *testing.T)，Xxx部分可以为任意的字母数字的组合，首字母不能是小写字母[a-z]，例如Testsum是错误的函数名。函数中通过调用*testing.T的Error，Errorf，FailNow，Fatal，FatalIf方法标注测试不通过，调用Log方法用来记录测试的信息。 12345678910111213141516package testgoimport &quot;testing&quot;func TestSum(t *testing.T) { s := Sum(1, 0) t.Log(&quot;Sum 1 to 0:&quot;, s) if 0 != s { t.Error(&quot;not equal.&quot;) } s = Sum(1, 10) t.Log(&quot;Sum 1 to 10:&quot;, s) if 55 != s { t.Error(&quot;not equal.&quot;) }} 在当前包中执行测试：go test -v === RUN TestSum— PASS: TestSum (0.00s) t0_test.go:7: Sum 1 to 0: 0 t0_test.go:12: Sum 1 to 10: 55 PASSok /home/cxy/go/src/testgo 0.004s 基准测试 Benchmark 基准测试 Benchmark用来检测函数/方法的性能基准测试用例函数必须以Benchmark开头go test默认不会执行基准测试的函数，需要加上参数-test.bench，语法:-test.bench=”test_name_regex”，例如go test -test.bench=”.*”表示测试全部的基准测试函数在基准测试用例中，在循环体内使用testing.B.N，使测试可以正常的运行 1234567package testgoimport &quot;testing&quot;func BenchmarkSum(b *testing.B) { b.Logf(&quot;Sum 1 to %d: %d\\n&quot;, b.N, Sum(1, b.N))} 在当前包中执行测试：go test -v -bench . BenchmarkSum 2000000000 0.91 ns/op— BENCH: BenchmarkSum t0_test.go:19: Sum 1 to 1: 1 t0_test.go:19: Sum 1 to 100: 5050 t0_test.go:19: Sum 1 to 10000: 50005000 t0_test.go:19: Sum 1 to 1000000: 500000500000 t0_test.go:19: Sum 1 to 100000000: 5000000050000000 t0_test.go:19: Sum 1 to 2000000000: 2000000001000000000 ok /home/cxy/go/src/testgo 1.922s","link":"/2019/10/05/Google-Go%E8%AF%AD%E8%A8%80-%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"CYK","slug":"CYK","link":"/tags/CYK/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"二分搜索","slug":"二分搜索","link":"/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"二分搜索树","slug":"二分搜索树","link":"/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"name":"LeetCode","slug":"LeetCode","link":"/tags/LeetCode/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"spark","slug":"spark","link":"/tags/spark/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"exhaustive search","slug":"exhaustive-search","link":"/tags/exhaustive-search/"},{"name":"聚类","slug":"聚类","link":"/tags/%E8%81%9A%E7%B1%BB/"},{"name":"降维","slug":"降维","link":"/tags/%E9%99%8D%E7%BB%B4/"},{"name":"Viterbi","slug":"Viterbi","link":"/tags/Viterbi/"},{"name":"条件随机场","slug":"条件随机场","link":"/tags/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"name":"统计学习方法","slug":"统计学习方法","link":"/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"},{"name":"监督学习","slug":"监督学习","link":"/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"经典网络","slug":"经典网络","link":"/tags/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/"},{"name":"GAN","slug":"GAN","link":"/tags/GAN/"},{"name":"Go","slug":"Go","link":"/tags/Go/"}],"categories":[{"name":"LeetCode","slug":"LeetCode","link":"/categories/LeetCode/"},{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"NLP","slug":"深度学习/NLP","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"}]}