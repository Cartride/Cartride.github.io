{"pages":[],"posts":[{"title":"First Position of Target","text":"Question lintcode: First Position of Target Problem Statement For a given sorted array (ascending order) and a target number, find thefirst index of this number in O(log n) time complexity. If the target number does not exist in the array, return -1. Example If the array is [1, 2, 3, 3, 4, 5, 10], for given target 3, return 2. Challenge If the count of numbers is bigger than $$2^{32}$$, can your code work properly? 题解 对于已排序升序(升序)数组，使用二分查找可满足复杂度要求，注意数组中可能有重复值，所以需要使用类似lower_bound中提到的方法。 Java12345678910111213141516171819202122232425262728293031class Solution { /** * @param nums: The integer array. * @param target: Target to find. * @return: The first position of target. Position starts from 0. */ public int binarySearch(int[] nums, int target) { if (nums == null || nums.length == 0) { return -1; } int start = -1, end = nums.length; int mid; while (start + 1 &lt; end) { // avoid overflow when (end + start) mid = start + (end - start) / 2; if (nums[mid] &lt; target) { start = mid; } else { end = mid; } } if (end == nums.length || nums[end] != target) { return -1; } else { return end; } }} 源码分析 首先对输入做异常处理，数组为空或者长度为0。 初始化 start, end, mid三个变量，这里start初始化为-1主要是考虑到end为1。注意mid的求值方法，可以防止两个整型值相加时溢出。 使用迭代而不是递归进行二分查找，因为工程中递归写法存在潜在溢出的可能。 while终止条件应为start + 1 &lt; end而不是start &lt;= end，start == end时可能出现死循环。即循环终止条件是相邻或相交元素时退出。由于这里初始化时start &lt; end，所以一定是start + 1 == end时退出循环。 迭代终止时有两种情况，一种是在原数组中找到了，这种情况下一定是end, 因为start的更新只在nums[mid] &lt; target. 最后判断end和target的关系，先排除end为数组长度这种会引起越界的情况，然后再判断和目标值是否相等。 复杂度分析时间复杂度 $$O(\\log n)$$, 空间复杂度 $$(1)$$.对于题中的 follow up, Java 中数组不允许使用 long 型，如果使用 long 型，那么数组大小可大 17GB 之巨！！几乎没法用。 Reference 《挑战程序设计竞赛》3.1节","link":"/2019/10/29/First-Position-of-Target/"},{"title":"Remove Duplicates from Sorted List II","text":"Question leetcode: Remove Duplicates from Sorted List II | LeetCode OJ lintcode: (113) Remove Duplicates from Sorted List II Problem Statement Given a sorted linked list, delete all nodes that have duplicate numbers,leaving only distinct numbers from the original list. ExampleGiven 1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5, return 1-&gt;2-&gt;5.Given 1-&gt;1-&gt;1-&gt;2-&gt;3, return 2-&gt;3. 题解上题为保留重复值节点的一个，这题删除全部重复节点，看似区别不大，但是考虑到链表头不确定(可能被删除，也可能保留)，因此若用传统方式需要较多的if条件语句。这里介绍一个处理链表头节点不确定的方法——引入dummy node. 123ListNode *dummy = new ListNode(0);dummy-&gt;next = head;ListNode *node = dummy; 引入新的指针变量dummy，并将其next变量赋值为head，考虑到原来的链表头节点可能被删除，故应该从dummy处开始处理，这里复用了head变量。考虑链表A-&gt;B-&gt;C，删除B时，需要处理和考虑的是A和C，将A的next指向C。如果从空间使用效率考虑，可以使用head代替以上的node，含义一样，node比较好理解点。 与上题不同的是，由于此题引入了新的节点dummy，不可再使用node-&gt;val == node-&gt;next-&gt;val，原因有二： 此题需要将值相等的节点全部删掉，而删除链表的操作与节点前后两个节点都有关系，故需要涉及三个链表节点。且删除单向链表节点时不能删除当前节点，只能改变当前节点的next指向的节点。 在判断val是否相等时需先确定node-&gt;next和node-&gt;next-&gt;next均不为空，否则不可对其进行取值。 说多了都是泪，先看看我的错误实现： C++ - Wrong12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Definition of ListNode * class ListNode { * public: * int val; * ListNode *next; * ListNode(int val) { * this-&gt;val = val; * this-&gt;next = NULL; * } * } */class Solution{public: /** * @param head: The first node of linked list. * @return: head node */ ListNode * deleteDuplicates(ListNode *head) { if (head == NULL || head-&gt;next == NULL) { return NULL; } ListNode *dummy; dummy-&gt;next = head; ListNode *node = dummy; while (node-&gt;next != NULL &amp;&amp; node-&gt;next-&gt;next != NULL) { if (node-&gt;next-&gt;val == node-&gt;next-&gt;next-&gt;val) { int val = node-&gt;next-&gt;val; while (node-&gt;next != NULL &amp;&amp; val == node-&gt;next-&gt;val) { ListNode *temp = node-&gt;next; node-&gt;next = node-&gt;next-&gt;next; delete temp; } } else { node-&gt;next = node-&gt;next-&gt;next; } } return dummy-&gt;next; }}; 错因分析错在什么地方？ 节点dummy的初始化有问题，对类的初始化应该使用new 在else语句中node-&gt;next = node-&gt;next-&gt;next;改写了dummy-next中的内容，返回的dummy-next不再是队首元素，而是队尾元素。原因很微妙，应该使用node = node-&gt;next;，node代表节点指针变量，而node-&gt;next代表当前节点所指向的下一节点地址。具体分析可自行在纸上画图分析，可对指针和链表的理解又加深不少。 图中上半部分为ListNode的内存示意图，每个框底下为其内存地址。dummy指针变量本身的地址为ox7fff5d0d2500，其保存着指针变量值为0x7fbe7bc04c50. head指针变量本身的地址为ox7fff5d0d2508，其保存着指针变量值为0x7fbe7bc04c00. 好了，接下来看看正确实现及解析。 Python12345678910111213141516171819202122232425# Definition for singly-linked list.# class ListNode:# def __init__(self, x):# self.val = x# self.next = Noneclass Solution: # @param {ListNode} head # @return {ListNode} def deleteDuplicates(self, head): if head is None: return None dummy = ListNode(0) dummy.next = head node = dummy while node.next is not None and node.next.next is not None: if node.next.val == node.next.next.val: val_prev = node.next.val while node.next is not None and node.next.val == val_prev: node.next = node.next.next else: node = node.next return dummy.next C++123456789101112131415161718192021222324252627282930313233/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) {} * }; */class Solution {public: ListNode* deleteDuplicates(ListNode* head) { if (head == NULL) return NULL; ListNode dummy(0); dummy.next = head; ListNode *node = &amp;dummy; while (node-&gt;next != NULL &amp;&amp; node-&gt;next-&gt;next != NULL) { if (node-&gt;next-&gt;val == node-&gt;next-&gt;next-&gt;val) { int val_prev = node-&gt;next-&gt;val; // remove ListNode node-&gt;next while (node-&gt;next != NULL &amp;&amp; val_prev == node-&gt;next-&gt;val) { ListNode *temp = node-&gt;next; node-&gt;next = node-&gt;next-&gt;next; delete temp; } } else { node = node-&gt;next; } } return dummy.next; }}; Java1234567891011121314151617181920212223242526272829/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */public class Solution { public ListNode deleteDuplicates(ListNode head) { if (head == null) return null; ListNode dummy = new ListNode(0); dummy.next = head; ListNode node = dummy; while(node.next != null &amp;&amp; node.next.next != null) { if (node.next.val == node.next.next.val) { int val_prev = node.next.val; while (node.next != null &amp;&amp; node.next.val == val_prev) { node.next = node.next.next; } } else { node = node.next; } } return dummy.next; }} 源码分析 首先考虑异常情况，head 为 NULL 时返回 NULL new一个dummy变量，dummy-&gt;next指向原链表头。(C++中最好不要使用 new 的方式生成 dummy, 否则会有内存泄露) 使用新变量node并设置其为dummy头节点，遍历用。 当前节点和下一节点val相同时先保存当前值，便于while循环终止条件判断和删除节点。注意这一段代码也比较精炼。 最后返回dummy-&gt;next，即题目所要求的头节点。 Python 中也可不使用is not None判断，但是效率会低一点。 复杂度分析两根指针(node.next 和 node.next.next)遍历，时间复杂度为 $$O(2n)$$. 使用了一个 dummy 和中间缓存变量，空间复杂度近似为 $$O(1)$$. Reference Remove Duplicates from Sorted List II | 九章","link":"/2019/10/19/Remove-Duplicates-from-Sorted-List-II/"},{"title":"CYK算法详解与代码实现","text":"概述在计算机科学领域，CYK算法（也称为Cocke–Younger–Kasami算法）是一种用来对上下文无关文法（CFG，Context Free Grammar）进行语法分析（parsing）的算法。该算法最早由John Cocke, Daniel Younger and Tadao Kasami分别独立提出，其中John Cocke还是1987年度的图灵奖得主。CYK算法是基于动态规划思想设计的一种自底向上语法分析算法。 乔姆斯基范式我们首先来谈谈CNF的话题。通常把一门语言定义成一些由单词组成的词串（也就是句子）构成的集合。所以如果问两种语法（或文法）是否等价，其实就是要考察它们能否生成完全一样的词串集合。事实上，两个完全不同的CFG是不可能生成相同语言的。 而谈到两种语法“等价”，我们又可以定义弱等价和强等价两种类型的等价： 如果两种语法能够生成相同的词串集合，且为每个句子都赋与相同的短语结构（phrase structure），也就是说仅允许对non-terminal symbols进行重命名，那么它们就是强等价的。 如果两种语法能够生成相同的词串集合，但不会为每个句子都赋与相同的短语结构，那么它们就是弱等价的。 CNF(Chomsky Normal Form)是一种这样的语法标准： 如果一个$CFG是 \\varepsilon-free$，而且它的规则只有如下两种形式: $A\\rightarrow BC$ $A\\rightarrow a$ 那么这个CFG就是CNF形式的，可见CNF语法都是二分叉的。任何语法都可以转化成一个弱等价的CNF形式，具体方法如下： Step 1: Convert $A\\rightarrow Bc$ to $A\\rightarrow BC$,$C\\rightarrow c$ Step 2: Convert $A\\rightarrow BCD$ to $A\\rightarrow BX,X\\rightarrow CD$ CYK算法CYK算法处理的语法必须是CNF形式的，所以如果输入的是任意文法，那么需要按照前面的步骤把CFG转换成CNF形式。 CYK算法是用来判断一个字符串是否属于某个CNF语法，故设输入的字符串w长度为n。 接下来我们需要用程序填一个动态规划的状态转移表，这里我们叫这个表parse table。 parse table的规模为$(n + 1) \\times n$ 算法原理注意，我们前面说过CYK是一种自底向上的算法，这里的自底向上意思是从单词开始，朝向 S(句子)工作。所以在上图我们填写的大方向是从左到右填写的。S 位于表的右上角，表示成功。算法描述如下：其中，i 和 j 指示的内容如下图所示： 我们定义$PT[n + 1][n]$表示parse table，且$PT[n, :]$依次存储字符串w中的每一个符号$a_1, a_2, \\dots, a_n$。$$\\begin{bmatrix}&amp; &amp;\\dots &amp; \\&amp; \\vdots &amp; \\ddots &amp; \\a_1 &amp; a_2 &amp; \\dots &amp;a_n\\end{bmatrix} %]]&gt;$$我们设根据给定CNF，即G能推导出w中第i到第j个字符的串的集合为$x_{i,j}$ 为了填写这个表，我们一行一行，自下而上地处理。每一行对应一种长度的子串。最下面一行对应长度为1的子串，倒数第二行对应长度为2的子串，以此类推。最上面一行就对应长度为n的子串，即w本身。计算该表的任何一个表项的方法如下： 对于最下面一行的元素，即$x_{i,i}$，是使得$A \\rightarrow a_i$是G的产生式的变元A的集合。 对于不在最下面一行的元素，我们需要找到符合以下条件的变元A的集合： 1、整数k满足$i \\leq k &lt; j$ 2、$B \\in X_{i,k}$ 3、$C \\in X_{k+1, j}$ 4、$A \\rightarrow BC$是G的产生式 根据这样的方法，我们可以填出一个下三角矩阵。 例如： CNF文法G的产生式：$$S \\rightarrow AB|BC \\A \\rightarrow BA|a \\B \\rightarrow CC|b \\C \\rightarrow AB|a$$对L(G)测试字符串$w = baaba$的成员性构造Parse Table如下：$$\\begin{bmatrix}x_{1,5}={S, A,C} &amp; &amp; &amp; &amp; \\&amp; x_{2,5}={S, A, C} &amp; &amp; &amp; \\&amp; x_{2,4}={B} &amp; x_{3,5}={B} &amp; &amp; \\x_{1,2} = {S, A} &amp; x_{2,3}={B} &amp; x_{3,4}={S, C} &amp; x_{4,5}={S, A} &amp;\\x_{1,1} = {B} &amp; x_{2,2} = {A, C} &amp; x_{3,3} ={A, C} &amp; x_{4,4}={B } &amp; x_{5,5}={A,C} \\a_1 = b &amp; a_2 = a &amp; a_3 = a &amp; a_4 = b &amp; a_5 = a\\end{bmatrix} %]]&gt;$$最终得到$x_{1,5}$集合之后，判断起始变元$S$是否属于$x_{1,5}$。如果是，则w可被G接受，反之不接受。 代码实现cyk.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#!usr/bin/env/python 3.6.5#-*- coding: utf-8 -*-'''Python 3.6.5installed module: - tkinter'''import reimport itertoolsimport tkinterfrom tkinter import ttkclass CNF(object): def __init__(self): self.__rules = {} def read_file(self, filename): with open(filename, 'r') as inFile: for line in inFile.readlines(): line = re.sub('[\\n\\t ]', '', line) rec_begin = line[:line.find('-')] for element in line[line.find('&gt;') + 1:].split('|'): if element in self._CNF__rules: self.__rules[element].append(rec_begin) else: self._CNF__rules[element] = [rec_begin] def get_inf(self, tar): if isinstance(tar, list) == False: exit() inf_set = [] for tarEle in tar: inf_set.extend(self.__rules.get(tarEle, [])) return list(set(inf_set))class CYK(object): def __init__(self, filename): if isinstance(filename, str) == False: exit() self.__str = '' self.__srtlen = 0 self.__canvas = [] self.__myCNF = CNF() self.__myCNF.read_file(filename) def get_str(self): self._CYK__str = input('input string:\\n').strip() if len(self._CYK__str) == 0: exit() self._CYK__srtlen = len(self._CYK__str) # MaxRow == MaxCol + 1 self._CYK__canvas = list(list([] for tmp in range(self._CYK__srtlen)) for tmp in range(self._CYK__srtlen + 1)) for iter in range(self._CYK__srtlen): self._CYK__canvas[self._CYK__srtlen][iter].append(self._CYK__str[iter]) def CYK_process(self): # for lowest level for col in range(self._CYK__srtlen): self._CYK__canvas[self._CYK__srtlen - 1][col].extend(self._CYK__myCNF.get_inf(self._CYK__canvas[self._CYK__srtlen][col])) # for upper level for row in range(self._CYK__srtlen - 2, -1, -1): for col in range(row + 1): mid_set = set() idx_i, idx_j = col + 1, col - row + self._CYK__srtlen for mid_k in range(idx_i, idx_j): fir_row, fir_col = idx_i - mid_k - 1 + self._CYK__srtlen, idx_i - 1 sec_row, sec_col = mid_k - idx_j + self._CYK__srtlen, mid_k mid_set |= set(obj[0] + obj[1] for obj in itertools.product(self._CYK__canvas[fir_row][fir_col], self._CYK__canvas[sec_row][sec_col])) self._CYK__canvas[row][col].extend(self._CYK__myCNF.get_inf(list(mid_set))) # get answer if 'S' in self._CYK__canvas[0][0]: print ('%s can be accepted.' % self._CYK__str) else: print ('%s can not be accepted.' % self._CYK__str) def GUI_show(self): def exc(line, step, row): if isinstance(line, list) == False and isinstance(line[0], list) == False: exit() for col in range(len(line)): line[col] = str('{' + '%s, ' * (len(line[col]) - 1) + '%s' * (len(line[col]) &gt; 0) + '}') % (tuple(line[col])) if col &lt;= row: line[col] = 'X%d,%d = ' % (col + 1, step + col + 1) + line[col] return (line) # default window = tkinter.Tk() window.geometry('800x400') window.title('CYK algorithm') table = ttk.Treeview(window, height = 10, show = 'headings') table['columns'] = (list(elem for elem in range(self._CYK__srtlen))) for col in range(self._CYK__srtlen): table.column(str(col), width = 100) # y&amp;x scrollbar yscrollbar = tkinter.Scrollbar(window, orient = tkinter.VERTICAL, command = table.yview) table.configure(yscrollcommand = yscrollbar.set) yscrollbar.pack(side = tkinter.RIGHT, fill = tkinter.Y) xscrollbar = tkinter.Scrollbar(window, orient = tkinter.HORIZONTAL, command = table.xview) table.configure(xscrollcommand = xscrollbar.set) xscrollbar.pack(side = tkinter.TOP, fill = tkinter.X) # insert information for row in range(self._CYK__srtlen): table.insert('', row, values = exc(self._CYK__canvas[row], self._CYK__srtlen - row - 1, row)) table.insert('', self._CYK__srtlen, values = (self._CYK__canvas[self._CYK__srtlen])) # end table.pack(side = tkinter.TOP, expand = 1, fill = tkinter.BOTH) window.mainloop()def main(): myCYK = CYK('./CNF.cfg') myCYK.get_str() myCYK.CYK_process() myCYK.GUI_show()if __name__ == '__main__': main() 实验效果 参考文献概率上下文无关文法PCFG Tagging Problems, and Hidden Markov Models NLP底层技术之语言模型","link":"/2018/07/15/CYK%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%E4%B8%8E%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},{"title":"数据类型","text":"&emsp;&emsp;MLlib既支持保存在单台机器上的本地向量和矩阵，也支持备份在一个或多个RDD中的分布式矩阵。本地向量和本地矩阵是简单的数据模型，作为公共接口提供。底层的线性代数操作通过Breeze和jblas提供。在MLlib中，用于有监督学习的训练样本称为标注点(labeled point)。 本地向量(Local vector)&emsp;&emsp;一个本地向量拥有从0开始的integer类型的索引以及double类型的值，它保存在单台机器上面。MLlib支持两种类型的本地向量：稠密(dense)向量和稀疏(sparse)向量。一个稠密向量通过一个double类型的数组保存数据，这个数组表示向量的条目值(entry values)；一个稀疏向量通过两个并行的数组（indices和values）保存数据。例如，一个向量(1.0, 0.0, 3.0)可以以稠密的格式保存为[1.0, 0.0, 3.0] 或者以稀疏的格式保存为(3, [0, 2], [1.0, 3.0])，其中3表示数组的大小。 &emsp;&emsp;本地向量的基类是Vector，Spark提供了两种实现：DenseVector和SparseVector。Spark官方推荐使用Vectors中实现的工厂方法去创建本地向量。下面是创建本地向量的例子。 1234567import org.apache.spark.mllib.linalg.{Vector, Vectors}// 创建一个dense vector (1.0, 0.0, 3.0).val dv: Vector = Vectors.dense(1.0, 0.0, 3.0)// 创建一个sparse vector (1.0, 0.0, 3.0)并且指定它的索引和值val sv1: Vector = Vectors.sparse(3, Array(0, 2), Array(1.0, 3.0))// 创建一个sparse vector (1.0, 0.0, 3.0)并且指定它的索引和值val sv2: Vector = Vectors.sparse(3, Seq((0, 1.0), (2, 3.0))) &emsp;&emsp; 注意，Scala默认引入scala.collection.immutable.Vector，这里我们需要主动引入MLLib中的org.apache.spark.mllib.linalg.Vector来操作。我们可以看看Vectors对象的部分方法。 1234567891011121314151617def dense(firstValue: Double, otherValues: Double*): Vector = new DenseVector((firstValue +: otherValues).toArray)def dense(values: Array[Double]): Vector = new DenseVector(values)def sparse(size: Int, indices: Array[Int], values: Array[Double]): Vector = new SparseVector(size, indices, values)def sparse(size: Int, elements: Seq[(Int, Double)]): Vector = { require(size &gt; 0, &quot;The size of the requested sparse vector must be greater than 0.&quot;) val (indices, values) = elements.sortBy(_._1).unzip var prev = -1 indices.foreach { i =&gt; require(prev &lt; i, s&quot;Found duplicate indices: $i.&quot;) prev = i } require(prev &lt; size, s&quot;You may not write an element to index $prev because the declared &quot; + s&quot;size of your vector is $size&quot;) new SparseVector(size, indices.toArray, values.toArray) } 标注点(Labeled point)&emsp;&emsp;一个标注点就是一个本地向量（或者是稠密的或者是稀疏的），这个向量和一个标签或者响应相关联。在MLlib中，标注点用于有监督学习算法。我们用一个double存储标签，这样我们就可以在回归和分类中使用标注点。对于二分类，一个标签可能是0或者是1；对于多分类，一个标签可能代表从0开始的类别索引。 &emsp;&emsp;在MLlib中，一个标注点通过样本类LabeledPoint表示。 123456789@Since(&quot;0.8.0&quot;)@BeanInfocase class LabeledPoint @Since(&quot;1.0.0&quot;) ( @Since(&quot;0.8.0&quot;) label: Double, @Since(&quot;1.0.0&quot;) features: Vector) { override def toString: String = { s&quot;($label,$features)&quot; }} &emsp;&emsp;下面是使用LabeledPoint的一个例子。 123456import org.apache.spark.mllib.linalg.Vectorsimport org.apache.spark.mllib.regression.LabeledPoint// Create a labeled point with a positive label and a dense feature vector.val pos = LabeledPoint(1.0, Vectors.dense(1.0, 0.0, 3.0))// Create a labeled point with a negative label and a sparse feature vector.val neg = LabeledPoint(0.0, Vectors.sparse(3, Array(0, 2), Array(1.0, 3.0))) &emsp;&emsp;在现实的应用中，训练数据是稀疏的情况非常常见，MLlib支持读取训练数据存储为LIBSVM格式。它是LIBSVM和LIBLINEAR默认的格式。它是一种文本格式，每一行表示一个标注的稀疏特征向量，如下所示： 1label index1:value1 index2:value2 ... 本地矩阵（Local matrix）&emsp;&emsp;一个本地矩阵拥有Integer类型的行和列索引以及Double类型的值。MLlib支持稠密矩阵和稀疏矩阵两种。稠密矩阵将条目(entry)值保存为单个double数组，这个数组根据列的顺序存储。稀疏矩阵的非零条目值保存为压缩稀疏列（Compressed Sparse Column ，CSC）格式，这种格式也是以列顺序存储。例如下面的稠密矩阵： &emsp;&emsp;这个稠密矩阵保存为一维数组[1.0, 3.0, 5.0, 2.0, 4.0, 6.0]，数组大小为(3,2)。 &emsp;&emsp;本地矩阵的基类是Matrix，它提供了两种实现：DenseMatrix和SparseMatrix。推荐使用Matrices的工厂方法来创建本地矩阵。下面是一个实现的例子： 12345import org.apache.spark.mllib.linalg.{Matrix, Matrices}// Create a dense matrix ((1.0, 2.0), (3.0, 4.0), (5.0, 6.0))val dm: Matrix = Matrices.dense(3, 2, Array(1.0, 3.0, 5.0, 2.0, 4.0, 6.0))// Create a sparse matrix ((9.0, 0.0), (0.0, 8.0), (0.0, 6.0))val sm: Matrix = Matrices.sparse(3, 2, Array(0, 1, 3), Array(0, 2, 1), Array(9, 6, 8)) &emsp;&emsp;稠密矩阵的存储很简单，不赘述。稀疏矩阵的存储使用CSC。关于压缩矩阵的介绍，请参看文献【1】。 分布式矩阵(Distributed matrix)&emsp;&emsp;一个分布式矩阵拥有long类型的行和列索引，以及double类型的值，分布式的存储在一个或多个RDD中。选择正确的格式存储大型分布式矩阵是非常重要的。将一个分布式矩阵转换为另外一个格式可能需要一个全局的shuffle，这是非常昂贵的。到目前为止，已经实现了三种类型的分布式矩阵。 &emsp;&emsp;基本的类型是RowMatrix，RowMatrix是一个面向行的分布式矩阵，它没有有意义的行索引。它的行保存为一个RDD,每一行都是一个本地向量。我们假设一个RowMatrix的列的数量不是很巨大，这样单个本地向量可以方便的和driver通信，也可以被单个节点保存和操作。IndexedRowMatrix和RowMatrix很像，但是它拥有行索引，行索引可以用于识别行和进行join操作。CoordinateMatrix是一个分布式矩阵，它使用COO格式存储。请参看文献【1】了解COO格式。 RowMatrix&emsp;&emsp;RowMatrix是一个面向行的分布式矩阵，它没有有意义的行索引。它的行保存为一个RDD,每一行都是一个本地向量。因为每一行保存为一个本地向量，所以列数限制在了整数范围。 &emsp;&emsp;一个RowMatrix可以通过RDD[Vector]实例创建。创建完之后，我们可以计算它的列的统计和分解。QR分解的形式为A=QR，其中Q是一个正交矩阵，R是一个上三角矩阵。下面是一个RowMatrix的例子。 12345678910import org.apache.spark.mllib.linalg.Vectorimport org.apache.spark.mllib.linalg.distributed.RowMatrixval rows: RDD[Vector] = ... // an RDD of local vectors// Create a RowMatrix from an RDD[Vector].val mat: RowMatrix = new RowMatrix(rows)// Get its size.val m = mat.numRows()val n = mat.numCols()// QR decomposition val qrResult = mat.tallSkinnyQR(true) IndexedRowMatrix&emsp;&emsp;IndexedRowMatrix和RowMatrix很像，但是它拥有行索引。索引的行保存为一个RDD[IndexedRow]，其中IndexedRow是一个参数为(Long, Vector)的样本类，所以每一行通过它的索引以及一个本地向量表示。 &emsp;&emsp;一个IndexedRowMatrix可以通过RDD[IndexedRow]实例创建，并且一个IndexedRowMatrix可以通过去掉它的行索引，转换成RowMatrix。下面是一个例子： 123456789import org.apache.spark.mllib.linalg.distributed.{IndexedRow, IndexedRowMatrix, RowMatrix}val rows: RDD[IndexedRow] = ... // an RDD of indexed rows// Create an IndexedRowMatrix from an RDD[IndexedRow].val mat: IndexedRowMatrix = new IndexedRowMatrix(rows)// Get its size.val m = mat.numRows()val n = mat.numCols()// Drop its row indices.val rowMat: RowMatrix = mat.toRowMatrix() &emsp;&emsp; IndexedRow这个样本类的代码如下： 1case class IndexedRow(index: Long, vector: Vector) CoordinateMatrix&emsp;&emsp;CoordinateMatrix是一个分布式矩阵，它的条目保存为一个RDD。每一个条目是一个(i: Long, j: Long, value: Double)格式的元组，其中i表示行索引，j表示列索引，value表示条目值。CoordinateMatrix应该仅仅在矩阵维度很大并且矩阵非常稀疏的情况下使用。 &emsp;&emsp;CoordinateMatrix可以通过RDD[MatrixEntry]实例创建，其中MatrixEntry是(Long, Long, Double)的包装。CoordinateMatrix可以转换成IndexedRowMatrix。下面是一个例子： 123456789import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, MatrixEntry}val entries: RDD[MatrixEntry] = ... // an RDD of matrix entries// Create a CoordinateMatrix from an RDD[MatrixEntry].val mat: CoordinateMatrix = new CoordinateMatrix(entries)// Get its size.val m = mat.numRows()val n = mat.numCols()// Convert it to an IndexRowMatrix whose rows are sparse vectors.val indexedRowMatrix = mat.toIndexedRowMatrix() &emsp;&emsp; MatrixEntry这个样本类的代码如下： 1case class MatrixEntry(i: Long, j: Long, value: Double) BlockMatrix&emsp;&emsp;BlockMatrix是一个分布式矩阵，它的保存为一个MatrixBlocks的RDD。MatrixBlock是一个((Int, Int), Matrix)类型的元组，其中(Int, Int)代表块的索引，Matrix代表子矩阵。BlockMatrix支持诸如add和multiply等方法。BlockMatrix还有一个帮助方法validate，用来判断一个BlockMatrix是否正确的创建。 &emsp;&emsp;可以轻松的通过调用toBlockMatrix从一个IndexedRowMatrix或者CoordinateMatrix创建一个BlockMatrix。toBlockMatrix默认创建1024 * 1024大小的块，用户可以手动修个块的大小。下面是一个例子： 1234567891011import org.apache.spark.mllib.linalg.distributed.{BlockMatrix, CoordinateMatrix, MatrixEntry}val entries: RDD[MatrixEntry] = ... // an RDD of (i, j, v) matrix entries// Create a CoordinateMatrix from an RDD[MatrixEntry].val coordMat: CoordinateMatrix = new CoordinateMatrix(entries)// Transform the CoordinateMatrix to a BlockMatrixval matA: BlockMatrix = coordMat.toBlockMatrix().cache()// Validate whether the BlockMatrix is set up properly. Throws an Exception when it is not valid.// Nothing happens if it is valid.matA.validate()// Calculate A^T A.val ata = matA.transpose.multiply(matA) 参考文献【1】稀疏矩阵存储格式总结+存储效率对比:COO,CSR,DIA,ELL,HYB","link":"/2019/08/05/data-type/"},{"title":"Git 与 GitHub 入门实践","text":"git配置优先级：--local &gt; --global &gt; --system 用了--global这个参数，表示你这台机器上所有的Git仓库都会使用这个配置 配置git用户名和邮箱1234git config --global user.name # 查看git config --global user.name 用户名 # 修改git config --global user.email # 查看git config --global user.email 邮箱 # 修改 仓库创建git仓库12git init 仓库名 #创建一个git仓库git init #将一个项目转化为使用git管理（创建.git目录） 示例： 目录结构： 12345678910project |------.git |--------branches |--------config #仓库的配置文件 |--------description |--------HEAD |--------hooks |--------info |--------objects |--------refs 隐藏目录.git不算工作区，而是Git的版本库 查看仓库状态1git status 远程仓库 最早，肯定只有一台机器有一个原始版本库，此后，别的机器可以“克隆”这个原始版本库，而且每台机器的版本库其实都是一样的，并没有主次之分 实际情况往往是这样，找一台电脑充当服务器的角色，每天24小时开机，其他每个人都从这个“服务器”仓库克隆一份到自己的电脑上，并且各自把各自的提交推送到服务器仓库里，也从服务器仓库中拉取别人的提交 GitHub就是提供Git仓库托管服务的，所以，只要注册一个GitHub账号，就可以免费获得Git远程仓库，即Github为我们的git仓库提供了一个远程仓库，有了这个远程仓库，妈妈再也不用担心我的硬盘了 为本地与GitHub的通信配置ssh本地git仓库和GitHub上的远程仓库之间的传输是通过SSH加密的，所以，需要一点设置： 创建ssh key： 1ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 登录你的GitHub帐号，Settings -&gt; SSH and GPG keys -&gt; new SSH key ，将id_rsa.pub的内容复制进去 为什么GitHub需要SSH Key呢？因为GitHub需要识别出你推送的提交确实是你推送的，而不是别人冒充的，而Git支持SSH协议，所以，GitHub只要知道了你的公钥，就可以确认只有你自己才能推送 让本地git仓库和远程仓库同步 在有了本地git仓库后，还需创建对应的远程仓库 在GitHub上创建远程仓库（如果已有则省略） 为本地仓库设置远程仓库信息（如果同时需要为本地仓库添加多个远程仓库（如果github+码云），则可以将origin分别换成github和gitee，推送操作时也要修改origin。添加后，远程库的名字就是origin，这是Git默认的叫法，也可以改成别的，但是origin这个名字一看就知道是远程库） 1git remote add origin https://github.com/用户名/仓库名 删除本地仓库的远程仓库信息：git remote remove origin 修改远端地址：git remote set-url 新地址 查看远程仓库信息：git remote -v 将本地git仓库push到远程仓库 1234# 由于远程库是空的，我们第一次推送master分支时，加上了-u参数,Git不但会把本地的# master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master# 分支关联起来，在以后的推送或者拉取时就可以简化命令git push [-u] origin 分支名 并不是一定要把本地分支往远程推送。哪些分支需要推送、哪些不需要呢？ master：主分支，要时刻与远程同步 dev：开发分支，团队所有成员都需要在上面工作，所有也需要与远程同步 bug：只用于在本地修复bug，就没必要推送到远程了，除非老板要看看你每周修复了几个bug 协同工作拉取分支： 1git pull git clone时，默认情况下只能看到本地的master分支。如果要在dev分支上开发，就必须创建远程origin的dev分支到本地，可以使用如下命令创建本地dev分支： 1git checkout -b dev 将本地dev分支与远程origin/dev分支关联起来： 1git branch --set-upstream dev origin/dev 使用GitHubBootstrap的官方仓库twbs/bootstrap、你在GitHub上克隆的仓库my/bootstrap，以及你自己克隆到本地电脑的仓库，他们的关系就像下图显示的那样： 如果你想修复bootstrap的一个bug，或者新增一个功能，立刻就可以开始干活，干完后，往自己的仓库推送 如果你希望bootstrap的官方库能接受你的修改，你就可以在GitHub上发起一个pull request。当然，对方是否接受你的pull request就不一定了 版本控制隐藏目录.git不算工作区，而是Git的版本库。版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区。还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD 添加或删除修改将修改添加到暂存区： 1git add 文件/目录 从暂存区删除修改： 1git rm --cached 文件/目录 以下命令可以将暂存区的修改重置，暂存区的改变会被移除到工作区： 1git reset HEAD [文件名] 以下命令可以丢弃工作区的修改： 1git checkout -- [文件名] 如果刚对一个文件进行了编辑，可以撤销文件的改变，回到编辑开始。命令其实起到“一键恢复”的作用，还可用于“误删恢复”。可以在 git reset HEAD [文件名] 后使用 提交版本如果修改了readme.txt，添加了文件LICENSE，并将2者添加到暂存区后，暂存区的状态就变成这样： 使用commit提交修改，实际上就是把暂存区的所有内容提交到当前分支： 1git commit -m '信息' commit相当于游戏里面一次存档。对应一个版本 文件删除rm做出的删除不会被暂存，git rm做出的改变会被暂存。如果使用rm删除掉，能使用git rm来暂存。git rm不在意文件已经不存在了 删除(暂存)单个文件 1git rm 删除(暂存)多个文件（一般情况下，更可能是对大量文件进行管理。可能同时会删除很多文件，不可能使用git rm一个个删除） 12# 它会变量当前目录，将所有删除暂存git add -u . 如果有文件被误删，可以使用git checkout -- 文件名恢复 工作现场保存与恢复有时候在修复bug或某项任务还未完成，但是需要紧急处理另外一个问题。此时可以先保存工作现场，当问题处理完成后，再恢复bug或任务的进度 保存工作现场：git stash 查看保存的工作现场：git stash list 恢复工作现场：git stash apply 删除stash内容：git stash drop 恢复工作现场并删除stash内容（相当于上面2步合并）：git stash pop 改动查询1234567git diff [选项] # 查看工作区中的修改git diff [选项] --staged # 查看已添加到暂存区的修改git diff [选项] HEAD # 查看当前所有未提交的修改选项： --color-words： 颜色 --stat： 不显示具体修改，只显示修改了的文件 版本回退123456git reset --hard 版本ID/HEAD形式的版本git reset --hard HEAD # 当前版本git reset --hard HEAD^ # 上一个版本git reset --hard HEAD^^ # 上上个版本git reset --hard HEAD~n # 前n个版本 如果回到过去的版本，想要回到原来新的版本： 如果终端未关，可以找到新版本的id，通过上述命令回去新版本 如果终端已关，git reflog查看版本，再通过上述命令回去新版本 查看历史提交1234567git log [选项]选项： --online：只显示提交提示信息 --stat：添加每次提交包含的文件信息 --path：查看每次提交改变的内容 --graph 加文件名可以显示具体文件相关的所有提交信息 分支管理创建与合并分支每次commit相当于一次存档，对应一个版本。Git都把它们串成一条时间线，这条时间线就是一个分支。master就是主分支。HEAD指向当前分支，而master指向主分支的最近提交。每次提交，master分支都会向前移动一步 当创建一个分支时，如dev，Git创建一个指针dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： 从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： 合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 上面的合并使用的是Fast forward。这种模式下，删除分支后，会丢掉分支信息。如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的提交，这样，从分支历史上就可以看出分支信息。通过在git merge命令中使用--no-ff选项禁用Fast forward模式。比如在合并dev时： 1git merge --no-ff -m &quot;merge with no-ff&quot; dev 由于会生成一个新的提交，所以需要使用-m指明新提交的信息。此时分支情况如下： 相关命令如下： (创建分支并)切换到新分支：git checkout -b 新分支 创建分支：git branch 新分支 切换分支：git checkout 欲切换到的分支 查看当前分支：git branch 合并某分支到当前分支：git merge 欲合并到当前分支的分支 查看历史分支情况：git log --graph --pretty=oneline --abbrev-commit 删除未合并的分支：git branch -D 分支 分支合并冲突如果两个分支修改了同一文件，合并时会发生冲突。比如master分支和feature1分支都修改了readme.txt文件，各自都有新的提交： 这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突。此时readme.txt文件会变成如下形式： 123456789Git is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，此时需要手动修改后保存。然后再使用git commit进行一次提交。分支会变成如下： 分支管理策略在实际开发中，我们应该按照几个基本原则进行分支管理 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活 干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了 所以，团队合作的分支看起来就像这样： 当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin 要查看远程库的信息，用git remote： 12$ git remoteorigin 或者，用git remote -v显示更详细的信息： 123$ git remote -vorigin git@github.com:michaelliao/learngit.git (fetch)origin git@github.com:michaelliao/learngit.git (push) 上面显示了可以抓取和推送的origin的地址。如果没有推送权限，就看不到push的地址 推送分支1git push origin 欲推送的分支 master分支是主分支，因此要时刻与远程同步 dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步 bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发","link":"/2015/02/28/git/"},{"title":"保序回归","text":"保序回归&emsp;&emsp;保序回归解决了下面的问题：给定包含n个数据点的序列 y_1,y_2,...,y_n , 怎样通过一个单调的序列 beta_1,beta_2,...,beta_n 来归纳这个问题。形式上，这个问题就是为了找到 &emsp;&emsp;大部分时候，我们会在括号前加上权重w_i。解决这个问题的一个方法就是 pool adjacent violators algorithm(PAVA) 算法。粗略的讲，PAVA算法的过程描述如下： &emsp;&emsp;我们从左边的y_1开始，右移y_1直到我们遇到第一个违例(violation)即y_i &lt; y_i+1，然后，我们用违例之前的所有y的平方替换这些y，以满足单调性。我们继续这个过程，直到我们最后到达y_n。 近似保序&emsp;&emsp;给定一个序列y_1,y_2,...,y_n，我们寻找一个近似单调估计，考虑下面的问题 &emsp;&emsp;在上式中，X_+表示正数部分，即X_+ = X.1 (x&gt;0)。这是一个凸优化问题，处罚项处罚违反单调性（即beta_i &gt; beta_i+1）的邻近对。 &emsp;&emsp;在公式（2）中，隐含着一个假设，即使用等距的网格测量数据点。如果情况不是这样，那么可以修改惩罚项为下面的形式 &emsp;&emsp;x_i表示y_i测量得到的值。 近似保序算法流程&emsp;&emsp;这个算法是标准PAVA算法的修改版本，它并不从数据的左端开始，而是在需要时连接相邻的点，以产生近似保序最优的顺序。相比一下，PAVA对中间的序列并不特别感兴趣，只关心最后的序列。 &emsp;&emsp;有下面一个引理成立。 &emsp;&emsp;这个引理证明的事实极大地简化了近似保序解路径（solution path）的构造。假设在参数值为lambda的情况下，有K_lambda个连接块，我们用A_1,A_2,..,A_K_lambda表示。这样我们可以重写（2）为如下（3）的形式。 &emsp;&emsp;上面的公式，对beta求偏导，可以得到下面的次梯度公式。通过这个公式即可以求得beta。 &emsp;&emsp;为了符合方便，令s_0 = s_K_lambda = 0。并且， &emsp;&emsp;现在假设，当lambda在一个区间内增长时，组A_1,A_2,...,A_K_lambda不会改变。我们可以通过相应的lambda区分（4）。 &emsp;&emsp;这个公式的值本身是一个常量，它意味着上式的beta是lambda的线性函数。 &emsp;&emsp;随着lambda的增长，方程（5）将连续的给出解决方案的斜率直到组A_1,A_2,...,A_K_lambda改变。更加引理1，只有两个组合并时，这才会发生。m_i表示斜率，那么对于每一个i=1,...,K_lambda - 1，A_i和A_i+1合并之后得到的公式如下 &emsp;&emsp;因此我们可以一直移动，直到lambda “下一个”值的到来 &emsp;&emsp;并且合并A_i^star和A_i^star+1,其中 &emsp;&emsp;注意，可能有超过一对组别到达了这个最小值，在这种情况下，会组合所有满足条件的组别。公式（7）和（8）成立的条件是t_i,i+1大于lambda，如果没有t_i,i+1大于lambda，说明没有组别可以合并，算法将会终止。 &emsp;&emsp;算法的流程如下： 初始时，lambda=0，K_lambda=n,A_i={i},i=1,2,...,n。对于每个i，解是beta_lambda,i = y_i 重复下面过程 &emsp;&emsp;1、通过公式（5）计算每个组的斜率m_i &emsp;&emsp;2、通过公式（6）计算没对相邻组的碰撞次数t_i,i+1 &emsp;&emsp;3、如果t_i,i+1 &lt; lambda，终止 &emsp;&emsp;4、计算公式（7）中的临界点lambda^star,并根据斜率更新解 &emsp;&emsp;对于每个i，根据公式（8）合并合适的组别（所以K_lambda^star = K_lambda - 1），并设置lambda = lambda^star。 源码分析&emsp;&emsp;在1.6.x版本中，并没有实现近似保序回归，后续会实现。现在我们只介绍一般的保序回归算法实现。 实例12345678910111213141516171819202122import org.apache.spark.mllib.regression.{IsotonicRegression, IsotonicRegressionModel}val data = sc.textFile(&quot;data/mllib/sample_isotonic_regression_data.txt&quot;)// 创建（label, feature, weight） tuples ，权重默认设置为1.0val parsedData = data.map { line =&gt; val parts = line.split(',').map(_.toDouble) (parts(0), parts(1), 1.0)}// Split data into training (60%) and test (40%) sets.val splits = parsedData.randomSplit(Array(0.6, 0.4), seed = 11L)val training = splits(0)val test = splits(1)// Create isotonic regression model from training data.// Isotonic parameter defaults to true so it is only shown for demonstrationval model = new IsotonicRegression().setIsotonic(true).run(training)// Create tuples of predicted and real labels.val predictionAndLabel = test.map { point =&gt; val predictedLabel = model.predict(point._2) (predictedLabel, point._1)}// Calculate mean squared error between predicted and real labels.val meanSquaredError = predictionAndLabel.map { case (p, l) =&gt; math.pow((p - l), 2) }.mean()println(&quot;Mean Squared Error = &quot; + meanSquaredError) 训练过程分析&emsp;&emsp;parallelPoolAdjacentViolators方法用于实现保序回归的训练。parallelPoolAdjacentViolators方法的代码如下： 1234567891011private def parallelPoolAdjacentViolators( input: RDD[(Double, Double, Double)]): Array[(Double, Double, Double)] = { val parallelStepResult = input //以（feature，label）为key进行排序 .sortBy(x =&gt; (x._2, x._1)) .glom()//合并不同分区的数据为一个数组 .flatMap(poolAdjacentViolators) .collect() .sortBy(x =&gt; (x._2, x._1)) // Sort again because collect() doesn't promise ordering. poolAdjacentViolators(parallelStepResult) } &emsp;&emsp;parallelPoolAdjacentViolators方法的主要实现是poolAdjacentViolators方法，该方法主要的实现过程如下： 123456789101112131415161718192021var i = 0val len = input.lengthwhile (i &lt; len) { var j = i //找到破坏单调性的元祖的index while (j &lt; len - 1 &amp;&amp; input(j)._1 &gt; input(j + 1)._1) { j = j + 1 } // 如果没有找到违规点，移动到下一个数据点 if (i == j) { i = i + 1 } else { // 否则用pool方法处理违规的节点 // 并且检查pool之后，之前处理过的节点是否违反了单调性约束 while (i &gt;= 0 &amp;&amp; input(i)._1 &gt; input(i + 1)._1) { pool(input, i, j) i = i - 1 } i = j }} &emsp;&emsp;pool方法的实现如下所示。 123456789101112131415def pool(input: Array[(Double, Double, Double)], start: Int, end: Int): Unit = { //取得i到j之间的元组组成的子序列 val poolSubArray = input.slice(start, end + 1) //求子序列sum（label * w）之和 val weightedSum = poolSubArray.map(lp =&gt; lp._1 * lp._3).sum //求权重之和 val weight = poolSubArray.map(_._3).sum var i = start //子区间的所有元组标签相同，即拥有相同的预测 while (i &lt;= end) { //修改标签值为两者之商 input(i) = (weightedSum / weight, input(i)._2, input(i)._3) i = i + 1 }} &emsp;&emsp;经过上文的处理之后，input根据中的label和feature均是按升序排列。对于拥有相同预测的点，我们只保留两个特征边界点。 1234567891011121314151617181920212223242526val compressed = ArrayBuffer.empty[(Double, Double, Double)]var (curLabel, curFeature, curWeight) = input.headvar rightBound = curFeaturedef merge(): Unit = { compressed += ((curLabel, curFeature, curWeight)) if (rightBound &gt; curFeature) { compressed += ((curLabel, rightBound, 0.0)) }}i = 1while (i &lt; input.length) { val (label, feature, weight) = input(i) if (label == curLabel) { //权重叠加 curWeight += weight rightBound = feature } else {//如果标签不同，合并 merge() curLabel = label curFeature = feature curWeight = weight rightBound = curFeature } i += 1}merge() &emsp;&emsp;最后将训练的结果保存为模型。 12345//标签集val predictions = if (isotonic) pooled.map(_._1) else pooled.map(-_._1)//特征集val boundaries = pooled.map(_._2)new IsotonicRegressionModel(boundaries, predictions, isotonic) 预测过程分析123456789101112131415161718192021222324def predict(testData: Double): Double = { def linearInterpolation(x1: Double, y1: Double, x2: Double, y2: Double, x: Double): Double = { y1 + (y2 - y1) * (x - x1) / (x2 - x1) } //二分查找index val foundIndex = binarySearch(boundaries, testData) val insertIndex = -foundIndex - 1 // Find if the index was lower than all values, // higher than all values, in between two values or exact match. if (insertIndex == 0) { predictions.head } else if (insertIndex == boundaries.length){ predictions.last } else if (foundIndex &lt; 0) { linearInterpolation( boundaries(insertIndex - 1), predictions(insertIndex - 1), boundaries(insertIndex), predictions(insertIndex), testData) } else { predictions(foundIndex) } } &emsp;&emsp;当测试数据精确匹配一个边界，那么返回相应的特征。如果测试数据比所有边界都大或者小，那么分别返回第一个和最后一个特征。当测试数据位于两个边界之间，使用linearInterpolation方法计算特征。这个方法是线性内插法。","link":"/2019/07/13/isotonic-regression/"},{"title":"流式&#96;k-means&#96;算法","text":"&emsp;&emsp;当数据是以流的方式到达的时候，我们可能想动态的估计（estimate ）聚类的簇，通过新的到达的数据来更新聚类。spark.mllib支持流式k-means聚类，并且可以通过参数控制估计衰减（decay）(或“健忘”(forgetfulness))。这个算法使用一般地小批量更新规则来更新簇。 流式k-means算法原理&emsp;&emsp;对每批新到的数据，我们首先将点分配给距离它们最近的簇，然后计算新的数据中心，最后更新每一个簇。使用的公式如下所示： &emsp;&emsp;在上面的公式中，$c_{t}$表示前一个簇中心，$n_{t}$表示分配给这个簇的点的数量，$x_{t}$表示从当前批数据的簇中心，$m_{t}$表示当前批数据的点数量。当评价新的数据时，把衰减因子alpha当做折扣加权应用到当前的点上，用以衡量当前预测的簇的贡献度量。当alpha等于1时，所有的批数据赋予相同的权重，当alpha等于0时，数据中心点完全通过当前数据确定。 &emsp;&emsp;衰减因子alpha也可以通过halfLife参数联合时间单元（time unit）来确定，时间单元可以是一批数据也可以是一个数据点。假如数据从t时刻到来并定义了halfLife为h，在t+h时刻，应用到t时刻的数据的折扣（discount）为0.5。 &emsp;&emsp;流式k-means算法的步骤如下所示： （1）分配新的数据点到离其最近的簇； （2）根据时间单元（time unit）计算折扣（discount）值，并更新簇权重； （3）应用更新规则； （4）应用更新规则后，有些簇可能消失了，那么切分最大的簇为两个簇。 流式k-means算法源码分析&emsp;&emsp;在分步骤分析源码之前，我们先了解一下StreamingKMeans参数表达的含义。 12345class StreamingKMeans( var k: Int, //簇个数 var decayFactor: Double,//衰减因子 var timeUnit: String //时间单元) &emsp;&emsp;在上述定义中，k表示我们要聚类的个数，decayFactor表示衰减因子，用于计算折扣，timeUnit表示时间单元，时间单元既可以是一批数据（StreamingKMeans.BATCHES）也可以是单条数据（StreamingKMeans.POINTS）。 &emsp;&emsp;由于我们处理的是流式数据，所以我们在流式数据来之前要先初始化模型。有两种初始化模型的方法，一种是直接指定初始化中心点及簇权重，一种是随机初始化中心点以及簇权重。 12345678910111213//直接初始化中心点及簇权重def setInitialCenters(centers: Array[Vector], weights: Array[Double]): this.type = { model = new StreamingKMeansModel(centers, weights) this}//随机初始化中心点以及簇权重def setRandomCenters(dim: Int, weight: Double, seed: Long = Utils.random.nextLong): this.type = { val random = new XORShiftRandom(seed) val centers = Array.fill(k)(Vectors.dense(Array.fill(dim)(random.nextGaussian()))) val weights = Array.fill(k)(weight) model = new StreamingKMeansModel(centers, weights) this} &emsp;&emsp;初始化中心点以及簇权重之后，对于新到的流数据，我们使用更新规则修改中心点和权重，调整聚类情况。更新过程在update方法中实现，下面我们分步骤分析该方法。 （1）分配新到的数据到离其最近的簇，并计算更新后的簇的向量和以及点数量 123456789101112131415//选择离数据点最近的簇val closest = data.map(point =&gt; (this.predict(point), (point, 1L)))def predict(point: Vector): Int = { //返回和给定点相隔最近的中心 KMeans.findClosest(clusterCentersWithNorm, new VectorWithNorm(point))._1}// 获得更新的簇的向量和以及点数量val mergeContribs: ((Vector, Long), (Vector, Long)) =&gt; (Vector, Long) = (p1, p2) =&gt; { // y += a * x,向量相加 BLAS.axpy(1.0, p2._1, p1._1) (p1._1, p1._2 + p2._2)}val pointStats: Array[(Int, (Vector, Long))] = closest .aggregateByKey((Vectors.zeros(dim), 0L))(mergeContribs, mergeContribs) .collect() （2）获取折扣值，并用折扣值作用到权重上 1234567891011121314// 折扣val discount = timeUnit match { case StreamingKMeans.BATCHES =&gt; decayFactor case StreamingKMeans.POINTS =&gt; //所有新增点的数量和 val numNewPoints = pointStats.view.map { case (_, (_, n)) =&gt; n }.sum // x^y math.pow(decayFactor, numNewPoints)}//将折扣应用到权重上//x = a * xBLAS.scal(discount, Vectors.dense(clusterWeights)) &emsp;&emsp;上面的代码更加时间单元的不同获得不同的折扣值。当时间单元为StreamingKMeans.BATCHES时，折扣就为衰减因子；当时间单元为StreamingKMeans.POINTS时，折扣由新增数据点的个数n和衰减因子decay共同决定。折扣值为n个decay相乘。 （3）实现更新规则 12345678910111213// 实现更新规则pointStats.foreach { case (label, (sum, count)) =&gt; //获取中心点 val centroid = clusterCenters(label) //更新权重 val updatedWeight = clusterWeights(label) + count val lambda = count / math.max(updatedWeight, 1e-16) clusterWeights(label) = updatedWeight //x = a * x,即（1-lambda）*centroid BLAS.scal(1.0 - lambda, centroid) // y += a * x，即centroid +=sum*lambda/count BLAS.axpy(lambda / count, sum, centroid)} &emsp;&emsp;上面的代码对每一个簇，首先更新簇的权重，权重值为原有的权重加上新增数据点的个数。然后计算lambda，通过lambda更新中心点。lambda为新增数据的个数和更新权重的商。假设更新之前的中心点为c1，更新之后的中心点为c2，那么c2=(1-lambda)*c1+sum/count，其中sum/count为所有点的平均值。 （4）调整权重最小和最大的簇 12345678910111213141516171819202122val weightsWithIndex = clusterWeights.view.zipWithIndex//获取权重值最大的簇val (maxWeight, largest) = weightsWithIndex.maxBy(_._1)//获取权重值最小的簇val (minWeight, smallest) = weightsWithIndex.minBy(_._1)//判断权重最小的簇是否过小，如果过小，就将这两个簇重新划分为两个新的簇，权重为两者的均值if (minWeight &lt; 1e-8 * maxWeight) { logInfo(s&quot;Cluster $smallest is dying. Split the largest cluster $largest into two.&quot;) val weight = (maxWeight + minWeight) / 2.0 clusterWeights(largest) = weight clusterWeights(smallest) = weight val largestClusterCenter = clusterCenters(largest) val smallestClusterCenter = clusterCenters(smallest) var j = 0 while (j &lt; dim) { val x = largestClusterCenter(j) val p = 1e-14 * math.max(math.abs(x), 1.0) largestClusterCenter.toBreeze(j) = x + p smallestClusterCenter.toBreeze(j) = x - p j += 1 } }","link":"/2019/07/31/streaming-k-means/"},{"title":"Permutation Sequence","text":"Question leetcode: Permutation Sequence | LeetCode OJ lintcode: (388) Permutation Sequence Problem StatementGiven n and k, return the k-th permutation sequence. ExampleFor n = 3, all permutations are listed as follows: &quot;123&quot; &quot;132&quot; &quot;213&quot; &quot;231&quot; &quot;312&quot; &quot;321&quot; If k = 4, the fourth permutation is &quot;231&quot; Noten will be between 1 and 9 inclusive. ChallengeO(n*k) in time complexity is easy, can you do it in O(n^2) or less? 题解和题 Permutation Index 正好相反，这里给定第几个排列的相对排名，输出排列值。和不同进制之间的转化类似，这里的『进制』为1!, 2!..., 以n=3, k=4为例，我们从高位到低位转化，直觉应该是用 k/(n-1)!, 但以 n=3,k=5 和 n=3,k=6 代入计算后发现边界处理起来不太方便，故我们可以尝试将 k 减1进行运算，后面的基准也随之变化。第一个数可以通过(k-1)/(n-1)!进行计算，那么第二个数呢？联想不同进制数之间的转化，我们可以通过求模运算求得下一个数的k-1, 那么下一个数可通过(k2 - 1)/(n-2)!求得，这里不理解的可以通过进制转换类比进行理解。和减掉相应的阶乘值是等价的。 Python12345678910111213141516171819202122class Solution: &quot;&quot;&quot; @param n: n @param k: the k-th permutation @return: a string, the k-th permutation &quot;&quot;&quot; def getPermutation(self, n, k): # generate factorial list factorial = [1] for i in xrange(1, n + 1): factorial.append(factorial[-1] * i) nums = range(1, n + 1) perm = [] for i in xrange(n): rank = (k - 1) / factorial[n - i - 1] k = (k - 1) % factorial[n - i - 1] + 1 # append and remove nums[rank] perm.append(nums[rank]) nums.remove(nums[rank]) # combine digits return &quot;&quot;.join([str(digit) for digit in perm]) C++12345678910111213141516171819202122232425262728293031323334class Solution {public: /** * @param n: n * @param k: the kth permutation * @return: return the k-th permutation */ string getPermutation(int n, int k) { // generate factorial list vector&lt;int&gt; factorial = vector&lt;int&gt;(n + 1, 1); for (int i = 1; i &lt; n + 1; ++i) { factorial[i] = factorial[i - 1] * i; } // generate digits ranging from 1 to n vector&lt;int&gt; nums; for (int i = 1; i &lt; n + 1; ++i) { nums.push_back(i); } vector&lt;int&gt; perm; for (int i = 0; i &lt; n; ++i) { int rank = (k - 1) / factorial[n - i - 1]; k = (k - 1) % factorial[n - i - 1] + 1; // append and remove nums[rank] perm.push_back(nums[rank]); nums.erase(std::remove(nums.begin(), nums.end(), nums[rank]), nums.end()); } // transform a vector&lt;int&gt; to a string std::stringstream result; std::copy(perm.begin(), perm.end(), std::ostream_iterator&lt;int&gt;(result, &quot;&quot;)); return result.str(); }}; Java1234567891011121314151617181920212223242526272829303132class Solution { /** * @param n: n * @param k: the kth permutation * @return: return the k-th permutation */ public String getPermutation(int n, int k) { if (n &lt;= 0 &amp;&amp; k &lt;= 0) return &quot;&quot;; int fact = 1; // generate nums 1 to n List&lt;Integer&gt; nums = new ArrayList&lt;Integer&gt;(); for (int i = 1; i &lt;= n; i++) { fact *= i; nums.add(i); } // get the permutation digit StringBuilder sb = new StringBuilder(); for (int i = n; i &gt;= 1; i--) { fact /= i; // take care of rank and k int rank = (k - 1) / fact; k = (k - 1) % fact + 1; // ajust the mapping of rank to num sb.append(nums.get(rank)); nums.remove(rank); } return sb.toString(); }} 源码分析源码结构分为三步走， 建阶乘数组 生成排列数字数组 从高位到低位计算排列数值 复杂度分析几个 for 循环，时间复杂度为 $$O(n)$$, 用了与 n 等长的一些数组，空间复杂度为 $$O(n)$$. Reference Permutation Sequence 解题报告 Permutation Sequence 参考程序 Java/C++/Python c++ - How to transform a vector into a string? - Stack Overflow","link":"/2019/04/30/permutation_sequence/"},{"title":"条件随机场CRF(三) 模型学习与维特比算法解码","text":"在CRF系列的前两篇，我们总结了CRF的模型基础与第一个问题的求解方法，本文我们关注于linear-CRF的第二个问题与第三个问题的求解。第二个问题是模型参数学习的问题，第三个问题是维特比算法解码的问题。 linear-CRF模型参数学习思路在linear-CRF模型参数学习问题中，我们给定训练数据集$X$和对应的标记序列$Y$，$K$个特征函数$f_k(x,y)$，需要学习linear-CRF的模型参数$w_k$和条件概率$P_w(y|x)$，其中条件概率$P_w(y|x)$和模型参数$w_k$满足一下关系：$$P_w(y|x) = P(y|x) = \\frac{1}{Z_w(x)}exp\\sum\\limits_{k=1}^Kw_kf_k(x,y) = \\frac{exp\\sum\\limits_{k=1}^Kw_kf_k(x,y)}{\\sum\\limits_{y}exp\\sum\\limits_{k=1}^Kw_kf_k(x,y)}$$所以我们的目标就是求出所有的模型参数$w_k$，这样条件概率$P_w(y|x)$可以从上式计算出来。 求解这个问题有很多思路，比如梯度下降法，牛顿法，拟牛顿法。同时，这个模型中$P_w(y|x)$的表达式和最大熵模型原理小结中的模型一样，也可以使用最大熵模型中使用的改进的迭代尺度法(improved iterative scaling, IIS)来求解。 下面我们只简要介绍用梯度下降法的求解思路。 linear-CRF模型参数学习之梯度下降法求解在使用梯度下降法求解模型参数之前，我们需要定义我们的优化函数，一般极大化条件分布$P_w(y|x)$的对数似然函数如下：$$L(w)= log\\prod_{x,y}P_w(y|x)^{\\overline{P}(x,y)} = \\sum\\limits_{x,y}\\overline{P}(x,y)logP_w(y|x)$$其中$\\overline{P}(x,y)$为经验分布，可以从先验知识和训练集样本中得到,这点和最大熵模型类似。为了使用梯度下降法，我们现在极小化$f(w) = -L(P_w)$如下：对$w$求导可以得到：$$\\frac{\\partial f(w)}{\\partial w} = \\sum\\limits_{x,y}\\overline{P}(x)P_w(y|x)f(x,y) - \\sum\\limits_{x,y}\\overline{P}(x,y)f(x,y)$$有了$w$的导数表达书，就可以用梯度下降法来迭代求解最优的$w$了。注意在迭代过程中，每次更新$w$后，需要同步更新$P_w(x,y)$,以用于下一次迭代的梯度计算。 梯度下降法的过程这里就不累述了，如果不熟悉梯度下降算法过程建议阅读之前写的梯度下降（Gradient Descent）小结。以上就是linear-CRF模型参数学习之梯度下降法求解思路总结。 linear-CRF模型维特比算法解码思路现在我们来看linear-CRF的第三个问题：解码。在这个问题中，给定条件随机场的条件概率$P(y|x)$和一个观测序列$x$,要求出满足$P(y|x)$最大的序列$y$。 这个解码算法最常用的还是和HMM解码类似的维特比算法。到目前为止，我已经在三个地方讲到了维特比算法，第一个是文本挖掘的分词原理中用于中文分词，第二个是隐马尔科夫模型HMM（四）维特比算法解码隐藏状态序列中用于HMM解码。第三个就是这一篇了。 维特比算法本身是一个动态规划算法，利用了两个局部状态和对应的递推公式，从局部递推到整体，进而得解。对于具体不同的问题，仅仅是这两个局部状态的定义和对应的递推公式不同而已。由于在之前已详述维特比算法，这里就是做一个简略的流程描述。 对于我们linear-CRF中的维特比算法，我们的第一个局部状态定义为$\\delta_i(l)$,表示在位置$i$标记$l$各个可能取值(1,2…m)对应的非规范化概率的最大值。之所以用非规范化概率是，规范化因子$Z(x)$不影响最大值的比较。根据$\\delta_i(l)$的定义，我们递推在位置$i+1$标记$l$的表达式为：$$\\delta_{i+1}(l) = \\max_{1 \\leq j \\leq m}{\\delta_i(j) + \\sum\\limits_{k=1}^Kw_kf_k(y_{i} =j,y_{i+1} = l,x,i)};, l=1,2,…m$$和HMM的维特比算法类似，我们需要用另一个局部状态$\\Psi_{i+1}(l)$来记录使$\\delta_{i+1}(l)$达到最大的位置$i$的标记取值,这个值用来最终回溯最优解，$\\delta_{i+1}(l)$的递推表达式为：$$\\Psi_{i+1}(l) = arg;\\max_{1 \\leq j \\leq m}{\\delta_i(j) + \\sum\\limits_{k=1}^Kw_kf_k(y_{i} =j,y_{i+1} = l,x,i)}; ,l=1,2,…m$$ linear-CRF模型维特比算法流程现在我们总结下 linear-CRF模型维特比算法流程： 输入：模型的$K$个特征函数，和对应的K个权重。观测序列$x=(x_1,x_2,…x_n)$,可能的标记个数$m$ 输出：最优标记序列$y^* =(y_1^*,y_2^*,…y_n^*)$ 初始化：$$\\delta_{1}(l) = \\sum\\limits_{k=1}^Kw_kf_k(y_{0} =start,y_{1} = l,x,i)};, l=1,2,…m$$$$\\Psi_{1}(l) = start;, l=1,2,…m$$ 对于$i=1,2…n-1$,进行递推：$$\\delta_{i+1}(l) = \\max_{1 \\leq j \\leq m}{\\delta_i(j) + \\sum\\limits_{k=1}^Kw_kf_k(y_{i} =j,y_{i+1} = l,x,i)};, l=1,2,…m$$$$\\Psi_{i+1}(l) = arg;\\max_{1 \\leq j \\leq m}{\\delta_i(j) + \\sum\\limits_{k=1}^Kw_kf_k(y_{i} =j,y_{i+1} = l,x,i)}; ,l=1,2,…m$$ 终止：$$y_n^* = arg;\\max_{1 \\leq j \\leq m}\\delta_n(j)$$ 回溯：$$y_i^* = \\Psi_{i+1}(y_{i+1}^*);, i=n-1,n-2,…1$$最终得到最优标记序列$y^* =(y_1^*,y_2^*,…y_n^*)$ linear-CRF模型维特比算法实例下面用一个具体的例子来描述 linear-CRF模型维特比算法，例子的模型和CRF系列第一篇中一样，都来源于《统计学习方法》。 假设输入的都是三个词的句子，即$X=(X_1,X_2,X_3)$,输出的词性标记为$Y=(Y_1,Y_2,Y_3)$,其中$Y \\in {1(名词)，2(动词)}$ 这里只标记出取值为1的特征函数如下：$$t_1 =t_1(y_{i-1} = 1, y_i =2,x,i), i =2,3,;;\\lambda_1=1 \\t_2 =t_2(y_1=1,y_2=1,x,2);;\\lambda_2=0.6 \\t_3 =t_3(y_2=2,y_3=1,x,3);;\\lambda_3=1 \\t_4 =t_4(y_1=2,y_2=1,x,2);;\\lambda_4=1 \\t_5 =t_5(y_2=2,y_3=2,x,3);;\\lambda_5=0.2 \\s_1 =s_1(y_1=1,x,1);;\\mu_1 =1 \\s_2 =s_2( y_i =2,x,i), i =1,2,;;\\mu_2=0.5 \\s_3 =s_3( y_i =1,x,i), i =2,3,;;\\mu_3=0.8 \\s_4 =s_4(y_3=2,x,3);;\\mu_4 =0.5$$求标记(1,2,2)的最可能的标记序列。 首先初始化:$$\\delta_1(1) = \\mu_1s_1 = 1;;;\\delta_1(2) = \\mu_2s_2 = 0.5;;;\\Psi_{1}(1) =\\Psi_{1}(2) = start$$接下来开始递推，先看位置2的：$$\\delta_2(1) = max{\\delta_1(1) + t_2\\lambda_2+\\mu_3s_3, \\delta_1(2) + t_4\\lambda_4+\\mu_3s_3 } = max{1+0.6+0.8,0.5+1+0.8} =2.4;;;\\Psi_{2}(1) =1$$$$\\delta_2(2) = max{\\delta_1(1) + t_1\\lambda_1+\\mu_2s_2, \\delta_1(2) + \\mu_2s_2} = max{1+1+0.5,0.5+0.5} =2.5;;;\\Psi_{2}(2) =1$$再看位置3的：$$\\delta_3(1) = max{\\delta_2(1) +\\mu_3s_3, \\delta_2(2) + t_3\\lambda_3+\\mu_3s_3} = max{2.4+0.8,2.5+1+0.8} =4.3$$$$\\Psi_{3}(1) =2$$$$\\delta_3(2) = max{\\delta_2(1) +t_1\\lambda_1 + \\mu_4s_4, \\delta_2(2) + t_5\\lambda_5+\\mu_4s_4} = max{2.4+1+0.5,2.5+0.2+0.5} =3.9$$$$\\Psi_{3}(2) =1$$最终得到$y_3^* =\\arg;max{\\delta_3(1), \\delta_3(2)}$,递推回去，得到：$$y_2^* = \\Psi_3(1) =2;;y_1^* = \\Psi_2(2) =1$$即最终的结果为(1,2,1),即标记为(名词，动词，名词)。 linear-CRF vs HMMlinear-CRF模型和HMM模型有很多相似之处，尤其是其三个典型问题非常类似，除了模型参数学习的问题求解方法不同以外，概率估计问题和解码问题使用的算法思想基本也是相同的。同时，两者都可以用于序列模型，因此都广泛用于自然语言处理的各个方面。 现在来看看两者的不同点。最大的不同点是linear-CRF模型是判别模型，而HMM是生成模型，即linear-CRF模型要优化求解的是条件概率$P(y|x)$,则HMM要求解的是联合分布$P(x,y)$。第二，linear-CRF是利用最大熵模型的思路去建立条件概率模型，对于观测序列并没有做马尔科夫假设。而HMM是在对观测序列做了马尔科夫假设的前提下建立联合分布的模型。 最后想说的是，只有linear-CRF模型和HMM模型才是可以比较讨论的。但是linear-CRF是CRF的一个特例，CRF本身是一个可以适用于很复杂条件概率的模型，因此理论上CRF的使用范围要比HMM广泛的多。 以上就是CRF系列的所有内容。","link":"/2020/03/05/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%B8%89-%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E8%A7%A3%E7%A0%81/"},{"title":"第一篇 监督学习","text":"笔记摘要 统计学习或机器学习一般包括监督学习、无监督学习、强化学习，有时还包括半监督学习、主动学习监督学习 监督学习指从标注数据中学习预测模型的机器学习问题，其本质是学习输入到输出的映射的统计规律。 输入变量$X$和输出变量$Y$有不同的类型，可以是连续或是离散的。根据输入输出变量的不同类型，对预测任务给予不同的名称：输入与输出均为连续变量的预测问题称为回归问题；输出变量为有限个离散变量的预测问题称为分类问题；输入与输出变量均为变量序列的预测问题称为标注问题。 无监督学习 无监督学习指从无标注数据中学习预测模型的机器学习问题，其本质是学习数据中的统计规律或内在结构。 无监督学习旨在从假设空间中选出在给定评价标准下的最优模型，模型可以实现对数据的聚类、降维或是概率估计。强化学习 强化学习指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题，其本质是学习最优的序贯决策。 智能系统的目标不是短期奖励的最大化，而是长期累积奖励的最大化。强化学习过程中，系统不断地试错，以达到学习最优策略地目的。 半监督学习与主动学习 半监督学习指利用标注数据和未标注数据学习预测模型地机器学习问题。其旨在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习效果。 主动学习是指机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型的机器学习问题。主动学习的目标是找出对学习最有帮助的实例让教师标注，以较小的标注代价达到较好的学习效果。 这两种学习更接近监督学习。 实现统计学习方法的步骤 得到一个有限的训练数据集合 确定包含所有可能的模型的假设空间，即学习模型的集合 确定模型选择的准则，即学习的策略 实现求解最优模型的算法，即学习的算法 通过学习方法选择最优的模型 利用学习的最优模型对新数据进行预测或分析 在上述步骤中涵盖了统计学习方法三要素：模型，策略，算法 在监督学习过程中，模型就是所要学习的条件概率分布或者决策函数。注意书中的这部分描述，整理了一下到表格里： 假设空间$\\mathcal F$ 输入空间$\\mathcal X$ 输出空间$\\mathcal Y$ 参数空间 决策函数 $\\mathcal F ={f$|$Y=f_{\\theta}(x), \\theta \\in \\bf R \\it ^n}$ 变量 变量 $\\bf R\\it ^n$ 条件概率分布 $\\mathcal F ={P$|$P_\\theta(Y$|$X), \\theta \\in \\bf R \\it ^n}$ 随机变量 随机变量 $\\bf R\\it ^n$ 损失函数与风险函数 损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。 损失函数(loss function)或代价函数(cost function)定义为给定输入$X$的预测值$f(X)$和真实值$Y$之间的非负实值函数，记作$L(Y,f(X))$。 风险函数(risk function)或期望损失(expected loss)和模型的泛化误差的形式是一样的$R_{exp}(f)=E_p[L(Y, f(X))]=\\int_{\\mathcal X\\times\\mathcal Y}L(y,f(x))P(x,y), {\\rm d}x{\\rm d}y$上式是模型$f(X)$关于联合分布$P(X,Y)$的平均意义下的损失(期望损失)，但是因为$P(X,Y)$是未知的，所以前面的用词是期望，以及平均意义下的。这个表示其实就是损失的均值，反映了对整个数据的预测效果的好坏。 经验风险(empirical risk)或经验损失(empirical loss) $R_{emp}(f)=\\frac{1}{N}\\sum^{N}_{i=1}L(y_i,f(x_i))$ 上式是模型$f$关于训练样本集的平均损失。根据大数定律，当样本容量N趋于无穷大时，经验风险趋于期望风险。 结构风险(structural risk) $R_{srm}(f)=\\frac{1}{N}\\sum_{i=1}^{N}L(y_i,f(x_i))+\\lambda J(f)$ 其中$J(f)$为模型复杂度, $\\lambda \\geqslant 0$是系数，用以权衡经验风险和模型复杂度。 常用损失函数损失函数数值越小，模型就越好 0-1损失 $L(Y,f(X))=\\begin{cases}1, Y \\neq f(X) \\0, Y=f(X) \\end{cases}$ 平方损失 $L(Y,f(X))=(Y-f(X))^2$ 绝对损失 $L(Y,f(X))=|Y-f(X)|$ 对数损失$L(Y,P(Y|X))=−logP(Y|X)$ ERM与SRM经验风险最小化(ERM)与结构风险最小化(SRM) 极大似然估计是经验风险最小化的一个例子。当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化等价于极大似然估计，下面习题1.2中给出了证明。 结构风险最小化等价于正则化 贝叶斯估计中的最大后验概率估计是结构风险最小化的一个例子。当模型是条件概率分布，损失函数是对数损失函数，模型复杂度由模型的先验概率表示时，结构风险最小化等价于最大后验概率估计。 算法 算法是指学习模型的具体计算方法。统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么杨的计算方法来求解最优模型。 模型评估与选择 训练误差和测试误差是模型关于数据集的平均损失。 注意：统计学习方法具体采用的损失函数未必是评估时使用的损失函数。 过拟合是指学习时选择的模型所包含的参数过多，以至出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。可以说模型选择旨在避免过拟合并提高模型的预测能力。 正则化与交叉验证 模型选择的典型方法是正则化.。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化就越大。比如，正则化项可以是模型参数向量的范数。 $L(w)=\\frac{1}{N}\\sum_{i=1}^{N}(f(x_i;w)-y_i)^2+\\frac{\\lambda}{2}|w|^2$ $|w|$表示向量$w$的$L_2$范数 正则化符合奥卡姆剃刀原理：如无必要，勿增实体。在应用于模型选择中时，可以理解为：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单的才是最好的模型，也是应该选择的模型。 交叉验证的基本想法时重复地利用数据；把给定地数据进行切分，将切分的数据集组合为训练集和测试集，在此基础上反复地进行训练、测试以及模型选择。 主要有简单交叉验证，S折交叉验证，留一交叉验证三种。 在算法学习的过程中，测试集可能是固定的，但是验证集和训练集可能是变化的。比如S折交叉验证的情况下，分成S折之后，其中的S-1折作为训练集，1折作为验证集，计算这S个模型每个模型的平均测试误差，最后选择平均测试误差最小的模型。这个过程中用来验证模型效果的那一折数据就是验证集。 生成模型与判别模型监督学习方法可分为生成方法(generative approach)与判别方法(discriminative approach) 生成方法(generative approach) 可以还原出联合概率分布$P(X,Y)$ 收敛速度快, 当样本容量增加时, 学到的模型可以更快收敛到真实模型 当存在隐变量时仍可以用 判别方法(discriminative approach) 直接学习条件概率$P(Y|X)$或者决策函数$f(X)$ 直接面对预测, 往往学习准确率更高 可以对数据进行各种程度的抽象, 定义特征并使用特征, 可以简化学习问题 习题解答 1.1 说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学方法三要素 伯努利模型是定义在取值为0与1的随机变量上的概率分布。统计学分为两派：经典统计学派和贝叶斯统计学派。两者的不同主要是，经典统计学派认为模型已定，参数未知，参数是固定的，只是还不知道；贝叶斯统计学派是通过观察到的现象对概率分布中的主观认定不断进行修正。 极大似然估计用的是经典统计学派的策略，贝叶斯估计用的是贝叶斯统计学派的策略；为了得到使经验风险最小的参数值，使用的算法都是对经验风险求导，使导数为0。 定义随机变量$A$为一次伯努利试验的结果，$A$的取值为${0,1}$，概率分布为$P(A)$： $$P(A=1)=θ，P(A=0)=1-θ$$ * 极大似然估计 $$L(θ)=\\prod_{i=1}^nP(A_i)=θ^k(1-θ)^{n-k}$$$$θ=\\arg\\max_{θ}L(θ)=\\frac{k}{n}$$上述估计通过取对数求导得到，$A_i$为第$i$次随机试验 贝叶斯估计$$P(θ|A_1,A_2,…，A_n)=\\frac{P(A_1,A_2,…，A_n|θ)P(θ)}{P(A_1,A_2,…，A_n)}$$ 根据观察到的结果修正$θ$，也就是假设$θ$是随机变量，$θ$服从β分布，有很多个可能的取值，我们要取的值是在已知观察结果的条件下使$θ$出现概率最大的值。上式分母是不变的，求分子最大就可以。 $$\\begin{aligned}\\theta&amp;=arg\\max \\limits_\\theta {P(A_1,A_2,…,A_n|\\theta)P(\\theta)} \\&amp;= arg\\max \\limits_\\theta {\\prod_{i=1}^{n}P(A_i|\\theta)P(\\theta)} \\&amp;=arg \\max \\limits_\\theta {\\theta^k(1-\\theta)^{n-k}\\theta^{a-1}(1-\\theta)^{b-1}} \\&amp;=\\frac{k+(a-1)}{n+(a-1)+(b-1)}\\end{aligned}$$ β分布是一个作为伯努利分布和二项式分布的共轭先验分布的密度函数，是指一组定义在$(0,1)$区间的连续概率分布，有两个参数α，β&gt;0。选定参数后就可以确定$\\theta$。 统计学习方法的三要素为模型，策略，算法。 1.2 通过经验风险最小化推导极大似然估计。证明模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。 模型是条件概率分布：$P_θ(Y|X)$，损失函数是对数损失函数：$L(Y,P_θ(Y|X))=−logP_θ(Y|X)$经验风险为：$$ \\begin{aligned}R_{emp}(f)&amp;=\\frac{1}{N}\\sum_{i=1}^{N}L(y_i,f(x_i)) \\&amp;=\\frac{1}{N}\\sum_{i=1}^{N}-logP(y_i|x_i) \\&amp;=-\\frac{1}{N}\\sum_{i=1}^{N}logP(y_i|x_i)\\end{aligned}$$ 极大似然估计的似然函数为：$$L(\\theta)=\\prod_DP_{\\theta}(Y|X)$$ * 取对数$$log(L(\\theta))=\\sum_DlogP_{\\theta}(Y|X)$$$$arg\\max_\\theta\\sum_DlogP_{\\theta}(Y|X)=arg\\min_{\\theta}\\sum_D-logP_{\\theta}(Y|X)$$ 因此，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。","link":"/2021/05/23/%E7%AC%AC%E4%B8%80%E7%AF%87-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"title":"经典网络解读","text":"LeNet-5模型介绍​ LeNet-5是由$LeCun$ 提出的一种用于识别手写数字和机器印刷字符的卷积神经网络（Convolutional Neural Network，CNN）$^{[1]}$，其命名来源于作者$LeCun$的名字，5则是其研究成果的代号，在LeNet-5之前还有LeNet-4和LeNet-1鲜为人知。LeNet-5阐述了图像中像素特征之间的相关性能够由参数共享的卷积操作所提取，同时使用卷积、下采样（池化）和非线性映射这样的组合结构，是当前流行的大多数深度图像识别网络的基础。 模型结构 ​ 图4.1 LeNet-5网络结构图 ​ 如图4.1所示，LeNet-5一共包含7层（输入层不作为网络结构），分别由2个卷积层、2个下采样层和3个连接层组成，网络的参数配置如表4.1所示，其中下采样层和全连接层的核尺寸分别代表采样范围和连接矩阵的尺寸（如卷积核尺寸中的$“5\\times5\\times1/1,6”$表示核大小为$5\\times5\\times1$、步长为$1​$且核个数为6的卷积核）。 ​ 表4.1 LeNet-5网络参数配置 网络层 输入尺寸 核尺寸 输出尺寸 可训练参数量 卷积层$C_1$ $32\\times32\\times1$ $5\\times5\\times1/1,6$ $28\\times28\\times6$ $(5\\times5\\times1+1)\\times6$ 下采样层$S_2$ $28\\times28\\times6$ $2\\times2/2$ $14\\times14\\times6$ $(1+1)\\times6$ $^*$ 卷积层$C_3$ $14\\times14\\times6$ $5\\times5\\times6/1,16$ $10\\times10\\times16$ $1516^*$ 下采样层$S_4$ $10\\times10\\times16$ $2\\times2/2$ $5\\times5\\times16$ $(1+1)\\times16$ 卷积层$C_5$$^*$ $5\\times5\\times16$ $5\\times5\\times16/1,120$ $1\\times1\\times120$ $(5\\times5\\times16+1)\\times120$ 全连接层$F_6$ $1\\times1\\times120$ $120\\times84$ $1\\times1\\times84$ $(120+1)\\times84$ 输出层 $1\\times1\\times84$ $84\\times10$ $1\\times1\\times10$ $(84+1)\\times10$ ​ $^*$ 在LeNet中，下采样操作和池化操作类似，但是在得到采样结果后会乘以一个系数和加上一个偏置项，所以下采样的参数个数是$(1+1)\\times6​$而不是零。 ​ $^*$ $C_3$卷积层可训练参数并未直接连接$S_2$中所有的特征图（Feature Map），而是采用如图4.2所示的采样特征方式进行连接（稀疏连接），生成的16个通道特征图中分别按照相邻3个特征图、相邻4个特征图、非相邻4个特征图和全部6个特征图进行映射，得到的参数个数计算公式为$6\\times(25\\times3+1)+6\\times(25\\times4+1)+3\\times(25\\times4+1)+1\\times(25\\times6+1)=1516$，在原论文中解释了使用这种采样方式原因包含两点：限制了连接数不至于过大（当年的计算能力比较弱）;强制限定不同特征图的组合可以使映射得到的特征图学习到不同的特征模式。 ​ 图4.2 $S_2$与$C_3$之间的特征图稀疏连接 ​ $^*$ $C_5$卷积层在图4.1中显示为全连接层，原论文中解释这里实际采用的是卷积操作，只是刚好在$5\\times5$卷积后尺寸被压缩为$1\\times1​$，输出结果看起来和全连接很相似。 模型特性 卷积网络使用一个3层的序列组合：卷积、下采样（池化）、非线性映射（LeNet-5最重要的特性，奠定了目前深层卷积网络的基础） 使用卷积提取空间特征 使用映射的空间均值进行下采样 使用$tanh$或$sigmoid$进行非线性映射 多层神经网络（MLP）作为最终的分类器 层间的稀疏连接矩阵以避免巨大的计算开销 AlexNet模型介绍​ AlexNet是由$Alex$ $Krizhevsky$提出的首个应用于图像分类的深层卷积神经网络，该网络在2012年ILSVRC（ImageNet Large Scale Visual Recognition Competition）图像分类竞赛中以15.3%的top-5测试错误率赢得第一名$^{[2]}$。AlexNet使用GPU代替CPU进行运算，使得在可接受的时间范围内模型结构能够更加复杂，它的出现证明了深层卷积神经网络在复杂模型下的有效性，使CNN在计算机视觉中流行开来，直接或间接地引发了深度学习的热潮。 模型结构 ​ 图4.3 AlexNet网络结构图 ​ 如图4.3所示，除去下采样（池化层）和局部响应规范化操作（Local Responsible Normalization, LRN），AlexNet一共包含8层，前5层由卷积层组成，而剩下的3层为全连接层。网络结构分为上下两层，分别对应两个GPU的操作过程，除了中间某些层（$C_3$卷积层和$F_{6-8}$全连接层会有GPU间的交互），其他层两个GPU分别计算结 果。最后一层全连接层的输出作为$softmax$的输入，得到1000个图像分类标签对应的概率值。除去GPU并行结构的设计，AlexNet网络结构与LeNet十分相似，其网络的参数配置如表4.2所示。 ​ 表4.2 AlexNet网络参数配置 网络层 输入尺寸 核尺寸 输出尺寸 可训练参数量 卷积层$C_1$ $^*$ $224\\times224\\times3$ $11\\times11\\times3/4,48(\\times2_{GPU})$ $55\\times55\\times48(\\times2_{GPU})$ $(11\\times11\\times3+1)\\times48\\times2$ 下采样层$S_{max}$$^*$ $55\\times55\\times48(\\times2_{GPU})$ $3\\times3/2(\\times2_{GPU})$ $27\\times27\\times48(\\times2_{GPU})$ 0 卷积层$C_2$ $27\\times27\\times48(\\times2_{GPU})$ $5\\times5\\times48/1,128(\\times2_{GPU})$ $27\\times27\\times128(\\times2_{GPU})$ $(5\\times5\\times48+1)\\times128\\times2$ 下采样层$S_{max}$ $27\\times27\\times128(\\times2_{GPU})$ $3\\times3/2(\\times2_{GPU})$ $13\\times13\\times128(\\times2_{GPU})$ 0 卷积层$C_3$ $^*$ $13\\times13\\times128\\times2_{GPU}$ $3\\times3\\times256/1,192(\\times2_{GPU})$ $13\\times13\\times192(\\times2_{GPU})$ $(3\\times3\\times256+1)\\times192\\times2$ 卷积层$C_4$ $13\\times13\\times192(\\times2_{GPU})$ $3\\times3\\times192/1,192(\\times2_{GPU})$ $13\\times13\\times192(\\times2_{GPU})$ $(3\\times3\\times192+1)\\times192\\times2$ 卷积层$C_5$ $13\\times13\\times192(\\times2_{GPU})$ $3\\times3\\times192/1,128(\\times2_{GPU})$ $13\\times13\\times128(\\times2_{GPU})$ $(3\\times3\\times192+1)\\times128\\times2$ 下采样层$S_{max}$ $13\\times13\\times128(\\times2_{GPU})$ $3\\times3/2(\\times2_{GPU})$ $6\\times6\\times128(\\times2_{GPU})$ 0 全连接层$F_6$ $^*$ $6\\times6\\times128\\times2_{GPU}$ $9216\\times2048(\\times2_{GPU})$ $1\\times1\\times2048(\\times2_{GPU})$ $(9216+1)\\times2048\\times2$ 全连接层$F_7$ $1\\times1\\times2048\\times2_{GPU}$ $4096\\times2048(\\times2_{GPU})$ $1\\times1\\times2048(\\times2_{GPU})$ $(4096+1)\\times2048\\times2$ 全连接层$F_8$ $1\\times1\\times2048\\times2_{GPU}$ $4096\\times1000$ $1\\times1\\times1000$ $(4096+1)\\times1000\\times2$ 卷积层$C_1$输入为$224\\times224\\times3$的图片数据，分别在两个GPU中经过核为$11\\times11\\times3$、步长（stride）为4的卷积卷积后，分别得到两条独立的$55\\times55\\times48$的输出数据。 下采样层$v$实际上是嵌套在卷积中的最大池化操作，但是为了区分没有采用最大池化的卷积层单独列出来。在$C_{1-2}$卷积层中的池化操作之后（ReLU激活操作之前），还有一个LRN操作，用作对相邻特征点的归一化处理。 卷积层$C_3$的输入与其他卷积层不同，$13\\times13\\times192\\times2_{GPU}$表示汇聚了上一层网络在两个GPU上的输出结果作为输入，所以在进行卷积操作时通道上的卷积核维度为384。 全连接层$F_{6-8}$中输入数据尺寸也和$C_3$类似，都是融合了两个GPU流向的输出结果作为输入。 模型特性 所有卷积层都使用ReLU作为非线性映射函数，使模型收敛速度更快 在多个GPU上进行模型的训练，不但可以提高模型的训练速度，还能提升数据的使用规模 使用LRN对局部的特征进行归一化，结果作为ReLU激活函数的输入能有效降低错误率 重叠最大池化（overlapping max pooling），即池化范围z与步长s存在关系$z&gt;s$（如$S_{max}$中核尺度为$3\\times3/2$），避免平均池化（average pooling）的平均效应 使用随机丢弃技术（dropout）选择性地忽略训练中的单个神经元，避免模型的过拟合 ZFNet模型介绍​ ZFNet是由$Matthew$ $D. Zeiler$和$Rob$ $Fergus$在AlexNet基础上提出的大型卷积网络，在2013年ILSVRC图像分类竞赛中以11.19%的错误率获得冠军（实际上原ZFNet所在的队伍并不是真正的冠军，原ZFNet以13.51%错误率排在第8，真正的冠军是$Clarifai$这个队伍，而$Clarifai$这个队伍所对应的一家初创公司的CEO又是$Zeiler$，而且$Clarifai$对ZFNet的改动比较小，所以通常认为是ZFNet获得了冠军）$^{[3-4]}​$。ZFNet实际上是微调（fine-tuning）了的AlexNet，并通过反卷积（Deconvolution）的方式可视化各层的输出特征图，进一步解释了卷积操作在大型网络中效果显著的原因。 模型结构 ​ 图4.4 ZFNet网络结构图（原始结构图与AlexNet风格结构图） ​ 如图4.4所示，ZFNet与AlexNet类似，都是由8层网络组成的卷积神经网络，其中包含5层卷积层和3层全连接层。两个网络结构最大的不同在于，ZFNet第一层卷积采用了$7\\times7\\times3/2$的卷积核替代了AlexNet中第一层卷积核$11\\times11\\times3/4$的卷积核。图4.5中ZFNet相比于AlexNet在第一层输出的特征图中包含更多中间频率的信息，而AlexNet第一层输出的特征图大多是低频或高频的信息，对中间频率特征的缺失导致后续网络层次如图4.5（c）能够学习到的特征不够细致，而导致这个问题的根本原因在于AlexNet在第一层中采用的卷积核和步长过大。 ​ 图4.5 （a）ZFNet第一层输出的特征图（b）AlexNet第一层输出的特征图（c）AlexNet第二层输出的特征图（d）ZFNet第二层输出的特征图 ​ 表4.3 ZFNet网络参数配置​| 网络层 | 输入尺寸 | 核尺寸 | 输出尺寸 | 可训练参数量 || :——————-: | :———————————-: | :————————————–: | :———————————-: | :————————————-: || 卷积层$C_1$ $^*$ | $224\\times224\\times3$ | $7\\times7\\times3/2,96$ | $110\\times110\\times96$ | $(7\\times7\\times3+1)\\times96$ || 下采样层$S_{max}$ | $110\\times110\\times96$ | $3\\times3/2$ | $55\\times55\\times96$ | 0 || 卷积层$C_2$ $^*$ | $55\\times55\\times96$ | $5\\times5\\times96/2,256$ | $26\\times26\\times256$ | $(5\\times5\\times96+1)\\times256$ || 下采样层$S_{max}$ | $26\\times26\\times256$ | $3\\times3/2$ | $13\\times13\\times256$ | 0 || 卷积层$C_3$ | $13\\times13\\times256$ | $3\\times3\\times256/1,384$ | $13\\times13\\times384$ | $(3\\times3\\times256+1)\\times384$ || 卷积层$C_4$ | $13\\times13\\times384$ | $3\\times3\\times384/1,384$ | $13\\times13\\times384$ | $(3\\times3\\times384+1)\\times384$ || 卷积层$C_5$ | $13\\times13\\times384$ | $3\\times3\\times384/1,256$ | $13\\times13\\times256$ | $(3\\times3\\times384+1)\\times256$ || 下采样层$S_{max}$ | $13\\times13\\times256$ | $3\\times3/2$ | $6\\times6\\times256$ | 0 || 全连接层$F_6$ | $6\\times6\\times256$ | $9216\\times4096$ | $1\\times1\\times4096$ | $(9216+1)\\times4096$ || 全连接层$F_7$ | $1\\times1\\times4096$ | $4096\\times4096$ | $1\\times1\\times4096$ | $(4096+1)\\times4096$ || 全连接层$F_8$ | $1\\times1\\times4096$ | $4096\\times1000$ | $1\\times1\\times1000$ | $(4096+1)\\times1000$ | 卷积层$C_1$与AlexNet中的$C_1$有所不同，采用$7\\times7\\times3/2$的卷积核代替$11\\times11\\times3/4​$，使第一层卷积输出的结果可以包含更多的中频率特征，对后续网络层中多样化的特征组合提供更多选择，有利于捕捉更细致的特征。 卷积层$C_2$采用了步长2的卷积核，区别于AlexNet中$C_2$的卷积核步长，所以输出的维度有所差异。 模型特性​ ZFNet与AlexNet在结构上几乎相同，此部分虽属于模型特性，但准确地说应该是ZFNet原论文中可视化技术的贡献。 可视化技术揭露了激发模型中每层单独的特征图。 可视化技术允许观察在训练阶段特征的演变过程且诊断出模型的潜在问题。 可视化技术用到了多层解卷积网络，即由特征激活返回到输入像素空间。 可视化技术进行了分类器输出的敏感性分析，即通过阻止部分输入图像来揭示那部分对于分类是重要的。 可视化技术提供了一个非参数的不变性来展示来自训练集的哪一块激活哪个特征图，不仅需要裁剪输入图片，而且自上而下的投影来揭露来自每块的结构激活一个特征图。 可视化技术依赖于解卷积操作，即卷积操作的逆过程，将特征映射到像素上。 Network in Network模型介绍​ Network In Network (NIN)是由$Min Lin$等人提出，在CIFAR-10和CIFAR-100分类任务中达到当时的最好水平，因其网络结构是由三个多层感知机堆叠而被成为NIN$^{[5]}$。NIN以一种全新的角度审视了卷积神经网络中的卷积核设计，通过引入子网络结构代替纯卷积中的线性映射部分，这种形式的网络结构激发了更复杂的卷积神经网络的结构设计，其中下一节中介绍的GoogLeNet的Inception结构就是来源于这个思想。 模型结构​ 图 4.6 NIN网络结构图 ​ NIN由三层的多层感知卷积层（MLPConv Layer）构成，每一层多层感知卷积层内部由若干层的局部全连接层和非线性激活函数组成，代替了传统卷积层中采用的线性卷积核。在网络推理（inference）时，这个多层感知器会对输入特征图的局部特征进行划窗计算，并且每个划窗的局部特征图对应的乘积的权重是共享的，这两点是和传统卷积操作完全一致的，最大的不同在于多层感知器对局部特征进行了非线性的映射，而传统卷积的方式是线性的。NIN的网络参数配置表4.4所示（原论文并未给出网络参数，表中参数为编者结合网络结构图和CIFAR-100数据集以$3\\times3$卷积为例给出）。 ​ 表4.4 NIN网络参数配置（结合原论文NIN结构和CIFAR-100数据给出） 网络层 输入尺寸 核尺寸 输出尺寸 参数个数 局部全连接层$L_{11}$ $^*$ $32\\times32\\times3$ $(3\\times3)\\times16/1$ $30\\times30\\times16$ $(3\\times3\\times3+1)\\times16$ 全连接层$L_{12}$ $^*$ $30\\times30\\times16$ $16\\times16$ $30\\times30\\times16$ $((16+1)\\times16)$ 局部全连接层$L_{21}$ $30\\times30\\times16$ $(3\\times3)\\times64/1$ $28\\times28\\times64$ $(3\\times3\\times16+1)\\times64$ 全连接层$L_{22}$ $28\\times28\\times64$ $64\\times64$ $28\\times28\\times64$ $((64+1)\\times64)$ 局部全连接层$L_{31}$ $28\\times28\\times64$ $(3\\times3)\\times100/1$ $26\\times26\\times100$ $(3\\times3\\times64+1)\\times100$ 全连接层$L_{32}$ $26\\times26\\times100$ $100\\times100$ $26\\times26\\times100$ $((100+1)\\times100)$ 全局平均采样$GAP$ $^*$ $26\\times26\\times100$ $26\\times26\\times100/1$ $1\\times1\\times100$ $0$ 局部全连接层$L_{11}$实际上是对原始输入图像进行划窗式的全连接操作，因此划窗得到的输出特征尺寸为$30\\times30$（$\\frac{32-3_k+1}{1_{stride}}=30$）全连接层$L_{12}$是紧跟$L_{11}$后的全连接操作，输入的特征是划窗后经过激活的局部响应特征，因此仅需连接$L_{11}$和$L_{12}$的节点即可，而每个局部全连接层和紧接的全连接层构成代替卷积操作的多层感知卷积层（MLPConv）。全局平均采样层或全局平均池化层$GAP$（Global Average Pooling）将$L_{32}$输出的每一个特征图进行全局的平均池化操作，直接得到最后的类别数，可以有效地减少参数量。 模型特点 使用多层感知机结构来代替卷积的滤波操作，不但有效减少卷积核数过多而导致的参数量暴涨问题，还能通过引入非线性的映射来提高模型对特征的抽象能力。 使用全局平均池化来代替最后一个全连接层，能够有效地减少参数量（没有可训练参数），同时池化用到了整个特征图的信息，对空间信息的转换更加鲁棒，最后得到的输出结果可直接作为对应类别的置信度。 VGGNet模型介绍​ VGGNet是由牛津大学视觉几何小组（Visual Geometry Group, VGG）提出的一种深层卷积网络结构，他们以7.32%的错误率赢得了2014年ILSVRC分类任务的亚军（冠军由GoogLeNet以6.65%的错误率夺得）和25.32%的错误率夺得定位任务（Localization）的第一名（GoogLeNet错误率为26.44%）$^{[5]}$，网络名称VGGNet取自该小组名缩写。VGGNet是首批把图像分类的错误率降低到10%以内模型，同时该网络所采用的$3\\times3$卷积核的思想是后来许多模型的基础，该模型发表在2015年国际学习表征会议（International Conference On Learning Representations, ICLR）后至今被引用的次数已经超过1万4千余次。 模型结构 ​ 图 4.7 VGG16网络结构图 ​ 在原论文中的VGGNet包含了6个版本的演进，分别对应VGG11、VGG11-LRN、VGG13、VGG16-1、VGG16-3和VGG19，不同的后缀数值表示不同的网络层数（VGG11-LRN表示在第一层中采用了LRN的VGG11，VGG16-1表示后三组卷积块中最后一层卷积采用卷积核尺寸为$1\\times1$，相应的VGG16-3表示卷积核尺寸为$3\\times3$），本节介绍的VGG16为VGG16-3。图4.7中的VGG16体现了VGGNet的核心思路，使用$3\\times3$的卷积组合代替大尺寸的卷积（2个$3\\times3卷积即可与$$5\\times5$卷积拥有相同的感受视野），网络参数设置如表4.5所示。 ​ 表4.5 VGG16网络参数配置 网络层 输入尺寸 核尺寸 输出尺寸 参数个数 卷积层$C_{11}$ $224\\times224\\times3$ $3\\times3\\times64/1$ $224\\times224\\times64$ $(3\\times3\\times3+1)\\times64$ 卷积层$C_{12}$ $224\\times224\\times64$ $3\\times3\\times64/1$ $224\\times224\\times64$ $(3\\times3\\times64+1)\\times64$ 下采样层$S_{max1}$ $224\\times224\\times64$ $2\\times2/2$ $112\\times112\\times64$ $0$ 卷积层$C_{21}$ $112\\times112\\times64$ $3\\times3\\times128/1$ $112\\times112\\times128$ $(3\\times3\\times64+1)\\times128$ 卷积层$C_{22}$ $112\\times112\\times128$ $3\\times3\\times128/1$ $112\\times112\\times128$ $(3\\times3\\times128+1)\\times128$ 下采样层$S_{max2}$ $112\\times112\\times128$ $2\\times2/2$ $56\\times56\\times128$ $0$ 卷积层$C_{31}$ $56\\times56\\times128$ $3\\times3\\times256/1$ $56\\times56\\times256$ $(3\\times3\\times128+1)\\times256$ 卷积层$C_{32}$ $56\\times56\\times256$ $3\\times3\\times256/1$ $56\\times56\\times256$ $(3\\times3\\times256+1)\\times256$ 卷积层$C_{33}$ $56\\times56\\times256$ $3\\times3\\times256/1$ $56\\times56\\times256$ $(3\\times3\\times256+1)\\times256$ 下采样层$S_{max3}$ $56\\times56\\times256$ $2\\times2/2$ $28\\times28\\times256$ $0$ 卷积层$C_{41}$ $28\\times28\\times256$ $3\\times3\\times512/1$ $28\\times28\\times512$ $(3\\times3\\times256+1)\\times512$ 卷积层$C_{42}$ $28\\times28\\times512$ $3\\times3\\times512/1$ $28\\times28\\times512$ $(3\\times3\\times512+1)\\times512$ 卷积层$C_{43}$ $28\\times28\\times512$ $3\\times3\\times512/1$ $28\\times28\\times512$ $(3\\times3\\times512+1)\\times512$ 下采样层$S_{max4}$ $28\\times28\\times512$ $2\\times2/2$ $14\\times14\\times512$ $0$ 卷积层$C_{51}$ $14\\times14\\times512$ $3\\times3\\times512/1$ $14\\times14\\times512$ $(3\\times3\\times512+1)\\times512$ 卷积层$C_{52}$ $14\\times14\\times512$ $3\\times3\\times512/1$ $14\\times14\\times512$ $(3\\times3\\times512+1)\\times512$ 卷积层$C_{53}$ $14\\times14\\times512$ $3\\times3\\times512/1$ $14\\times14\\times512$ $(3\\times3\\times512+1)\\times512$ 下采样层$S_{max5}$ $14\\times14\\times512$ $2\\times2/2$ $7\\times7\\times512$ $0$ 全连接层$FC_{1}$ $7\\times7\\times512$ $(7\\times7\\times512)\\times4096$ $1\\times4096$ $(7\\times7\\times512+1)\\times4096$ 全连接层$FC_{2}$ $1\\times4096$ $4096\\times4096$ $1\\times4096$ $(4096+1)\\times4096$ 全连接层$FC_{3}$ $1\\times4096$ $4096\\times1000$ $1\\times1000$ $(4096+1)\\times1000$ 模型特性 整个网络都使用了同样大小的卷积核尺寸$3\\times3$和最大池化尺寸$2\\times2$。 $1\\times1$卷积的意义主要在于线性变换，而输入通道数和输出通道数不变，没有发生降维。 两个$3\\times3$的卷积层串联相当于1个$5\\times5$的卷积层，感受野大小为$5\\times5$。同样地，3个$3\\times3$的卷积层串联的效果则相当于1个$7\\times7$的卷积层。这样的连接方式使得网络参数量更小，而且多层的激活函数令网络对特征的学习能力更强。 VGGNet在训练时有一个小技巧，先训练浅层的的简单网络VGG11，再复用VGG11的权重来初始化VGG13，如此反复训练并初始化VGG19，能够使训练时收敛的速度更快。 在训练过程中使用多尺度的变换对原始数据做数据增强，使得模型不易过拟合。 GoogLeNet模型介绍​ GoogLeNet作为2014年ILSVRC在分类任务上的冠军，以6.65%的错误率力压VGGNet等模型，在分类的准确率上面相比过去两届冠军ZFNet和AlexNet都有很大的提升。从名字GoogLeNet可以知道这是来自谷歌工程师所设计的网络结构，而名字中GoogLeNet更是致敬了LeNet$^{[0]}$。GoogLeNet中最核心的部分是其内部子网络结构Inception，该结构灵感来源于NIN，至今已经经历了四次版本迭代（Inception$_{v1-4}$）。 ​ 图 4.8 Inception性能比较图 模型结构​ 图 4.9 GoogLeNet网络结构图​ 如图4.9中所示，GoogLeNet相比于以前的卷积神经网络结构，除了在深度上进行了延伸，还对网络的宽度进行了扩展，整个网络由许多块状子网络的堆叠而成，这个子网络构成了Inception结构。图4.9为Inception的四个版本：$Inception_{v1}​$在同一层中采用不同的卷积核，并对卷积结果进行合并;$Inception_{v2}​$组合不同卷积核的堆叠形式，并对卷积结果进行合并;$Inception_{v3}​$则在$v_2​$基础上进行深度组合的尝试;$Inception_{v4}​$结构相比于前面的版本更加复杂，子网络中嵌套着子网络。 $Inception_{v1}$ $Inception_{v2}$ $Inception_{v3}$ $Inception_{v4}$ ​ 图 4.10 Inception$_{v1-4}$结构图 ​ 表 4.6 GoogLeNet中Inception$_{v1}$网络参数配置 网络层 输入尺寸 核尺寸 输出尺寸 参数个数 卷积层$C_{11}$ $H\\times{W}\\times{C_1}$ $1\\times1\\times{C_2}/2$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $(1\\times1\\times{C_1}+1)\\times{C_2}$ 卷积层$C_{21}$ $H\\times{W}\\times{C_2}$ $1\\times1\\times{C_2}/2$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $(1\\times1\\times{C_2}+1)\\times{C_2}$ 卷积层$C_{22}$ $H\\times{W}\\times{C_2}$ $3\\times3\\times{C_2}/1$ $H\\times{W}\\times{C_2}/1$ $(3\\times3\\times{C_2}+1)\\times{C_2}$ 卷积层$C_{31}$ $H\\times{W}\\times{C_1}$ $1\\times1\\times{C_2}/2$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $(1\\times1\\times{C_1}+1)\\times{C_2}$ 卷积层$C_{32}$ $H\\times{W}\\times{C_2}$ $5\\times5\\times{C_2}/1$ $H\\times{W}\\times{C_2}/1$ $(5\\times5\\times{C_2}+1)\\times{C_2}$ 下采样层$S_{41}$ $H\\times{W}\\times{C_1}$ $3\\times3/2$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $0$ 卷积层$C_{42}$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $1\\times1\\times{C_2}/1$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}$ $(3\\times3\\times{C_2}+1)\\times{C_2}$ 合并层$M$ $\\frac{H}{2}\\times\\frac{W}{2}\\times{C_2}(\\times4)$ 拼接 $\\frac{H}{2}\\times\\frac{W}{2}\\times({C_2}\\times4)$ $0$ 模型特性 采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合； 之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了； 网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。但是，使用5x5的卷积核仍然会带来巨大的计算量。 为此，文章借鉴NIN2，采用1x1卷积核来进行降维。 为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？ 评测对比：为了让自己的结果更有说服力，在发表自己成果的时候会同一个标准的baseline及在baseline上改进而进行比较，常见的比如各种检测分割的问题都会基于VGG或者Resnet101这样的基础网络。 时间和精力有限：在科研压力和工作压力中，时间和精力只允许大家在有限的范围探索。 模型创新难度大：进行基本模型的改进需要大量的实验和尝试，并且需要大量的实验积累和强大灵感，很有可能投入产出比比较小。 资源限制：创造一个新的模型需要大量的时间和计算资源，往往在学校和小型商业团队不可行。 在实际的应用场景中，其实是有大量的非标准模型的配置。 参考文献[1] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, november 1998. [2] A. Krizhevsky, I. Sutskever and G. E. Hinton. ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems 25. Curran Associates, Inc. 1097–1105. [3] LSVRC-2013. http://www.image-net.org/challenges/LSVRC/2013/results.php [4] M. D. Zeiler and R. Fergus. Visualizing and Understanding Convolutional Networks. European Conference on Computer Vision. [5] M. Lin, Q. Chen, and S. Yan. Network in network. Computing Research Repository, abs/1312.4400, 2013. [6] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale Image Recognition. International Conference on Machine Learning, 2015. [7] Bharath Raj. a-simple-guide-to-the-versions-of-the-inception-network, 2018. [8] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi. Inception-v4, Inception-ResNet andthe Impact of Residual Connections on Learning, 2016. [9] Sik-Ho Tsang. review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification, 2018. [10] Zbigniew Wojna, Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens. Rethinking the Inception Architecture for Computer Vision, 2015. [11] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. Going deeper with convolutions, 2014.","link":"/2019/10/28/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E8%A7%A3%E8%AF%BB/"},{"title":"Google Go语言 语法笔记","text":"包 Package包的声明 Declare 使用package关键字声明当前源文件所在的包包声明语句是所有源文件的第一行非注释语句包名称中不能包含空白字符包名推荐与源文件所在的目录名称保持一致每个目录中只能定义一个package 12345package cxy // 声明一个名为“cxy”的包package 我的包 // 声明一个名为“我的包”的包package main // main包, 程序启动执行的入口包 错误的包声明 12345package &quot;mypkg&quot; // 错误package a/b/c // 错误pakcage a.b.c // 错误 包的导入 Import 导入包路径是对应包在$GOROOT/pkg/$GOOS_$GOARCH/、$GOPATH/pkg/$GOOS_$GOARCH/或当前路径中的相对路径 1234567// 导入$GOROOT/$GOOS_$GOARCH/中的相对路径包(官方标准库)import &quot;fmt&quot;import &quot;math/rand&quot;// 导入$GOPATH/$GOOS_$GOARCH/中的相对路径包import &quot;github.com/user/project/pkg&quot;import &quot;code.google.com/p/project/pkg&quot; 导入当前包的相对路径包例如有Go目录如下：$GOPATH/src ├─x0 │ ├─y0 │ │ └─z0 │ └─y1 │ └─z1 └─x1 └─y2 123import &quot;./y0/z0&quot; // x0包中导入子包 z0包import &quot;../y0/z0&quot; // y1包中导入子包 z0包import &quot;x0/y1/z1&quot; // y2包中导入 z1包 错误的导入包路径 123import a/b/c // 错误import &quot;a.b.c&quot; // 错误import a.b.c // 错误 用圆括号组合导入包路径 123456import (&quot;fmt&quot;; &quot;math&quot;)import ( &quot;fmt&quot; &quot;math&quot;) 导入包可以定义别名，防止同名称的包冲突 123456789import ( &quot;a/b/c&quot; c1 &quot;x/y/c&quot; // 将导入的包c定义别名为 c1 格式化 &quot;fmt&quot; // 将导入的包fmt定义别名为 格式化 m &quot;math&quot; // 将导入的包math定义别名为 m) 引用包名是导入包路径的最后一个目录中定义的唯一包的名称定义的包名与目录同名时，直接引用即可 12345// 引用普通名称的导入包c.hello()// 引用定义别名的包格式化.Println(m.Pi) 定义的包名与所在目录名称不同时，导入包路径仍为目录所在路径，引用包名为定义的包名称 123// 源文件路径: $GOPATH/src/proj/my-util/util.go// 定义包名: utilpackage util 12345// 导入util包路径import &quot;proj/my-util&quot;// 引用util包util.doSomething() 静态导入，在导入的包路径之前增加一个小数点. 12345// 类似C中的include 或Java中的import staticimport . &quot;fmt&quot;// 然后像使用本包元素一样使用fmt包中可见的元素，不需要通过包名引用Println(&quot;no need package name&quot;) 导入包但不直接使用该包，在导入的包路径之前增加一个下划线_ 123456// 如果当前go源文件中未引用过log包，将会导致编译错误import &quot;log&quot; // 错误import . &quot;log&quot; // 静态导入未使用同样报错// 在包名前面增加下划线表示导入包但是不直接使用它，被导入的包中的init函数会在导入的时候执行import _ &quot;github.com/go-sql-driver/mysql&quot; 包内元素的可见性 Accessability 名称首字符为Unicode包含的大写字母的元素是被导出的，对外部包是可见的首字为非大写字母的元素只对本包可见(同包跨源文件可以访问，子包不能访问) 1234567891011var In int // In is exportedvar in byte // in is unexportedvar ȸȹ string // ȸȹ is unexportedconst Ȼom bool = false // Ȼom is exportedconst ѧѩ uint8 = 1 // ѧѩ is unexportedtype Ĩnteger int // Ĩnteger is exportedtype ブーリアン *bool // ブーリアン is unexportedfunc Ӭxport() {...} // Ӭxport is exportedfunc įnner() {...} // įnner is unexportedfunc (me *Integer) ⱱalueOf(s string) int {...} // ⱱalueOf is unexportedfunc (i ブーリアン) Ȿtring() string {...} // Ȿtring is exported internal包（内部包） Go1.4+internal包及其子包中的导出元素只能被与internal同父包的其他包访问 例如有Go目录如下：$GOPATH/src ├─x0 │ ├─internal │ │ └─z0 │ └─y0 │ └─z1 └─x1 └─y1 x0，y0，z1包中可以访问internal，z0包中的可见元素x1，y1包中不能导入internal，z0包 规范导入包路径Canonical import paths Go1.4+包声明语句后面添加标记注释，用于标识这个包的规范导入路径。 1package pdf // import &quot;rsc.io/pdf&quot; 如果使用此包的代码的导入的路径不是规范路径，go命令会拒绝编译。例如有 rsc.io/pdf 的一个fork路径 github.com/rsc/pdf如下程序代码导入路径时使用了非规范的路径则会被go拒绝编译 1import &quot;github.com/rsc/pdf&quot; 数据类型 Data Type基础数据类型 Basic data type 基本类型包含：数值类型，布尔类型，字符串 类型 取值范围 默认零值 类型 取值范围 默认零值 int int32,int64 0 uint uint32,uint64 0 int8 -27 ~ 27-1 0 uint8,byte 0 ~ 28-1 0 int16 -215 ~ 215-1 0 uint16 0 ~ 216-1 0 int32,rune -231 ~ 231-1 0 uint32 0 ~ 232-1 0 int64 -263 ~ 263-1 0 uint64 0 ~ 264-1 0 float32 IEEE-754 32-bit 0.0 float64 IEEE-754 64-bit 0.0 complex64 float32+float32i 0 + 0i complex128 float64+float64i 0 + 0i bool true,false false string “” ~ “∞” “”,`` uintptr uint32,uint64 0 error - nil byte 是 uint8 的别名 `rune` 是 `int32` 的别名，代表一个Unicode码点 `int`与`int32`或`int64`是不同的类型，只是根据架构对应32/64位值 `uint`与`uint32`或`uint64`是不同的类型，只是根据架构对应32/64位值 变量 Variable 变量声明, 使用var关键字Go中只能使用var 声明变量，无需显式初始化值 12345var i int // i = 0var s string // s = &quot;&quot; (Go中的string是值类型，默认零值是空串 &quot;&quot; 或 ``，不存在nil(null)值)var e error // e = nil, error是Go的内建接口类型。 关键字的顺序错误或缺少都是编译错误的 123var int a // 编译错误a int // 编译错误int a // 编译错误 var 语句可以声明一个变量列表，类型在变量名之后 12345678910var a,b,c int // a = 0, b = 0, c = 0var ( a int // a = 0 b string // b = &quot;&quot; c uint // c = 0)var ( a,b,c int d string) 变量定义时初始化赋值，每个变量对应一个值 12var a int = 0var a, b int = 0, 1 变量定义并初始化时可以省略类型，Go自动根据初始值推导变量的类型 12var a = 'A' // a int32var a,b = 0, &quot;B&quot; // a int, b string 使用组合符号:=定义并初始化变量，根据符号右边表达式的值的类型声明变量并初始化它的值:= 不能在函数外使用，函数外的每个语法块都必须以关键字开始 12345a := 3 // a inta, b, c := 8, '呴', true // a int, b int32, c boolc := `formatted string` // c stringc := 1 + 2i // c complex128 常量 Constant 常量可以是字符、字符串、布尔或数值类型的值，数值常量是高精度的值 12345678910const x int = 3const y,z int = 1,2const ( a byte = 'A' b string = &quot;B&quot; c bool = true d int = 4 e float32 = 5.1 f complex64 = 6 + 6i) 根据常量值自动推导类型 12345const a = 0 // a intconst ( b = 2.3 // b float64 c = true // c bool) 常量组内定义时复用表达式常量组内定义的常量只有名称时，其值会根据上一次最后出现的常量表达式计算相同的类型与值 12345678910const ( a = 3 // a = 3 b // b = 3 c // c = 3 d = len(&quot;asdf&quot;) // d = 4 e // e = 4 f // f = 4 g,h,i = 7,8,9 // 复用表达式要一一对应 x,y,z // x = 7, y = 8, z = 9) 自动递增枚举常量 iotaiota的枚举值可以赋值给数值兼容类型每个常量单独声明时，iota不会自动递增 1234const a int = iota // a = 0const b int = iota // b = 0const c byte = iota // c = 0const d uint64 = iota // d = 0 常量组合声明时，iota每次引用会逐步自增，初始值为0，步进值为1 1234567const ( a uint8 = iota // a = 0 b int16 = iota // b = 1 c rune = iota // c = 2 d float64 = iota // d = 3 e uintptr = iota // e = 4) 即使iota不是在常量组内第一个开始引用，也会按组内常量数量递增 1234567const ( a = &quot;A&quot; b = 'B' c = iota // c = 2 d = &quot;D&quot; e = iota // e = 4) 枚举的常量都为同一类型时，可以使用简单序列格式(组内复用表达式). 12345const ( a = iota // a int32 = 0 b // b int32 = 1 c // c int32 = 2) 枚举序列中的未指定类型的常量会跟随序列前面最后一次出现类型定义的类型 12345678const ( a byte = iota // a uint8 = 0 b // b uint8 = 1 c // c uint8 = 2 d rune = iota // d int32 = 3 e // e int32 = 4 f // f int32 = 5) iota自增值只在一个常量定义组合中有效，跳出常量组合定义后iota初始值归0 123456789const ( a = iota // a int32 = 0 b // b int32 = 1 c // c int32 = 2)const ( e = iota // e int32 = 0 (iota重新初始化并自增) f // f int32 = 1) 定制iota序列初始值与步进值 (通过组合内复用表达式实现) 123456const ( a = (iota + 2) * 3 // a int32 = 6 (a=(0+2)*3) 初始值为6,步进值为3 b // b int32 = 9 (b=(1+2)*3) c // c int32 = 12 (c=(2+2)*3) d // d int32 = 15 (d=(3+2)*3)) 数组 Array 数组声明带有长度信息且长度固定，数组是值类型默认零值不是nil，传递参数时会进行复制。声明定义数组时中括号[ ]在类型名称之前，赋值引用元素时中括号[ ]在数组变量名之后。 1234567var a [3]int = [3]int{0, 1, 2} // a = [0 1 2]var b [3]int = [3]int{} // b = [0 0 0]var c [3]intc = [3]int{}c = [3]int{0,0,0} // c = [0 0 0]d := [3]int{} // d = [0 0 0]fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, d, d, len(d), cap(d)) // [3]int [3]int{0, 0, 0} 3 3 使用...自动计算数组的长度 12345678var a = [...]int{0, 1, 2}// 多维数组只能自动计算最外围数组长度x := [...][3]int{{0, 1, 2}, {3, 4, 5}}y := [...][2][2]int{{{0,1},{2,3}},{{4,5},{6,7}}}// 通过下标访问数组元素println(y[1][1][0]) // 6 初始化指定索引的数组元素，未指定初始化的元素保持默认零值 12var a = [3]int{2:3}var b = [...]string{2:&quot;c&quot;, 3:&quot;d&quot;} 切片 Slice slice 切片是对一个数组上的连续一段的引用，并且同时包含了长度和容量信息因为是引用类型，所以未初始化时的默认零值是nil，长度与容量都是0 12345678var a []intfmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, a, a, len(a), cap(a)) // []int []int(nil) 0 0// 可用类似数组的方式初始化slicevar d []int = []int{0, 1, 2}fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, d, d, len(d), cap(d)) // []int []int{0, 1, 2} 3 3var e = []string{2:&quot;c&quot;, 3:&quot;d&quot;} 使用内置函数make初始化slice，第一参数是slice类型，第二参数是长度，第三参数是容量(省略时与长度相同) 12345678var b = make([]int, 0)fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, b, b, len(b), cap(b)) // []int []int{} 0 0var c = make([]int, 3, 10)fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, c, c, len(c), cap(c)) // []int []int{} 3 10var a = new([]int)fmt.Printf(&quot;%T\\t%#v\\t%d\\t%d\\n&quot;, a, a, len(*a), cap(*a)) // *[]int &amp;[]int(nil) 0 0 基于slice或数组重新切片，创建一个新的 slice 值指向相同的数组重新切片支持两种格式： 2个参数 slice[beginIndex:endIndex]需要满足条件：0 &lt;= beginIndex &lt;= endIndex &lt;= cap(slice)截取从开始索引到结束索引-1 之间的片段新slice的长度：length=(endIndex - beginIndex)新slice的容量：capacity=(cap(slice) - beginIndex)beginIndex的值可省略，默认为0endIndex 的值可省略，默认为len(slice) 123456s := []int{0, 1, 2, 3, 4}a := s[1:3] // a: [1 2], len: 2, cap: 4b := s[:4] // b: [0 1 2 3], len: 4, cap: 5c := s[1:] // c: [1 2 3 4], len: 4, cap: 4d := s[1:1] // d: [], len: 0, cap: 4e := s[:] // e: [0 1 2 3 4], len: 5, cap: 5 3个参数 slice[beginIndex:endIndex:capIndex] Go1.2+需要满足条件：0 &lt;= beginIndex &lt;= endIndex &lt;= capIndex &lt;= cap(slice)新slice的长度：length=(endIndex - beginIndex)新slice的容量：capacity=(capIndex - beginIndex)beginIndex的值可省略，默认为0 123s := make([]int, 5, 10)a := s[9:10:10] // a: [0], len: 1, cap: 1b := s[:3:5] // b: [0 0 0], len: 3, cap: 5 向slice中追加/修改元素 123456789s := []string{}s = append(s, &quot;a&quot;) // 添加一个元素s = append(s, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) // 添加一列元素t = []string{&quot;e&quot;, &quot;f&quot;, &quot;g&quot;}s = append(s, t...} // 添加另一个切片t的所有元素s = append(s, t[:2]...} // 添加另一个切片t的部分元素s[0] = &quot;A&quot; // 修改切片s的第一个元素s[len(s)-1] = &quot;G&quot; // 修改切片s的最后一个元素 向slice指定位置插入元素，从slice中删除指定的元素因为slice引用指向底层数组，数组的长度不变元素是不能插入/删除的插入的原理就是从插入的位置将切片分为两部分依次将首部、新元素、尾部拼接为一个新的切片删除的原理就是排除待删除元素后用其他元素重新构造一个数组 12345678910111213141516171819202122func insertSlice(s []int, i int, elements ...int) []int { // x := append(s[:i], append(elements, s[i:]...)...) x := s[:i] x = append(x, elements...) x = append(x, s[i:]...) return x}func deleteByAppend() { i := 3 s := []int{1, 2, 3, 4, 5, 6, 7} // delete the fourth element(index is 3), using append s = append(s[:i], s[i+1:]...)}func deleteByCopy() { i := 3 s := []int{1, 2, 3, 4, 5, 6, 7} // delete the fourth element(index is 3), using copy copy(s[i:], s[i+1:]) s = s[:len(s)-1]} 字典/映射 Map map是引用类型，使用内置函数 make进行初始化，未初始化的map零值为 nil长度为0，并且不能赋值元素 1234567var m map[int]intm[0] = 0 // × runtime error: assignment to entry in nil mapfmt.Printf(&quot;type: %T\\n&quot;, m) // map[int]intfmt.Printf(&quot;value: %#v\\n&quot;, m) // map[int]int(nil)fmt.Printf(&quot;value: %v\\n&quot;, m) // map[]fmt.Println(&quot;is nil: &quot;, nil == m) // truefmt.Println(&quot;length: &quot;, len(m)) // 0，if m is nil, len(m) is zero. 使用内置函数make初始化map 1234567var m map[int]int = make(map[int]int)m[0] = 0 // 插入或修改元素fmt.Printf(&quot;type: %T\\n&quot;, m) // map[int]intfmt.Printf(&quot;value: %#v\\n&quot;, m) // map[int]int(0:0)fmt.Printf(&quot;value: %v\\n&quot;, m) // map[0:0]fmt.Println(&quot;is nil: &quot;, nil == m) // falsefmt.Println(&quot;length: &quot;, len(m)) // 1 直接赋值初始化map 12345678m := map[int]int{0:0,1:1, // 最后的逗号是必须的}n := map[string]S{&quot;a&quot;:S{0,1},&quot;b&quot;:{2,3}, // 类型名称可省略} map的使用：读取、添加、修改、删除元素 1234567m[0] = 3 // 修改m中key为0的值为3m[4] = 8 // 添加到m中key为4值为8a := n[&quot;a&quot;] // 获取n中key为“a“的值b, ok := n[&quot;c&quot;] // 取值, 并通过ok(bool)判断key对应的元素是否存在.delete(n, &quot;a&quot;) // 使用内置函数delete删除key为”a“对应的元素. 结构体 Struct 结构体类型struct是一个字段的集合 1234type S struct { A int B, c string} 结构体初始化通过结构体字段的值作为列表来新分配一个结构体。 1var s S = S{0, &quot;1&quot;, &quot;2&quot;} 使用 Name: 语法可以仅列出部分字段(字段名的顺序无关) 1var s S = S{B: &quot;1&quot;, A: 0} 结构体是值类型，传递时会复制值，其默认零值不是nil 123var a Svar b = S{}fmt.Println(a == b) // true 结构体组合将一个命名类型作为匿名字段嵌入一个结构体嵌入匿名字段支持命名类型、命名类型的指针和接口类型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package maintype ( A struct { v int } // 定义结构体B，嵌入结构体A作为匿名字段 B struct { A } // 定义结构体C，嵌入结构体A的指针作为匿名字段 C struct { *A })func (a *A) setV(v int) { a.v = v}func (a A) getV() int { return a.v}func (b B) getV() string { return &quot;B&quot;}func (c *C) getV() bool { return true}func main() { a := A{} b := B{} // 初始化结构体B，其内匿名字段A默认零值是A{} c := C{&amp;A{}} // 初始化结构体C，其内匿名指针字段*A默认零值是nil，需要初始化赋值 println(a.v) // 结构体A嵌入B，A内字段自动提升到B println(b.v) // 结构体指针*A嵌入C，*A对应结构体内字段自动提升到C println(c.v) a.setV(3) b.setV(5) c.setV(7) println(a.getV(), b.A.getV(), c.A.getV()) println(a.getV(), b.getV(), c.getV())} 匿名结构体匿名结构体声明时省略了type关键字，并且没有名称 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package mainimport &quot;fmt&quot;type Integer int// 声明变量a为空的匿名结构体类型var a struct{}// 声明变量b为包含一个字段的匿名结构体类型var b struct{ x int }// 声明变量c为包含两个字段的匿名结构体类型var c struct { u int v bool}func main() { printa(a) b.x = 1 fmt.Printf(&quot;bx: %#v\\n&quot;, printb(b)) // bx: struct { y uint8 }{y:0x19} printc(c) // 声明d为包含3个字段的匿名结构体并初始化部分字段 d := struct { x int y complex64 z string }{ z: &quot;asdf&quot;, x: 111, } d.y = 22 + 333i fmt.Printf(&quot;d: %#v\\n&quot;, d) // d: struct { x int; y complex64; z string }{x:111, y:(22+333i), z:&quot;asdf&quot;} // 声明变量e为包含两个字段的匿名结构体类型 // 包含1个匿名结构体类型的命名字段和1个命名类型的匿名字段 e := struct { a struct{ x int } // 结构体组合嵌入匿名字段只支持命名类型 Integer }{} e.Integer = 444 fmt.Printf(&quot;e: %#v\\n&quot;, e) // e: struct { a struct { x int }; main.Integer }{a:struct { x int }{x:0}, Integer:444}}// 函数参数为匿名结构体类型时，传入参数类型声明必须保持一致func printa(s struct{}) { fmt.Printf(&quot;a: %#v\\n&quot;, s) // a: struct {}{}}// 函数入参和返回值都支持匿名结构体类型func printb(s struct{ x int }) (x struct{ y byte }) { fmt.Printf(&quot;b: %#v\\n&quot;, s) // b: struct { x int }{x:1} x.y = 25 return}func printc(s struct {u int; v bool }) { fmt.Printf(&quot;c: %#v\\n&quot;, s) // c: struct { u int; v bool }{u:0, v:false}} 指针 Pointer 通过取地址操作符&amp;获取指向值/引用对象的指针。 1234567var i int = 1pi := &amp;i // 指向数值的指针a := []int{0, 1, 2}pa := &amp;a // 指向引用对象的指针var s *S = &amp;S{0, &quot;1&quot;, &quot;2&quot;} // 指向值对象的指针 内置函数new(T)分配了一个零初始化的 T 值，并返回指向它的指针 12var i = new(int)var s *S = new(S) 使用*读取/修改指针指向的值 12345678func main() { i := new(int) *i = 3 println(i, *i) // 0xc208031f80 3 i = new(int) println(i, *i) // 0xc208031f78 0} 指针使用点号来访问结构体字段结构体字段/方法可以通过结构体指针来访问，通过指针间接的访问是透明的。 12fmt.Println(s.A)fmt.Println((*s).A) 指针的指针 123456789101112func main() { var i int var p *int var pp **int var ppp ***int var pppp ****int println(i, p, pp, ppp, pppp) // 0 0x0 0x0 0x0 0x0 i, p, pp, ppp, pppp = 123, &amp;i, &amp;p, &amp;pp, &amp;ppp println(i, p, pp, ppp, pppp) // 123 0xc208031f68 0xc208031f88 0xc208031f80 0xc208031f78 println(i, *p, **pp, ***ppp, ****pppp) // 123 123 123 123 123} 跨层指针元素的使用在指针引用多层对象时，指针是针对引用表达式的最后一位元素。 1234567891011package atype X struct { A Y}type Y struct { B Z}type Z struct { C int} 12345678910111213141516package mainimport ( &quot;a&quot; &quot;fmt&quot;)func main() { var x = a.X{} var p = &amp;x fmt.Println(&quot;x: &quot;, x) // x: {{{0}}} println(&quot;p: &quot;, p) // p: 0xc208055f20 fmt.Println(&quot;*p: &quot;, *p) // *p: {{{0}}} println(&quot;x.A.B.C: &quot;, x.A.B.C) // x.A.B.C: 0 // println(&quot;*p.A.B.C: &quot;, *p.A.B.C) // invalid indirect of p.A.B.C (type int) println(&quot;(*p).A.B.C: &quot;, (*p).A.B.C) // (*p).A.B.C: 0} Go的指针没有指针运算，但是 道高一尺，魔高一丈Go语言中的指针运算利用unsafe操作未导出变量 通道 Channel channel用于两个goroutine之间传递指定类型的值来同步运行和通讯。操作符&lt;-用于指定channel的方向，发送或接收。如果未指定方向，则为双向channel。 123var c0 chan int // 可用来发送和接收int类型的值var c1 chan&lt;- int // 可用来发送int类型的值var c2 &lt;-chan int // 可用来接收int类型的值 channel是引用类型，使用make函数来初始化。未初始化的channel零值是nil，且不能用于发送和接收值。 12c0 := make(chan int) // 不带缓冲的int类型channelc1 := make(chan *int, 10) // 带缓冲的*int类型指针channel 无缓冲的channe中有值时发送方会阻塞，直到接收方从channel中取出值。带缓冲的channel在缓冲区已满时发送方会阻塞，直到接收方从channel中取出值。接收方在channel中无值会一直阻塞。 通过channel发送一个值时，&lt;-作为二元操作符使用， 1c0 &lt;- 3 通过channel接收一个值时，&lt;-作为一元操作符使用。 1i := &lt;-c1 关闭channel，只能用于双向或只发送类型的channel只能由 发送方调用close函数来关闭channel接收方取出已关闭的channel中发送的值后，后续再从channel中取值时会以非阻塞的方式立即返回channel传递类型的零值。 12345678910111213141516171819202122232425ch := make(chan string, 1)// 发送方，发送值后关闭channelch &lt;- &quot;hello&quot;close(ch)// 接收方，取出发送的值fmt.Println(&lt;-ch) // 输出： “hello”// 再次从已关闭的channel中取值，返回channel传递类型的零值fmt.Println(&lt;-ch) // 输出： 零值，空字符串“”// 接收方判断接收到的零值是由发送方发送的还是关闭channel返回的默认值s, ok := &lt;-chif ok { fmt.Println(&quot;Receive value from sender:&quot;, s)} else { fmt.Println(&quot;Get zero value from closed channel&quot;)}// 向已关闭的通道发送值会产生运行时恐慌panicch &lt;- &quot;hi&quot;// 再次关闭已经关闭的通道也会产生运行时恐慌panicclose(ch) 使用for range语句依次读取发送到channel的值，直到channel关闭。 12345678910111213141516171819package mainimport &quot;fmt&quot;func main() { // 无缓冲和有缓冲的channel的range用法相同 var ch = make(chan int) // make(chan int, 2) 或 make(chan int , 100) go func() { for i := 0; i &lt; 5; i++ { ch &lt;- i } close(ch) }() // channel中无发送值且未关闭时会阻塞 for x := range ch { fmt.Println(x) }} 下面方式与for range用法效果相同 12345678910loop: for { select { case x, ok := &lt;-c: if !ok { break loop } fmt.Println(x) } } 接口 Interface 接口类型是由一组方法定义的集合。接口类型的值可以存放实现这些方法的任何值。 123type Abser interface { Abs() float64} 类型通过实现定义的方法来实现接口， 不需要显式声明实现某接口。 12345678type MyFloat float64func (f MyFloat) Abs() float64 { if f &lt; 0 { return float64(-f) } return float64(f)} 接口组合 12345678910111213141516171819202122232425262728293031323334353637383940type Reader interface { Read(b []byte) (n int)}type Writer interface { Write(b []byte) (n int)}// 接口ReadWriter组合了Reader和Writer两个接口type ReadWriter interface { Reader Writer}type File struct { // ...}func (f *File) Read(b []byte) (n int) { println(&quot;Read&quot;, len(b),&quot;bytes data.&quot;) return len(b)}func (f *File) Write(b []byte) (n int) { println(&quot;Write&quot;, len(b),&quot;bytes data.&quot;) return len(b)}func main() { // *File 实现了Read方法和Write方法，所以实现了Reader接口和Writer接口以及组合接口ReadWriter var f *File = &amp;File{} var r Reader = f var w Writer = f var rw ReadWriter = f bs := []byte(&quot;asdf&quot;) r.Read(bs) rw.Read(bs) w.Write(bs) rw.Write(bs)} 内置接口类型error是一个用于表示错误情况的常规接口，其零值nil表示没有错误所有实现了Error方法的类型都能表示为一个错误 123type error interface { Error() string} 自定义类型 Go中支持自定义的类型可基于： 基本类型、数组类型、切片类型、字典类型、函数类型、结构体类型、通道类型、接口类型以及自定义类型的类型 12345678910111213141516171819202122232425262728type ( A int B int8 C int16 D rune E int32 F int64 G uint H byte I uint16 J uint32 K uint64 L float32 M float64 N complex64 O complex128 P uintptr Q bool R string S [3]uint8 T []complex128 U map[string]uintptr V func(i int) (b bool) W struct {a, b int} X chan int Y interface {} Z A) 以及支持以上所有支持类型的指针类型 12345678910111213141516171819202122232425262728type ( A *int B *int8 C *int16 D *rune E *int32 F *int64 G *uint H *byte I *uint16 J *uint32 K *uint64 L *float32 M *float64 N *complex64 O *complex128 P *uintptr Q *bool R *string S *[3]uint8 T *[]complex128 U *map[string]uintptr V *func(i int) (b bool) W *struct {a, b int} X *chan int Y *interface {} Z *A) 类型别名 Go1.9+ 1234567891011121314151617181920type ( A struct{} B struct{} // 定义两个结构相同的类型A，B C = A // 定义类型A的别名)func main() { var ( a A b B c C ) // 因为类型名不同，所以a和b不是相同类型，此处编译错误 fmt.Println(a == b) // invalid operation: a == b (mismatched types A and B) fmt.Println(a == c) // true a = C{} c = A{} fmt.Println(c == a) // true} 强制类型转换 数据类型转换语法规则 12// T 为新的数据类型newDataTypeVariable = T(oldDataTypeVariable) 数值类型转换 123var i int = 123var f = float64(i)var u = uint(f) 接口类型转换任意类型的数据都可以转换为其类型已实现的接口类型 1234567type I interface{}var x int = 123var y = I(x) var s struct{a string}var t = I(s) 结构体类型转换 Go1.8+如果两个结构体包含的所有字段的名称和类型相同(忽略字段的标签差异)，则可以互相强制转换类型。 12345678910type T1 struct { X int `json:&quot;foo&quot;`}type T2 struct { X int `json:&quot;bar&quot;`}var v1 = T1{X: 123}var v2 = T2(v1) 语句 Statement分号/括号 ; { Go是采用语法解析器自动在每行末尾增加分号，所以在写代码的时候可以省略分号。 Go编程中只有几个地方需要手工增加分号：for循环使用分号把初始化、条件和遍历元素分开。if/switch的条件判断带有初始化语句时使用分号分开初始化语句与判断语句。在一行中有多条语句时，需要增加分号。 控制语句(if，for，switch，select)、函数、方法 的左大括号不能单独放在一行， 语法解析器会在大括号之前自动插入一个分号，导致编译错误。 条件语句 if if语句 小括号 ( )是可选的，而大括号 { } 是必须的。 123456789101112131415161718192021if (i &lt; 0) // 编译错误. println(i)if i &lt; 0 // 编译错误. println(i)if (i &lt; 0) { // 编译通过. println(i)}if (i &lt; 0 || i &gt; 10) { println(i)}if i &lt; 0 { println(i)} else if i &gt; 5 &amp;&amp; i &lt;= 10 { println(i)} else { println(i)} 可以在条件之前执行一个简单的语句，由这个语句定义的变量的作用域仅在 if / else if / else 范围之内 123456789101112131415if (i := 0; i &lt; 1) { // 编译错误. println(i)}if i := 0; (i &lt; 1) { // 编译通过. println(i)}if i := 0; i &lt; 0 { // 使用gofmt格式化代码会自动移除代码中不必要的小括号( ) println(i)} else if i == 0 { println(i)} else { println(i)} if语句作用域范围内定义的变量会覆盖外部同名变量，与方法函数内局部变量覆盖全局变量同理 12345a, b := 0, 1if a, b := 3, 4; a &gt; 1 &amp;&amp; b &gt; 2 { println(a, b) // 3 4}println(a, b) // 0 1 if判断语句类型断言 12345678910111213141516171819202122232425262728package mainfunc f0() int {return 333}func main() { x := 9 checkType(x) checkType(f0)}func checkType(x interface{}) { // 断言传入的x为int类型，并获取值 if i, ok := x.(int); ok { println(&quot;int: &quot;, i) // int: 0 } if f, ok := x.(func() int); ok { println(&quot;func: &quot;, f()) // func: 333 } // 如果传入x类型为int，则可以直接获取其值 a := x.(int) println(a) // 如果传入x类型不是byte，则会产生恐慌panic b := x.(byte) println(b)} 分支选择 switch switch存在分支选择对象时，case分支支持单个常量、常量列表 12345678switch x {case 0: println(&quot;single const&quot;)case 1, 2, 3: println(&quot;const list&quot;)default: println(&quot;default&quot;)} 分支选择对象之前可以有一个简单语句，case语句的大括号可以省略 1234567891011switch x *= 2; x {case 4: { println(&quot;single const&quot;)}case 5, 6, 7: { println(&quot;const list&quot;)}default: { println(&quot;default&quot;)}} switch只有一个简单语句，没有分支选择对象时，case分支支持逻辑表达式语句 12345678switch x /= 3; {case x == 8: println(&quot;expression&quot;)case x &gt;= 9: println(&quot;expression&quot;)default: println(&quot;default&quot;)} switch没有简单语句，没有分支选择对象时，case分支支持逻辑表达式语句 12345678switch {case x == 10: println(&quot;expression&quot;)case x &gt;= 11: println(&quot;expression&quot;)default: println(&quot;default&quot;)} switch类型分支，只能在switch语句中使用的.(type)获取对象的类型。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package mainimport ( &quot;fmt&quot; &quot;code.google.com/p/go.crypto/openpgp/errors&quot;)func main() { var ( a = 0.1 b = 2+3i c = &quot;asdf&quot; d = [...]byte{1, 2, 3} e = []complex128{1+2i} f = map[string]uintptr{&quot;a&quot;: 0} g = func(int) bool {return true} h = struct { a, b int }{} i = &amp;struct {}{} j chan int k chan &lt;- bool l &lt;-chan string m errors.SignatureError ) values := []interface{}{nil, a, b, &amp;c, d, e, f, g, &amp;g, h, &amp;h, i, j, k, l, m} for _, v := range values { typeswitch(v) }}func typeswitch(x interface{}) { // switch x.(type) { // 不使用类型值时 switch i := x.(type) { case nil: fmt.Println(&quot;x is nil&quot;) case int, int8, int16, rune, int64, uint, byte, uint16, uint32, uint64, float32, float64, complex64, complex128, uintptr, bool, string: fmt.Printf(&quot;basic type : %T\\n&quot;, i) case *int, *int8, *int16, *rune, *int64, *uint, *byte, *uint16, *uint32, *uint64, *float32, *float64, *complex64, *complex128, *uintptr, *bool, *string: fmt.Printf(&quot;basic pointer type : %T\\n&quot;, i) case [3]byte, []complex128, map[string]uintptr: fmt.Printf(&quot;collection type : %T\\n&quot;, i) case func(i int) (b bool), *func(): fmt.Printf(&quot;function type : %T\\n&quot;, i) case struct {a, b int}, *struct {}: fmt.Printf(&quot;struct type : %T\\n&quot;, i) case chan int, chan &lt;- bool, &lt;-chan string: fmt.Printf(&quot;channel type : %T\\n&quot;, i) case error, interface{a(); b()}: fmt.Printf(&quot;interface type : %T\\n&quot;, i) default: fmt.Printf(&quot;other type : %T\\n&quot;, i) }}// output: // x is nil// basic type : float64// basic type : complex128// basic pointer type : *string// collection type : [3]uint8// collection type : []complex128// collection type : map[string]uintptr// function type : func(int) bool// other type : *func(int) bool// struct type : struct { a int; b int }// other type : *struct { a int; b int }// struct type : *struct {}// channel type : chan int// channel type : chan&lt;- bool// channel type : &lt;-chan string// interface type : errors.SignatureError switch中每个case分支默认带有break效果，一个分支执行后就跳出switch，不会自动向下执行其他case。使用fallthrough强制向下继续执行后面的case代码。在类型分支中不允许使用fallthrough语句 12345678910111213141516171819switch {case false: println(&quot;case 1&quot;) fallthroughcase true: println(&quot;case 2&quot;) fallthroughcase false: println(&quot;case 3&quot;) fallthroughcase true: println(&quot;case 4&quot;)case false: println(&quot;case 5&quot;) fallthroughdefault: println(&quot;default case&quot;)}// 输出：case 2 case 3 case 4 循环语句 for Go只有一种循环结构：for 循环。可以让前置(初始化)、中间(条件)、后置(迭代)语句为空，或者全为空。 12345678910for i := 0; i &lt; 10; i++ {...}for i := 0; i &lt; 10; {...} // 省略迭代语句for i := 0; ; i++; {...} // 省略条件语句for ; i &lt; 10; i++ {...} // 省略初始化语句for i := 0; ; {...} // 省略条件和迭代语句, 分号不能省略for ; i &lt; 10; {...} // 省略初始化和迭代语句, 分号可省略for ; ; i++ {...} // 省略初始化和条件语句, 分号不能省略for i &lt; 10 {...}for ; ; {...} // 分号可省略for {...} for语句中小括号 ( )是可选的，而大括号 { } 是必须的。 123for (i := 0; i &lt; 10; i++) {...} // 编译错误.for i := 0; (i &lt; 10); i++ {...} // 编译通过.for (i &lt; 10) {...} // 编译通过. Go的for each循环for range 12345678910111213a := [5]int{2, 3, 4, 5, 6}for k, v := range a { fmt.Println(k, v) // 输出：0 2, 1 3, 2 4, 3 5, 4 6}for k := range a { fmt.Println(k) // 输出：0 1 2 3 4}for _ = range a { fmt.Println(&quot;print without care about the key and value&quot;)} Go1.4+ 123for range a { fmt.Println(&quot;new syntax – print without care about the key and value&quot;)} 循环的继续、中断、跳转 123456789for k, v := range s { if v == 3 { continue // 结束本次循环，进入下一次循环中 } else if v == 5 { break // 结束整个for循环 } else { goto SOMEWHERE // 跳转到标签指定的代码处 }} for range只支持遍历数组、数组指针、slice、string、map、channel类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package mainimport &quot;fmt&quot;func main() { var arr = [...]int{33, 22, 11, 0} // 遍历数组，取一位值时为索引值 for k := range arr { fmt.Printf(&quot;%d, &quot;, k) // 0, 1, 2, 3, } fmt.Println() // 遍历数组，取两位值时，第一位为索引值，第二位为元素值 for k, v := range arr { fmt.Printf(&quot;%d %d, &quot;, k, v) // 0 33, 1 22, 2 11, 3 0, } fmt.Println() // 遍历数组指针，取一位值时为索引值 for k := range &amp;arr { fmt.Printf(&quot;%d, &quot;, k) // 0, 1, 2, 3, } fmt.Println() // 遍历数组指针，取两位值时，第一位为索引值，第二位为元素值 for k, v := range &amp;arr { fmt.Printf(&quot;%d %d, &quot;, k, v) // 0 33, 1 22, 2 11, 3 0, } fmt.Println() var slc = []byte{44, 55, 66, 77} // 遍历切片，取一位值时为索引值 for k := range slc { fmt.Printf(&quot;%d, &quot;, k) // 0, 1, 2, 3, } fmt.Println() // 遍历切片，取两位值时，第一位为索引值，第二位为元素值 for k, v := range slc { fmt.Printf(&quot;%d %d, &quot;, k, v) // 0 44, 1 55, 2 66, 3 77, } fmt.Println() var str = &quot;abc一二3&quot; // 遍历字符串，取一位值时为字节索引值 for k := range str { fmt.Printf(&quot;%d, &quot;, k) // 0, 1, 2, 3, 6, 9, } fmt.Println() // 遍历字符串，取两位值时，第一位为字节索引值，第二位为Unicode字符 for k, v := range str { fmt.Printf(&quot;%d %d %s, &quot;, k, v, string(v)) // 0 97 a, 1 98 b, 2 99 c, 3 19968 一, 6 20108 二, 9 51 3, } fmt.Println() var mp = map[int]string{5:&quot;A&quot;, 9:&quot;B&quot;} // 遍历map，取一位值时为键key for k := range mp { fmt.Printf(&quot;%d, &quot;, k) // 9, 5, } fmt.Println() // 遍历map，取两位值时，第一位为键key，第二位为元素值value for k, v := range mp { fmt.Printf(&quot;%d %s, &quot;, k, v) // 5 A, 9 B, } fmt.Println() var ch = make(chan int) go func() { for i := 0; i &lt; 5; i++ { ch &lt;- i } close(ch) }() // 遍历channel时，只能取一位值，为发送方发送到channel中的值 for x := range ch { fmt.Printf(&quot;%d &quot;, x) // 0 1 2 3 4 }} 通道选择 select select用于当前goroutine从一组可能的通讯中选择一个进一步处理。如果任意一个通讯都可以进一步处理，则从中随机选择一个，执行对应的语句。否则在没有默认分支(default case)时，select语句则会阻塞，直到其中一个通讯完成。select 的 case 里的操作语句只能是IO操作 123456789ch1, ch2 := make(chan int), make(chan int)// 因为没有值发送到select中的任一case的channel中，此select将会阻塞select {case &lt;-ch1: println(&quot;channel 1&quot;)case &lt;-ch2: println(&quot;channel 2&quot;)} 1234567891011ch1, ch2 := make(chan int), make(chan int)// 因为没有值发送到select中的任一case的channel中，此select将会执行default分支select {case &lt;-ch1: println(&quot;channel 1&quot;)case &lt;-ch2: println(&quot;channel 2&quot;)default: println(&quot;default&quot;)} select只会执行一次case分支的逻辑，与for组合使用实现多次遍历分支 12345678910111213func main() { for { select { case &lt;-time.Tick(time.Second): println(&quot;Tick&quot;) case &lt;-time.After(5 * time.Second): println(&quot;Finish&quot;) default: println(&quot;default&quot;) time.Sleep(5e8) } }} 延迟执行 defer defer语句调用函数，将调用的函数加入defer栈，栈中函数在defer所在的主函数返回时执行，执行顺序是先进后出/后进先出。 1234567891011121314package mainfunc main() { defer print(0) defer print(1) defer print(2) defer print(3) defer print(4) for i := 5; i &lt;= 9; i++ { defer print(i) } // 输出：9876543210} defer在函数返回后执行，可以修改函数返回值 123456789101112package mainfunc main() { println(f()) // 返回： 15}func f() (i int) { defer func() { i *= 5 }() return 3} defer用于释放资源 释放锁 12mu.Lock()defer mu.Unlock() 关闭channel 12ch &lt;- &quot;hello&quot;defer close(ch) 关闭IO流 12f, err := os.Open(&quot;file.xxx&quot;)defer f.Close() 关闭数据库连接 12345db, err := sql.Open(&quot;mysql&quot;,&quot;user:password@tcp(127.0.0.1:3306)/hello&quot;)if err != nil { log.Fatal(err)}defer db.Close() defer用于恐慌的截获panic用于产生恐慌，recover用于截获恐慌，recover只能在defer语句中使用, 直接调用recover是无效的。 123456789101112131415161718func main() { f() fmt.Println(&quot;main normal...&quot;)}func f() { defer func() { if r := recover(); r != nil { fmt.Println(&quot;catch:&quot;, r) } }() p() fmt.Println(&quot;normal...&quot;)}func p() { panic(&quot;exception...&quot;)} 跳转语句 goto goto用于在一个函数内部运行跳转到指定标签的代码处，不能跳转到其他函数中定义的标签。 goto模拟循环 1234567891011package mainfunc main() { i := 0loop: i++ if i &lt; 5 { goto loop } println(i)} goto模拟continue，break 12345678910111213141516func main() { i, sum := 0, 0head: for ; i &lt;= 10; i++ { if i &lt; 5 { i++ // 此处必须单独调用一次，因为goto跳转时不会执行for循环的自增语句 goto head // continue } if i &gt; 9 { goto tail // break } sum += i }tail: println(sum) // 输出：35} 注意：任何时候都不建议使用goto 阻塞语句 永久阻塞语句 12345678// 向一个未初始化的channel中写入数据会永久阻塞(chan int)(nil) &lt;- 0// 从一个未初始化的channel中读取数据会永久阻塞&lt;-(chan struct{})(nil)for range (chan struct{})(nil){}// select无任何选择分支会永久阻塞select{} 函数 Function函数声明 Declare 使用关键字func声明函数，函数可以没有参数或接受多个参数 12345func f0() {/*...*/}func f1(a int) {/*...*/}func f2(a int, b byte) {/*...*/} 在函数参数类型之前使用...声明该参数为可变数量的参数可变参数只能声明为函数的最后一个参数。 123func f3(a ...int) {/*...*/}func f4(a int, b bool, c ...string) {/*...*/} 函数可以返回任意数量的返回值 1234567891011func f0() { return}func f1() int { return 0}func f2() (int, string) { return 0, &quot;A&quot;} 函数返回结果参数，可以像变量那样命名和使用 123456func f() (a int, b string) { a = 1 b = &quot;B&quot; return // 即使return后面没有跟变量，关键字在函数结尾也是必须的 // 或者 return a, b} 当两个或多个连续的函数命名参数是同一类型，则除了最后一个类型之外，其他都可以省略 12345func f0(a,b,c int) {/*...*/}func f1() (a,b,c int) {/*...*/}func f2(a,b int, c,d byte) (x,y int, z,s bool) {/*...*/} 函数闭包 Closure 匿名函数、闭包、函数值Go中函数作为第一类对象，可以作为值对象赋值给变量可以在函数体外/内定义匿名函数，命名函数不能嵌套定义到函数体内，只能定义在函数体外 123456789101112131415161718192021222324252627package maintype Myfunc func(i int) intfunc f0(name string){ println(name)}func main() { var a = f0 a(&quot;hello&quot;) // hello var f1 Myfunc = func(i int) int { return i } fmt.Println(f1(3)) // 3 var f2 func() int = func() int { return 0 } fmt.Println(f2()) // 0 // 省略部分关键字 var f3 func() = func() {/*...*/} var f4 = func() {/*...*/} f5 := func() {/*...*/}} 内建函数 Builtin func append 1func append(slice []Type, elems ...Type) []Type 内建函数append将元素追加到切片的末尾。若它有足够的容量，其目标就会重新切片以容纳新的元素。否则，就会分配一个新的基本数组。append返回更新后的切片，因此必须存储追加后的结果。 12slice = append(slice, elem1, elem2)slice = append(slice, anotherSlice...) 作为特例，可以向一个字节切片append字符串，如下： 1slice = append([]byte(&quot;hello &quot;), &quot;world&quot;...) func cap 1func cap(v Type) int 内建函数cap返回 v 的容量，这取决于具体类型： 数组：v中元素的数量，与 len(v) 相同 数组指针：*v中元素的数量，与len(v) 相同 切片：切片的容量（底层数组的长度）；若 v为nil，cap(v) 即为零 信道：按照元素的单元，相应信道缓存的容量；若v为nil，cap(v)即为零 func close 1func close(c chan&lt;- Type) 内建函数close关闭信道，该通道必须为双向的或只发送的。它应当只由发送者执行，而不应由接收者执行，其效果是在最后发送的值被接收后停止该通道。在最后的值从已关闭的信道中被接收后，任何对其的接收操作都会无阻塞的成功。对于已关闭的信道，语句： 1x, ok := &lt;-c // ok值为false func complex 1func complex(r, i FloatType) ComplexType 使用实部r和虚部i生成一个复数。 12c := complex(1, 2)fmt.Println(c) // (1+2i) func copy 1func copy(dst, src []Type) int 内建函数copy将元素从来源切片复制到目标切片中，也能将字节从字符串复制到字节切片中。copy返回被复制的元素数量，它会是 len(src) 和 len(dst) 中较小的那个。来源和目标的底层内存可以重叠。 12345678910111213a, b, c := []byte{1, 2, 3}, make([]byte, 2), 0fmt.Println(&quot;a:&quot;, a, &quot; b:&quot;, b, &quot; c: &quot;, c) // a: [1 2 3] b: [0 0] c: 0c = copy(b, a)fmt.Println(&quot;a:&quot;, a, &quot; b:&quot;, b, &quot; c: &quot;, c) // a: [1 2 3] b: [1 2] c: 2b = make([]byte, 5)c = copy(b, a)fmt.Println(&quot;a:&quot;, a, &quot; b:&quot;, b, &quot; c: &quot;, c) // a: [1 2 3] b: [1 2 3 0 0] c: 3s := &quot;ABCD&quot;c = copy(b, s)fmt.Println(&quot;s:&quot;, s, &quot; b:&quot;, b, &quot; c: &quot;, c) // s: ABCD b: [65 66 67 68 0] c: 4 func delete 1func delete(m map[Type]Type1, key Type) 内建函数delete按照指定的键将元素从映射中删除。若m为nil或无此元素，delete不进行操作。 123456789m := map[int]string{ 0: &quot;A&quot;, 1: &quot;B&quot;, 2: &quot;C&quot;,}delete(m, 1)fmt.Println(m) // map[2:C 0:A]delete(m, 3) // 此行代码执行没有任何操作，也不会报错。 func imag 1func imag(c ComplexType) FloatType 返回复数c的虚部。 12c := 2+5ifmt.Println(imag(c)) // 5 func len 1func len(v Type) int 内建函数len返回 v 的长度，这取决于具体类型： 数组：v中元素的数量 数组指针：*v中元素的数量（v为nil时panic） 切片、映射：v中元素的数量；若v为nil，len(v)即为零 字符串：v中字节的数量，计算字符数量使用utf8.RuneCountInString() 通道：通道缓存中队列（未读取）元素的数量；若v为 nil，len(v)即为零 func make 1func make(Type, size IntegerType) Type 内建函数make分配并初始化一个类型为切片、映射、或通道的对象。其第一个实参为类型，而非值。make的返回类型与其参数相同，而非指向它的指针。其具体结果取决于具体的类型： 切片：size指定了其长度。该切片的容量等于其长度。切片支持第二个整数实参可用来指定不同的容量；它必须不小于其长度，因此 make([]int, 0, 10) 会分配一个长度为0，容量为10的切片。 映射：初始分配的创建取决于size，但产生的映射长度为0。size可以省略，这种情况下就会分配一个小的起始大小。 通道：通道的缓存根据指定的缓存容量初始化。若 size为零或被省略，该信道即为无缓存的。 func new 1func new(Type) *Type 内建函数new分配内存。其第一个实参为类型，而非值。其返回值为指向该类型的新分配的零值的指针。 func panic 1func panic(v interface{}) 内建函数panic停止当前Go程的正常执行。当函数F调用panic时，F的正常执行就会立刻停止。F中defer的所有函数先入后出执行后，F返回给其调用者G。G如同F一样行动，层层返回，直到该Go程中所有函数都按相反的顺序停止执行。之后，程序被终止，而错误情况会被报告，包括引发该恐慌的实参值，此终止序列称为恐慌过程。 func print 1func print(args ...Type) 内建函数print以特有的方法格式化参数并将结果写入标准错误，用于自举和调试。 func println 1func println(args ...Type) println类似print，但会在参数输出之间添加空格，输出结束后换行。 func real 1func real(c ComplexType) FloatType 返回复数c的实部。 123456789 c := 2+5i fmt.Println(real(c)) // 2 ``` - `func recover` ```go func recover() interface{} 内建函数recover允许程序管理恐慌过程中的Go程。在defer的函数中，执行recover调用会取回传至panic调用的错误值，恢复正常执行，停止恐慌过程。若recover在defer的函数之外被调用，它将不会停止恐慌过程序列。在此情况下，或当该Go程不在恐慌过程中时，或提供给panic的实参为nil时，recover就会返回nil。 初始化函数 init init函数是用于程序执行前做包的初始化工作的函数init函数的声明没有参数和返回值 123func init() { // ...} 一个package或go源文件可以包含零个或多个init函数 1234567891011121314package mainfunc main() {}func init() { println(&quot;init1...&quot;)}func init() { println(&quot;init2...&quot;)}func init() { println(&quot;init3...&quot;)} init函数被自动调用，在main函数之前执行，不能在其他函数中调用，显式调用会报错该函数未定义。 1234567func init() { println(&quot;init...&quot;)}func main() { init() // undefined: init} 所有init函数都会被自动调用，调用顺序如下： 同一个go文件的init函数调用顺序是 从上到下的 同一个package中按go源文件名字符串比较 从小到大顺序调用各文件中的init函数 不同的package，如果不相互依赖的，按照main包中 先import的后调用的顺序调用其包中的init函数 如果package存在依赖，则先调用最早被依赖的package中的init函数 方法 Method 通过指定函数的接收者receiver,将函数绑定到一个类型或类型的指针上,使这个函数成为该类型的方法。只能对命名类型和命名类型的指针编写方法。只能在定义命名类型的那个包编写其方法。不能对接口类型和接口类型的指针编写方法。方法的接收者receiver是类型的值时，编译器会隐式的生成一个同名方法，其接收者receiver为该类型的指针，反过来却不会。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package maintype A struct { x, y int}// 定义结构体的方法，'_'表示方法内忽略使用结构体、字段及其他方法func (_ A) echo_A() { println(&quot;(_ A)&quot;)}// 同上func (A) echoA(s string) { println(&quot;(A)&quot;, s)}// 定义结构体指针的方法，'_'表示方法内忽略使用结构体指针、字段及其他方法func (_ *A) echo_жA() { println(&quot;(_ *A)&quot;)}// 同上func (*A) echoжA(s string) { println(&quot;(*A)&quot;, s)}// 定义结构体的方法，方法内可以引用结构体、字段及其他方法func (a A) setX(x int) { a.x = x}// 定义结构体指针的方法，方法内可以引用结构体、结构体指针、字段及其他方法func (a *A) setY(y int) { a.y = y}func main() { var a A // a = A{} a.setX(3) a.setY(6) println(a.x, a.y) // 0 6 a.echo_A() // (_ A) a.echoA(&quot;a&quot;) // (A) a a.echo_жA() // (_ *A) a.echoжA(&quot;a&quot;) // (*A) a // 以下是定义在结构体值上的方法原型，通过调用结构体类型上定义的函数，传入结构体的值 A.echo_A(a) // (_ A) A.echoA(a, &quot;a&quot;) // (A) a // A.echo_жA(a) // A.echo_жA未定义 // A.echoжA(a) // A.echoжA未定义 A.setX(a, 4) // A.setY(a, 7) // A.setY未定义 println(a.x) // 0 b := &amp;a b.setX(2) b.setY(5) println(b.x, b.y) // 0 5 b.echo_A() // (_ A) b.echoA(&quot;b&quot;) // (A) b b.echo_жA() // (_ *A) b.echoжA(&quot;b&quot;) // (*A) b // 以下是定义在结构体指针上的方法原型，通过调用结构体类型指针上定义的函数，传入结构体的指针 (*A).echo_A(b) // (_ A) (*A).echoA(b, &quot;b&quot;) // (A) b (*A).echo_жA(b) // (_ *A) (*A).echoжA(b, &quot;b&quot;) // (*A) b (*A).setX(b, 1) (*A).setY(b, 8) println(b.x, b.y) // 0 8 // 调用结构体空指针上的方法，以下注释掉的代码都是空指针错误 var c *A // c = nil // c.setX(2) // c.setY(5) // println(c.x, c.y) // c.echo_A() // c.echoA() c.echo_жA() // (_ *A) c.echoжA(&quot;c&quot;) // (*A) c // (*A).echo_A(c) // (*A).echoA(c) (*A).echo_жA(c) // (_ *A) (*A).echoжA(c, &quot;c&quot;) // (*A) c // (*A).setX(c, 1) // (*A).setY(c, 8) // println(c.x, c.y)} 结构体中组合匿名字段时，匿名字段的方法会向外传递，其规则如下：匿名字段为值类型时：值的方法会传递给结构体的值，指针的方法会传递给结构体的指针；匿名字段为指针类型时：指针的方法会传递给值和指针；匿名字段为接口类型时：方法会传递给值和指针； Go中有匿名函数，但是没有匿名方法 并发 Concurrency 协程goroutine是由Go运行时环境管理的轻量级线程。使用关键字go调用一个函数/方法，启动一个新的协程goroutine 1234567891011121314151617package mainimport ( &quot;time&quot;)func say(i int) { println(&quot;goroutine:&quot;, i)}func main() { for i := 1; i &lt;= 5; i++ { go say(i) } say(0) time.Sleep(5 * time.Second)} 主协程goroutine输出0，其他由go启动的几个子协程分别输出1～5 goroutine: 0 goroutine: 1 goroutine: 2 goroutine: 3 goroutine: 4 goroutine: 5 goroutine 在相同的地址空间中运行，因此访问共享内存必须进行同步。 12345678910111213141516171819202122232425package mainimport ( &quot;sync&quot; &quot;time&quot;)var mu sync.Mutexvar i intfunc main() { for range [5]byte{} { go Add() } time.Sleep(5*time.Second) println(i)}func Add() { // 使用互斥锁防止多个协程goroutine同时修改共享变量 // 只能限制同时访问此方法修改变量，在方法外修改则限制是无效的 mu.Lock() defer mu.Unlock() i++} 使用通道channel进行同步 12345678910111213141516171819202122package mainimport ( &quot;time&quot;)var i intvar ch = make(chan byte, 1)func main() { for range [5]byte{} { go Add() } time.Sleep(5*time.Second) println(i)}func Add() { ch &lt;- 0 i++ &lt;-ch} 使用channel在不同的goroutine之间通信 1234567891011121314151617181920212223242526// 上一个例子只是将channel用作同步开关，稍做修改即可在不同goroutine间通信package mainimport ( &quot;time&quot;)var i intvar ch = make(chan int, 1)func main() { for range [5]byte{} { go Add() } ch &lt;- i time.Sleep(5*time.Second) i = &lt;-ch println(i)}func Add() { // 从channel中接收的值是来自其他goroutine发送的 x := &lt;-ch x++ ch &lt;- x} 测试 Testing Go中自带轻量级的测试框架testing和自带的go test命令来实现单元测试和基准测试 单元测试 Unit 有如下待测试testgo包，一段简单的求和代码 1234567891011121314package testgoimport &quot;math&quot;func Sum(min, max int) (sum int) { if min &lt; 0 || max &lt; 0 || max &gt; math.MaxInt32 || min &gt; max { return 0 } for ; min &lt;= max; min++ { sum += min } return} 测试源文件名必须是_test.go结尾的，go test的时候才会执行到相应的代码必须import testing包所有的测试用例函数必须以Test开头测试用例按照源码中编写的顺序依次执行测试函数TestXxx()的参数是*testing.T，可以使用该类型来记录错误或者是测试状态测试格式：func TestXxx (t *testing.T)，Xxx部分可以为任意的字母数字的组合，首字母不能是小写字母[a-z]，例如Testsum是错误的函数名。函数中通过调用*testing.T的Error，Errorf，FailNow，Fatal，FatalIf方法标注测试不通过，调用Log方法用来记录测试的信息。 12345678910111213141516package testgoimport &quot;testing&quot;func TestSum(t *testing.T) { s := Sum(1, 0) t.Log(&quot;Sum 1 to 0:&quot;, s) if 0 != s { t.Error(&quot;not equal.&quot;) } s = Sum(1, 10) t.Log(&quot;Sum 1 to 10:&quot;, s) if 55 != s { t.Error(&quot;not equal.&quot;) }} 在当前包中执行测试：go test -v === RUN TestSum— PASS: TestSum (0.00s) t0_test.go:7: Sum 1 to 0: 0 t0_test.go:12: Sum 1 to 10: 55 PASSok /home/cxy/go/src/testgo 0.004s 基准测试 Benchmark 基准测试 Benchmark用来检测函数/方法的性能基准测试用例函数必须以Benchmark开头go test默认不会执行基准测试的函数，需要加上参数-test.bench，语法:-test.bench=”test_name_regex”，例如go test -test.bench=”.*”表示测试全部的基准测试函数在基准测试用例中，在循环体内使用testing.B.N，使测试可以正常的运行 1234567package testgoimport &quot;testing&quot;func BenchmarkSum(b *testing.B) { b.Logf(&quot;Sum 1 to %d: %d\\n&quot;, b.N, Sum(1, b.N))} 在当前包中执行测试：go test -v -bench . BenchmarkSum 2000000000 0.91 ns/op— BENCH: BenchmarkSum t0_test.go:19: Sum 1 to 1: 1 t0_test.go:19: Sum 1 to 100: 5050 t0_test.go:19: Sum 1 to 10000: 50005000 t0_test.go:19: Sum 1 to 1000000: 500000500000 t0_test.go:19: Sum 1 to 100000000: 5000000050000000 t0_test.go:19: Sum 1 to 2000000000: 2000000001000000000 ok /home/cxy/go/src/testgo 1.922s","link":"/2019/10/05/Google-Go%E8%AF%AD%E8%A8%80-%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"二分搜索","slug":"二分搜索","link":"/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"CYK","slug":"CYK","link":"/tags/CYK/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"spark","slug":"spark","link":"/tags/spark/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"回归","slug":"回归","link":"/tags/%E5%9B%9E%E5%BD%92/"},{"name":"聚类","slug":"聚类","link":"/tags/%E8%81%9A%E7%B1%BB/"},{"name":"LeetCode","slug":"LeetCode","link":"/tags/LeetCode/"},{"name":"exhaustive search","slug":"exhaustive-search","link":"/tags/exhaustive-search/"},{"name":"Viterbi","slug":"Viterbi","link":"/tags/Viterbi/"},{"name":"条件随机场","slug":"条件随机场","link":"/tags/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"},{"name":"统计学习方法","slug":"统计学习方法","link":"/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"},{"name":"监督学习","slug":"监督学习","link":"/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"经典网络","slug":"经典网络","link":"/tags/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/"},{"name":"Go","slug":"Go","link":"/tags/Go/"}],"categories":[{"name":"LeetCode","slug":"LeetCode","link":"/categories/LeetCode/"},{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"NLP","slug":"深度学习/NLP","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"}]}