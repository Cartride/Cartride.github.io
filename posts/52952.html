<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Transformer模型及源代码 - MCFON</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="MCFON"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="MCFON"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="12345678910import numpy as npimport torchimport torch.nn as nnimport torch.nn.functional as Fimport math, copy, timefrom torch.autograd import Variableimport matplotlib.pyplot as pltimport seabornseab"><meta property="og:type" content="blog"><meta property="og:title" content="Transformer模型及源代码"><meta property="og:url" content="https://hunlp.com/posts/52952.html"><meta property="og:site_name" content="MCFON"><meta property="og:description" content="12345678910import numpy as npimport torchimport torch.nn as nnimport torch.nn.functional as Fimport math, copy, timefrom torch.autograd import Variableimport matplotlib.pyplot as pltimport seabornseab"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u5e4lk4j30u01877db.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u5ytquxj314u0u00wj.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u6cj8t6j30wt0u00yd.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u6sjuw7j309b08paab.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u73mlhoj60c00c2gm002.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u7ff6pfj30c60cf74w.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u7qvob5j30p408p0u7.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u8o5iiaj30by0770tc.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u94q0fbj30b506wmxd.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u9f007xj60av077aa902.jpg"><meta property="article:published_time" content="2021-06-05T15:58:52.000Z"><meta property="article:modified_time" content="2021-06-05T16:11:35.209Z"><meta property="article:author" content="ฅ´ω`ฅ"><meta property="article:tag" content="Transformer"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gr7u5e4lk4j30u01877db.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hunlp.com/posts/52952.html"},"headline":"Transformer模型及源代码","image":["https://tva1.sinaimg.cn/large/008i3skNly1gr7u5e4lk4j30u01877db.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gr7u5ytquxj314u0u00wj.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gr7u6cj8t6j30wt0u00yd.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gr7u6sjuw7j309b08paab.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gr7u73mlhoj60c00c2gm002.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gr7u7ff6pfj30c60cf74w.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gr7u7qvob5j30p408p0u7.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gr7u8o5iiaj30by0770tc.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gr7u94q0fbj30b506wmxd.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gr7u9f007xj60av077aa902.jpg"],"datePublished":"2021-06-05T15:58:52.000Z","dateModified":"2021-06-05T16:11:35.209Z","author":{"@type":"Person","name":"ฅ´ω`ฅ"},"publisher":{"@type":"Organization","name":"MCFON","logo":{"@type":"ImageObject","url":"https://hunlp.com/img/logo.png"}},"description":"12345678910import numpy as npimport torchimport torch.nn as nnimport torch.nn.functional as Fimport math, copy, timefrom torch.autograd import Variableimport matplotlib.pyplot as pltimport seabornseab"}</script><link rel="canonical" href="https://hunlp.com/posts/52952.html"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?b99420d7a06d2b3361a8efeaf6e20764";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-131608076-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-131608076-1');</script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>Transformer模型及源代码</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="${date_xml(page.date)}" title="${date_xml(page.date)}">2021-06-05</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="${date_xml(page.updated)}" title="${date_xml(page.updated)}">2021-06-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">32 分钟读完 (大约4779个字)</span></div></div><div class="content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> math, copy, time</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn</span><br><span class="line">seaborn.set_context(context=<span class="string">&#x27;talk&#x27;</span>)</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h1 id="模型架构">模型架构</h1>
<p>通用的 <strong>编码器解码器</strong> 架构：</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u5e4lk4j30u01877db.jpg" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderDecoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, encoder, decoder, src_embed, tgt_embed, generator</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        编码器、解码器、输入嵌入层、目标嵌入层、输出层</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(EncoderDecoder, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">        self.src_embed = src_embed</span><br><span class="line">        self.tgt_embed = tgt_embed</span><br><span class="line">        self.generator = generator</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, src, tgt, src_mask, tgt_mask</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        src --&gt; memory</span></span><br><span class="line"><span class="string">        memory + tgt --&gt; output</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        memory = self.encode(src, src_mask)</span><br><span class="line">        <span class="keyword">return</span> self.decode(memory, src_mask, tgt, tgt_mask)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span>(<span class="params">self, src, src_mask</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        src --&gt; memory</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.encoder(self.src_embed(src), src_mask)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span>(<span class="params">self, memory, src_mask, tgt, tgt_mask</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        memory + tgt --&gt; output</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;Define standard linear + softmax generation step.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, vocab</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.proj = nn.Linear(d_model, vocab)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(self.proj(x), dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="编码器">编码器</h2>
<p>编码器由多层 <code>N=6</code> 完全相同的层堆叠而成 <img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u5ytquxj314u0u00wj.jpg" /> 其层次结构如上图中所示： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1. Encoder</span><br><span class="line">    2. EncoderLayer</span><br><span class="line">        3. SublayerConnection</span><br><span class="line">            4. sublayer --&gt; self_attn</span><br><span class="line">            </span><br><span class="line">        3. SublayerConnection</span><br><span class="line">            4. sublayer --&gt; feed_forward</span><br><span class="line">            </span><br><span class="line">    2. EncoderLayer</span><br><span class="line">    .</span><br><span class="line">    .</span><br><span class="line">    .</span><br><span class="line">    .</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clone</span>(<span class="params">module, N</span>):</span></span><br><span class="line">    <span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(N)])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, layer, N</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        self.layers = clone(layer, N)</span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, mask</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        需要自主生成 mask </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerNorm</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    inputs: batch, seq_len, features</span></span><br><span class="line"><span class="string">    沿输入数据的特征维度归一化</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, features, eps=<span class="number">1e-6</span></span>):</span></span><br><span class="line">        <span class="comment"># 需要指定特征数量 features</span></span><br><span class="line">        <span class="built_in">super</span>(LayerNorm, self).__init__()</span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(features))</span><br><span class="line">        self.b_2 = nn.Parameter(torch.ones(features))</span><br><span class="line">        self.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        x --&gt; (x - x.mean) / x.std </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        mean = x.mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        std = x.std(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_layernorm</span>():</span></span><br><span class="line">    x = np.array([[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>]],],</span><br><span class="line">                 dtype=np.<span class="built_in">float</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Before Norm: \n&quot;</span>, x)</span><br><span class="line">    x = torch.from_numpy(x)  <span class="comment"># batch, seq_len, features</span></span><br><span class="line">    norm = LayerNorm(x.shape[-<span class="number">1</span>])</span><br><span class="line">    x = norm(x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;After Norm: \n&quot;</span>, x.detach().numpy())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test_layernorm()</span><br></pre></td></tr></table></figure>
<pre><code>Before Norm: 
 [[[1. 2. 3.]
  [2. 4. 5.]]]
After Norm: 
 [[[ 9.99999000e-07  1.00000000e+00  1.99999900e+00]
  [-9.10887369e-02  1.21821775e+00  1.87287099e+00]]]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SublayerConnection</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, size, dropout</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SublayerConnection, self).__init__()</span><br><span class="line">        self.norm = LayerNorm(size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, sublayer</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        指定内部的结构 sublayer，是 attention 层，还是 feed_forward 层</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> x + self.dropout(sublayer(self.norm(x)))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;size: d_model&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, size, self_attn, feed_forward, dropout</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(EncoderLayer, self).__init__()</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clone(SublayerConnection(size, dropout), <span class="number">2</span>)</span><br><span class="line">        self.size = size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, mask</span>):</span></span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, mask))</span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">1</span>](x, self.feed_forward)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="解码器">解码器</h2>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u6cj8t6j30wt0u00yd.jpg" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, layer, N</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.layers = clone(layer, N)</span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, memory, src_mask, tgt_mask</span>):</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, memory, src_mask, tgt_mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, size, self_attn, src_attn, feed_forward, dropout</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DecoderLayer, self).__init__()</span><br><span class="line">        self.size = size  <span class="comment"># 作为参数用于 layernorm 层</span></span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.src_attn = src_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clone(SublayerConnection(size, dropout), <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, memory, src_mask, tgt_mask</span>):</span></span><br><span class="line">        m = memory</span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, tgt_mask))</span><br><span class="line">        x = self.sublayer[<span class="number">1</span>](x, <span class="keyword">lambda</span> x: self.src_attn(x, m, m, src_mask))</span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">2</span>](x, self.feed_forward)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解码器一次输入序列中向量，当前步后面的序列需要被遮盖</span></span><br><span class="line"><span class="comment"># 需要被遮盖的单词被标记为 False </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subsequent_mask</span>(<span class="params">size</span>):</span></span><br><span class="line">    attn_shape = (<span class="number">1</span>, size, size)</span><br><span class="line">    subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="number">1</span>).astype(<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(subsequent_mask) == <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">plt.imshow(subsequent_mask(<span class="number">20</span>)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f83a0e5ec90&gt;</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u6sjuw7j309b08paab.jpg" /></p>
<p><code>np.triu(m,k=0)</code>：第 k 对角线以下的元素归零，中心对角线索引为 0 ，索引向右上角增加 1、2、3 ，向左下角-1、-2、-3 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)</span><br><span class="line">array([[ 1,  2,  3],</span><br><span class="line">       [ 4,  5,  6],</span><br><span class="line">       [ 0,  8,  9],</span><br><span class="line">       [ 0,  0, 12]])</span><br></pre></td></tr></table></figure></p>
<h2 id="注意力">注意力</h2>
<h3 id="点积注意力">点积注意力</h3>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u73mlhoj60c00c2gm002.jpg" /> <span class="math display">\[\mathrm{Attention}(Q, K, V) = \mathrm{softmax}(\frac{QK^T}{\sqrt{d_k}})V\]</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention</span>(<span class="params">query, key, value, mask=<span class="literal">None</span>, dropout=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    query : batch, target_len, feats</span></span><br><span class="line"><span class="string">    key   : batch, seq_len,    feats</span></span><br><span class="line"><span class="string">    value : batch, seq_len,    val_feats</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    return: batch, target_len, val_feats</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    d_k = query.size(-<span class="number">1</span>)</span><br><span class="line">    scores = torch.matmul(query, key.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(d_k)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line">    p_attn = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        p_attn = dropout(p_attn)</span><br><span class="line">    <span class="keyword">return</span> torch.matmul(p_attn, value), p_attn</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_attention</span>():</span></span><br><span class="line">    query = torch.randn(<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>)  <span class="comment"># batch, target_len, feats</span></span><br><span class="line">    key = torch.randn(<span class="number">3</span>, <span class="number">6</span>, <span class="number">4</span>)  <span class="comment"># batch, seq_len, feats</span></span><br><span class="line">    value = torch.randn(<span class="number">3</span>, <span class="number">6</span>, <span class="number">8</span>)  <span class="comment"># batch, seq_len, val_feats</span></span><br><span class="line">    attn, _ = attention(query, key, value)</span><br><span class="line">    <span class="built_in">print</span>(attn.shape)</span><br><span class="line">    <span class="keyword">assert</span> attn.shape == (<span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test passed&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test_attention()</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([3, 5, 8])
Test passed</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="多头注意力">多头注意力</h3>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u7ff6pfj30c60cf74w.jpg" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadedAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, h, d_model, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        h, num_heads</span></span><br><span class="line"><span class="string">        d_model, features</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(MultiHeadedAttention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> d_model % h == <span class="number">0</span></span><br><span class="line">        self.d_k = d_model // h</span><br><span class="line">        self.h = h</span><br><span class="line">        self.linears = clone(nn.Linear(d_model, d_model), <span class="number">4</span>)</span><br><span class="line">        self.attn = <span class="literal">None</span></span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, query, key, value, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># query,key,value: batch,seq_len,d_model</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            mask = mask.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        nbatches = query.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        query, key, value = [</span><br><span class="line">            l(x).view(nbatches, -<span class="number">1</span>, self.h, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">            <span class="keyword">for</span> l, x <span class="keyword">in</span> <span class="built_in">zip</span>(self.linears, (query, key, value))</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        x, self.attn = attention(</span><br><span class="line">            query,  <span class="comment"># batch,num_head,seq_len,feats</span></span><br><span class="line">            key,</span><br><span class="line">            value,</span><br><span class="line">            mask=mask,</span><br><span class="line">            dropout=self.dropout)</span><br><span class="line"></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(nbatches, -<span class="number">1</span>,</span><br><span class="line">                                                self.h * self.d_k)</span><br><span class="line">        <span class="comment"># batch,seq_len,num_head*feats</span></span><br><span class="line">        <span class="keyword">return</span> self.linears[-<span class="number">1</span>](x)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_multi_head</span>():</span></span><br><span class="line">    x = torch.randn(<span class="number">2</span>, <span class="number">4</span>, <span class="number">12</span>)</span><br><span class="line">    d_model = x.shape[-<span class="number">1</span>]</span><br><span class="line">    model = MultiHeadedAttention(<span class="number">2</span>, d_model)</span><br><span class="line">    attn = model(x, x, x)</span><br><span class="line">    <span class="keyword">assert</span> attn.shape == (<span class="number">2</span>, <span class="number">4</span>, <span class="number">12</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test passed!&quot;</span>)</span><br><span class="line"></span><br><span class="line">test_multi_head()</span><br></pre></td></tr></table></figure>
<pre><code>Test passed!</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="前向层">前向层</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionwiseFeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, d_ff, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PositionwiseFeedForward, self).__init__()</span><br><span class="line">        self.w_1 = nn.Linear(d_model, d_ff)</span><br><span class="line">        self.w_2 = nn.Linear(d_ff, d_model)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.w_2(self.dropout(F.relu(self.w_1(x))))</span><br></pre></td></tr></table></figure>
<h2 id="嵌入层">嵌入层</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Embeddings</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, vocab</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Embeddings, self).__init__()</span><br><span class="line">        self.lut = nn.Embedding(vocab, d_model)</span><br><span class="line">        self.d_model = d_model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.lut(x) * math.sqrt(self.d_model)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="位置编码">位置编码</h2>
<p><span class="math display">\[
\text{PE}(i,\delta) = 
\begin{cases}
\sin(\frac{i}{10000^{2\delta&#39;/d}}) &amp; \text{if } \delta = 2\delta&#39;\\
\cos(\frac{i}{10000^{2\delta&#39;/d}}) &amp; \text{if } \delta = 2\delta&#39; + 1\\
\end{cases}
\]</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEncoding</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;Implement the PE function.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, dropout, max_len=<span class="number">5000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute the positional encodings once in log space.</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(</span><br><span class="line">            torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) * -(math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x + Variable(self.pe[:, :x.size(<span class="number">1</span>)], requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line">pe = PositionalEncoding(<span class="number">20</span>, <span class="number">0</span>)</span><br><span class="line">y = pe.forward(Variable(torch.zeros(<span class="number">1</span>, <span class="number">100</span>, <span class="number">20</span>)))</span><br><span class="line">plt.plot(np.arange(<span class="number">100</span>), y[<span class="number">0</span>, :, <span class="number">4</span>:<span class="number">8</span>].data.numpy())</span><br><span class="line">plt.legend([<span class="string">&quot;dim %d&quot;</span>%p <span class="keyword">for</span> p <span class="keyword">in</span> [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]])</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f83a03f5f10&gt;</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u7qvob5j30p408p0u7.jpg" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="完整的模型">完整的模型</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_model</span>(<span class="params">src_vocab,</span></span></span><br><span class="line"><span class="params"><span class="function">               tgt_vocab,</span></span></span><br><span class="line"><span class="params"><span class="function">               N=<span class="number">6</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">               d_model=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">               d_ff=<span class="number">2048</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">               h=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">               dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">    <span class="string">&quot;Helper: Construct a model from hyperparameters.&quot;</span></span><br><span class="line">    c = copy.deepcopy</span><br><span class="line">    attn = MultiHeadedAttention(h, d_model)</span><br><span class="line">    ff = PositionwiseFeedForward(d_model, d_ff, dropout)</span><br><span class="line">    position = PositionalEncoding(d_model, dropout)</span><br><span class="line">    model = EncoderDecoder(</span><br><span class="line">        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),</span><br><span class="line">        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),</span><br><span class="line">        Generator(d_model, tgt_vocab),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># This was important from their code.</span></span><br><span class="line">    <span class="comment"># Initialize parameters with Glorot / fan_avg.</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        <span class="keyword">if</span> p.dim() &gt; <span class="number">1</span>:</span><br><span class="line">            nn.init.xavier_uniform_(p)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmp_model = make_model(<span class="number">10</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">tmp_model</span><br></pre></td></tr></table></figure>
<pre><code>EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): Linear(in_features=512, out_features=512, bias=True)
            (2): Linear(in_features=512, out_features=512, bias=True)
            (3): Linear(in_features=512, out_features=512, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): Linear(in_features=512, out_features=512, bias=True)
            (2): Linear(in_features=512, out_features=512, bias=True)
            (3): Linear(in_features=512, out_features=512, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): Linear(in_features=512, out_features=512, bias=True)
            (2): Linear(in_features=512, out_features=512, bias=True)
            (3): Linear(in_features=512, out_features=512, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): Linear(in_features=512, out_features=512, bias=True)
            (2): Linear(in_features=512, out_features=512, bias=True)
            (3): Linear(in_features=512, out_features=512, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): Linear(in_features=512, out_features=512, bias=True)
            (2): Linear(in_features=512, out_features=512, bias=True)
            (3): Linear(in_features=512, out_features=512, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): Linear(in_features=512, out_features=512, bias=True)
            (2): Linear(in_features=512, out_features=512, bias=True)
            (3): Linear(in_features=512, out_features=512, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (src_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(10, 512)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (tgt_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(10, 512)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (generator): Generator(
    (proj): Linear(in_features=512, out_features=10, bias=True)
  )
)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmp_model.src_embed</span><br></pre></td></tr></table></figure>
<pre><code>Sequential(
  (0): Embeddings(
    (lut): Embedding(10, 512)
  )
  (1): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
)</code></pre>
<h1 id="训练">训练</h1>
<h2 id="数据批次同时创建-mask">数据批次，同时创建 mask</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Batch</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, src, trg=<span class="literal">None</span>, pad=<span class="number">0</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        src: 输入序列</span></span><br><span class="line"><span class="string">        trg: 目标序列</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.src = src</span><br><span class="line">        self.src_mask = (src != pad).unsqueeze(-<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> trg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.trg = trg[:, :-<span class="number">1</span>]</span><br><span class="line">            self.trg_y = trg[:, <span class="number">1</span>:]</span><br><span class="line">            self.trg_mask = self.make_std_mask(self.trg, pad)</span><br><span class="line">            self.ntokens = (self.trg_y != pad).data.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_std_mask</span>(<span class="params">tgt, pad</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        将 pad 产生的 mask，和序列一次预测下一个单词产生的 mask 结合起来</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        tgt_mask = (tgt != pad).unsqueeze(-<span class="number">2</span>)</span><br><span class="line">        tgt_mask = tgt_mask &amp; Variable(</span><br><span class="line">            subsequent_mask(tgt.size(-<span class="number">1</span>)).type_as(tgt_mask.data))</span><br><span class="line">        <span class="keyword">return</span> tgt_mask</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">src = torch.tensor([[<span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">0</span>]])  <span class="comment"># batch=2,seq_len=5</span></span><br><span class="line">trg = torch.tensor([[<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">                                         <span class="number">0</span>]])  <span class="comment"># batch=2,seq_len=6</span></span><br><span class="line"></span><br><span class="line">sample = Batch(src, trg)</span><br><span class="line">sample.src_mask</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[ True,  True,  True, False, False]],

        [[ True,  True,  True,  True, False]]])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample.trg_mask, sample.ntokens</span><br></pre></td></tr></table></figure>
<pre><code>(tensor([[[ True, False, False, False, False],
          [ True,  True, False, False, False],
          [ True,  True,  True, False, False],
          [ True,  True,  True,  True, False],
          [ True,  True,  True,  True, False]],
 
         [[ True, False, False, False, False],
          [ True,  True, False, False, False],
          [ True,  True,  True, False, False],
          [ True,  True,  True, False, False],
          [ True,  True,  True, False, False]]]),
 tensor(5))</code></pre>
<h2 id="训练过程">训练过程</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_epoch</span>(<span class="params">data_iter, model, loss_compute</span>):</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    total_tokens = <span class="number">0</span></span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    tokens = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_iter):</span><br><span class="line">        out = model.forward(batch.src, batch.trg, batch.src_mask,</span><br><span class="line">                            batch.trg_mask)</span><br><span class="line">        loss = loss_compute(out, batch.trg_y, batch.ntokens)</span><br><span class="line">        total_loss += loss</span><br><span class="line">        total_tokens += batch.ntokens  <span class="comment"># 总 tokens 数</span></span><br><span class="line">        tokens += batch.ntokens  <span class="comment"># 50 批训练时的总 tokens 数</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">1</span>:</span><br><span class="line">            elapsed = time.time() - start</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch Step: %d Loss: %f Tokens per Sec: %f&quot;</span> %</span><br><span class="line">                  (i, loss / batch.ntokens, tokens / elapsed))</span><br><span class="line">            start = time.time()</span><br><span class="line">            tokens = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> total_loss / total_tokens</span><br></pre></td></tr></table></figure>
<h2 id="训练数据">训练数据</h2>
<p>standard WMT 2014 English-German dataset consisting of about 4.5 million sentence pairs</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_size_fn</span>(<span class="params">mew, count, sofar</span>):</span></span><br><span class="line">    <span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">1</span>:</span><br><span class="line">        max_src_in_batch = <span class="number">0</span></span><br><span class="line">        max_tgt_in_batch = <span class="number">0</span></span><br><span class="line">    max_src_in_batch = <span class="built_in">max</span>(max_src_in_batch,  <span class="built_in">len</span>(new.src))</span><br><span class="line">    max_tgt_in_batch = <span class="built_in">max</span>(max_tgt_in_batch,  <span class="built_in">len</span>(new.trg) + <span class="number">2</span>)</span><br><span class="line">    src_elements = count * max_src_in_batch</span><br><span class="line">    tgt_elements = count * max_tgt_in_batch</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(src_elements, tgt_elements)        </span><br></pre></td></tr></table></figure>
<h2 id="优化器">优化器</h2>
<p>Adam 优化器，参数<span class="math inline">\(\beta_1=0.9\)</span>，<span class="math inline">\(\beta_2=0.98\)</span>，<span class="math inline">\(\epsilon=10^{-9}\)</span>，变学习率：</p>
<p><span class="math display">\[lrate = d_{\text{model}}^{-0.5} \cdot
  \min({step\_num}^{-0.5},
    {step\_num} \cdot {warmup\_steps}^{-1.5})\]</span></p>
<p>其中： <span class="math inline">\(warmup_{steps}=4000\)</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NoamOpt</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, model_size, factor, warmup, optimizer</span>):</span></span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self._step = <span class="number">0</span></span><br><span class="line">        self.warmup = warmup</span><br><span class="line">        self.factor = factor</span><br><span class="line">        self.model_size = model_size</span><br><span class="line">        self._rate = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._step += <span class="number">1</span></span><br><span class="line">        rate = self.rate()</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> self.optimizer.param_groups:</span><br><span class="line">            p[<span class="string">&#x27;lr&#x27;</span>] = rate</span><br><span class="line">        self._rate = rate</span><br><span class="line">        self.optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rate</span>(<span class="params">self, step=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> step <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            step = self._step</span><br><span class="line">        <span class="keyword">return</span> self.factor * (self.model_size**(-<span class="number">0.5</span>) *</span><br><span class="line">                              <span class="built_in">min</span>(step**(-<span class="number">0.5</span>), step * self.warmup**(-<span class="number">1.5</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_std_opt</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="keyword">return</span> NoamOpt(</span><br><span class="line">        model.src_embed[<span class="number">0</span>].d_model, <span class="number">2</span>, <span class="number">4000</span>,</span><br><span class="line">        torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>),</span><br><span class="line">                         eps=<span class="number">1e-9</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">opts = [</span><br><span class="line">    NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="literal">None</span>),</span><br><span class="line">    NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">8000</span>, <span class="literal">None</span>),</span><br><span class="line">    NoamOpt(<span class="number">256</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="literal">None</span>),</span><br><span class="line">]</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">20000</span>),</span><br><span class="line">         [[opt.rate(i) <span class="keyword">for</span> opt <span class="keyword">in</span> opts] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">20000</span>)])</span><br><span class="line">plt.legend([<span class="string">&quot;512:4000&quot;</span>, <span class="string">&quot;512:8000&quot;</span>, <span class="string">&quot;256:4000&quot;</span>])</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7ffb17580990&gt;</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u8o5iiaj30by0770tc.jpg" /></p>
<h2 id="正则化">正则化</h2>
<p>标签平滑<code>Label Smoothing</code>：<span class="math inline">\(\epsilon_{ls}=0.1\)</span>，会降低 perplexity，因为模型将更不确定，但增加精度和<code>BLEU</code>分数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelSmoothing</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, size, padding_idx, smoothing=<span class="number">0.0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LabelSmoothing, self).__init__()</span><br><span class="line">        self.criterion = nn.KLDivLoss(size_average=<span class="literal">False</span>)</span><br><span class="line">        self.padding_idx = padding_idx</span><br><span class="line">        self.confidence = <span class="number">1.0</span> - smoothing</span><br><span class="line">        self.smoothing = smoothing</span><br><span class="line">        self.size = size</span><br><span class="line">        self.true_dist = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, target</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> x.size(<span class="number">1</span>) == self.size</span><br><span class="line">        true_dist = x.data.clone()</span><br><span class="line"></span><br><span class="line">        true_dist.fill_(self.smoothing / (self.size - <span class="number">2</span>))</span><br><span class="line">        </span><br><span class="line">        true_dist.scatter_(<span class="number">1</span>, target.data.unsqueeze(<span class="number">1</span>), self.confidence)</span><br><span class="line">        </span><br><span class="line">        true_dist[:, self.padding_idx] = <span class="number">0</span></span><br><span class="line">        mask = torch.nonzero(target.data == self.padding_idx)</span><br><span class="line">        <span class="keyword">if</span> mask.dim() &gt; <span class="number">0</span>:</span><br><span class="line">            true_dist.index_fill_(<span class="number">0</span>, mask.squeeze(), <span class="number">0.0</span>)</span><br><span class="line">        self.true_dist = true_dist</span><br><span class="line">        <span class="keyword">return</span> self.criterion(x, Variable(true_dist, requires_grad=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure>
<p><code>nn.KLDivLoss</code>: 输入为<code>log</code>概率分布，目标为概率分布；<span class="math inline">\(l(x,y) = L = \{ l_1,\dots,l_N \}, \quad l_n = y_n \cdot \left( \log y_n - x_n \right)\)</span><br />
指定<code>reduction</code>参数时： <span class="math display">\[    \ell(x, y) = \begin{cases}
    \operatorname{mean}(L), &amp; \text{if reduction} = \text{&#39;mean&#39;;} \\
    \operatorname{sum}(L),  &amp; \text{if reduction} = \text{&#39;sum&#39;.}
\end{cases}\]</span></p>
<p><code>Tensor.scatter_(dim, index, src)</code>： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = tensor([[0.1333, 0.1333, 0.1333, 0.1333, 0.1333],</span><br><span class="line">            [0.1333, 0.1333, 0.1333, 0.1333, 0.1333],</span><br><span class="line">            [0.1333, 0.1333, 0.1333, 0.1333, 0.1333]])       </span><br><span class="line">index = tensor([[2],</span><br><span class="line">                [1],</span><br><span class="line">                [0]])</span><br><span class="line">x.scatter(1, index, 0.6) --&gt;</span><br><span class="line">tensor([[0.1333, 0.1333, 0.6, 0.1333, 0.1333],</span><br><span class="line">        [0.1333, 0.6, 0.1333, 0.1333, 0.1333],</span><br><span class="line">        [0.6, 0.1333, 0.1333, 0.1333, 0.1333]]) </span><br><span class="line">    </span><br></pre></td></tr></table></figure> 例如上述的五分类中，目标序列 <code>[2，1，0]</code> 表示类别 2，1，0。将明确的类别转换成概率分布，使概率分布更均匀些，然后与预测概率分布求损失</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">crit = LabelSmoothing(size=<span class="number">5</span>, padding_idx=<span class="number">0</span>, smoothing=<span class="number">0.4</span>)</span><br><span class="line">predict = torch.FloatTensor([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">])</span><br><span class="line">v = crit(Variable(predict.log()), Variable(torch.LongTensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>])))</span><br><span class="line">plt.imshow(crit.true_dist)</span><br><span class="line">crit.true_dist</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333],
        [0.0000, 0.6000, 0.1333, 0.1333, 0.1333],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u94q0fbj30b506wmxd.jpg" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">x</span>):</span></span><br><span class="line">    d = x + <span class="number">3</span> * <span class="number">1</span></span><br><span class="line">    predict = torch.FloatTensor([</span><br><span class="line">        [<span class="number">0</span>, x / d, <span class="number">1</span> / d, <span class="number">1</span> / d, <span class="number">1</span> / d],  <span class="comment"># 概率分布，x 的值越大，标签 1 的概率越大</span></span><br><span class="line">    ])</span><br><span class="line">    <span class="comment">#print(predict)</span></span><br><span class="line">    <span class="keyword">return</span> crit(</span><br><span class="line">        Variable(predict.log()),</span><br><span class="line">        Variable(torch.LongTensor([<span class="number">1</span>])),  <span class="comment"># 真实标签为 1</span></span><br><span class="line">    ).item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">100</span>), [loss(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">100</span>)])</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7ffb16742c90&gt;]</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gr7u9f007xj60av077aa902.jpg" /></p>
<h2 id="测试模型">测试模型</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成随机数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_gen</span>(<span class="params">V, batch, nbatches</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nbatches):</span><br><span class="line">        data = torch.from_numpy(np.random.randint(<span class="number">1</span>, V, size=(batch, <span class="number">10</span>)))</span><br><span class="line">        data[:, <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        src = Variable(data, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        tgt = Variable(data, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">yield</span> Batch(src, tgt, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleLossCompute</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, generator, criterion, opt=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.generator = generator  <span class="comment"># 模型最后的输出层</span></span><br><span class="line">        self.criterion = criterion</span><br><span class="line">        self.opt = opt</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, x, y, norm</span>):</span></span><br><span class="line">        x = self.generator(x)</span><br><span class="line">        loss = self.criterion(x.contiguous().view(-<span class="number">1</span>, x.size(-<span class="number">1</span>)),</span><br><span class="line">                              y.contiguous().view(-<span class="number">1</span>)) / norm</span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.opt.step()</span><br><span class="line">            self.opt.optimizer.zero_grad()</span><br><span class="line">        <span class="keyword">return</span> loss.data.item() * norm</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">V = <span class="number">11</span></span><br><span class="line">criterion = LabelSmoothing(size=V, padding_idx=<span class="number">0</span>, smoothing=<span class="number">0.0</span>)</span><br><span class="line">model = make_model(V, V, N=<span class="number">2</span>)</span><br><span class="line">model_opt = NoamOpt(</span><br><span class="line">    model.src_embed[<span class="number">0</span>].d_model, <span class="number">1</span>, <span class="number">400</span>,</span><br><span class="line">    torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">20</span>), model,</span><br><span class="line">              SimpleLossCompute(model.generator, criterion, model_opt))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">5</span>), model,</span><br><span class="line">                  SimpleLossCompute(model.generator, criterion, <span class="literal">None</span>)))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch Step: 1 Loss: 3.041517 Tokens per Sec: 2320.010498
Epoch Step: 1 Loss: 2.116642 Tokens per Sec: 3337.003174
tensor(2.0963)
Epoch Step: 1 Loss: 2.251899 Tokens per Sec: 2198.680176
Epoch Step: 1 Loss: 1.861713 Tokens per Sec: 3322.143066
tensor(1.9056)
Epoch Step: 1 Loss: 2.097054 Tokens per Sec: 2199.775635
Epoch Step: 1 Loss: 1.919798 Tokens per Sec: 3104.268799
tensor(1.9386)
Epoch Step: 1 Loss: 1.955538 Tokens per Sec: 2096.228027
Epoch Step: 1 Loss: 1.854445 Tokens per Sec: 3121.148926
tensor(1.8574)
Epoch Step: 1 Loss: 2.210659 Tokens per Sec: 2088.976074
Epoch Step: 1 Loss: 1.806028 Tokens per Sec: 3116.300537
tensor(1.7957)
Epoch Step: 1 Loss: 2.442501 Tokens per Sec: 2085.300537
Epoch Step: 1 Loss: 1.931611 Tokens per Sec: 3112.506348
tensor(1.9629)
Epoch Step: 1 Loss: 1.962478 Tokens per Sec: 2092.424561
Epoch Step: 1 Loss: 1.450812 Tokens per Sec: 3114.582275
tensor(1.5110)
Epoch Step: 1 Loss: 1.954074 Tokens per Sec: 2087.149170
Epoch Step: 1 Loss: 1.519574 Tokens per Sec: 3094.708252
tensor(1.4481)
Epoch Step: 1 Loss: 1.859929 Tokens per Sec: 2039.030151
Epoch Step: 1 Loss: 1.412592 Tokens per Sec: 3088.327881
tensor(1.3660)
Epoch Step: 1 Loss: 1.943988 Tokens per Sec: 2065.341797
Epoch Step: 1 Loss: 1.302344 Tokens per Sec: 2979.704590
tensor(1.3880)</code></pre>
<h2 id="解码算法">解码算法</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greedy_decode</span>(<span class="params">model, src, src_mask, max_len, start_symbol</span>):</span></span><br><span class="line">    memory = model.encode(src, src_mask)</span><br><span class="line">    ys = torch.ones(<span class="number">1</span>, <span class="number">1</span>).fill_(start_symbol).type_as(src.data)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_len - <span class="number">1</span>):</span><br><span class="line">        out = model.decode(</span><br><span class="line">            memory, src_mask, Variable(ys),</span><br><span class="line">            Variable(subsequent_mask(ys.size(<span class="number">1</span>)).type_as(src.data)))</span><br><span class="line">        prob = model.generator(out[:, -<span class="number">1</span>])</span><br><span class="line">        _, next_word = torch.<span class="built_in">max</span>(prob, dim=<span class="number">1</span>)</span><br><span class="line">        next_word = next_word.item()</span><br><span class="line">        ys = torch.cat(</span><br><span class="line">            [ys, torch.ones(<span class="number">1</span>, <span class="number">1</span>).type_as(src.data).fill_(next_word)], dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> ys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">src = Variable(torch.LongTensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]]))</span><br><span class="line">src_mask = Variable(torch.ones(<span class="number">1</span>, <span class="number">1</span>, <span class="number">10</span>))</span><br><span class="line"><span class="built_in">print</span>(greedy_decode(model, src, src_mask, max_len=<span class="number">10</span>, start_symbol=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[ 1,  2,  4,  3,  7,  9, 10,  8,  9,  8]])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="实战">实战</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data, datasets</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">import</span> spacy</span><br><span class="line">    spacy_de = spacy.load(<span class="string">&quot;de_core_news_sm&quot;</span>)</span><br><span class="line">    spacy_en = spacy.load(<span class="string">&quot;en_core_web_sm&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_de</span>(<span class="params">text</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_de.tokenizer(text)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_en</span>(<span class="params">text</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_en.tokenizer(text)]</span><br><span class="line"></span><br><span class="line">    BOS_WORD = <span class="string">&#x27;&lt;s&gt;&#x27;</span></span><br><span class="line">    EOS_WORD = <span class="string">&#x27;&lt;/s&gt;&#x27;</span></span><br><span class="line">    BLANK_WORD = <span class="string">&quot;&lt;blank&gt;&quot;</span></span><br><span class="line">    SRC = data.Field(tokenize=tokenize_de,</span><br><span class="line">                     pad_token=BLANK_WORD)  <span class="comment"># 定义预处理流程，分词、填充、</span></span><br><span class="line">    TGT = data.Field(tokenize=tokenize_en,</span><br><span class="line">                     init_token=BOS_WORD,</span><br><span class="line">                     eos_token=EOS_WORD,</span><br><span class="line">                     pad_token=BLANK_WORD)</span><br><span class="line"></span><br><span class="line">    MAX_LEN = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集</span></span><br><span class="line">    train, val, test = datasets.IWSLT.splits(</span><br><span class="line">        exts=(<span class="string">&#x27;.de&#x27;</span>, <span class="string">&#x27;.en&#x27;</span>),</span><br><span class="line">        fields=(SRC, TGT),</span><br><span class="line">        filter_pred=<span class="keyword">lambda</span> x: <span class="built_in">len</span>(<span class="built_in">vars</span>(x)[<span class="string">&#x27;src&#x27;</span>]) &lt;= MAX_LEN <span class="keyword">and</span> <span class="built_in">len</span>(</span><br><span class="line">            <span class="built_in">vars</span>(x)[<span class="string">&#x27;trg&#x27;</span>]) &lt;= MAX_LEN)</span><br><span class="line">    MIN_FREQ = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建词汇表</span></span><br><span class="line">    SRC.build_vocab(train.src, min_freq=MIN_FREQ)</span><br><span class="line">    TGT.build_vocab(train.trg, min_freq=MIN_FREQ)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据分批对训练速度很重要：需要拆分成均匀的批次，最小的填充</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyIterator</span>(<span class="params">data.Iterator</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_batches</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.train: <span class="comment"># 训练模式，数据分批，然后打乱顺序</span></span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">def</span> <span class="title">pool</span>(<span class="params">d, random_shuffler</span>):</span></span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> data.batch(d, self.batch_size * <span class="number">100</span>):</span><br><span class="line">                    p_batch = data.batch(<span class="built_in">sorted</span>(p, key=self.sort_key),</span><br><span class="line">                                         self.batch_size, self.batch_size_fn)</span><br><span class="line">                    <span class="keyword">for</span> b <span class="keyword">in</span> random_shuffler(<span class="built_in">list</span>(p_batch)):</span><br><span class="line">                        <span class="keyword">yield</span> b</span><br><span class="line"></span><br><span class="line">            self.batches = pool(self.data(), self.random_shuffler)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.batches = []</span><br><span class="line">            <span class="keyword">for</span> b <span class="keyword">in</span> data.batch(self.data(), self.batch_size,</span><br><span class="line">                                self.batch_size_fn):</span><br><span class="line">                self.batches.append(<span class="built_in">sorted</span>(b, key=self.sort_key))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rebatch</span>(<span class="params">pad_idx, batch</span>):</span> <span class="comment"># batch first --&gt; True</span></span><br><span class="line">    <span class="string">&quot;Fix order in torchtext to match ours&quot;</span></span><br><span class="line">    src, trg = batch.src.transpose(<span class="number">0</span>, <span class="number">1</span>), batch.trg.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> Batch(src, trg, pad_idx)</span><br></pre></td></tr></table></figure>
<h2 id="并行计算">并行计算</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 multi-gpu 加速训练速度：将单词生成拆分成块，便于并行处理</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiGPULossCompute</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, generator, criterion, devices, opt=<span class="literal">None</span>, chunk_size=<span class="number">5</span></span>):</span></span><br><span class="line">        self.generator = generator</span><br><span class="line">        self.criterion = nn.parallel.replicate(criterion, devices=devices)</span><br><span class="line">        self.opt = opt</span><br><span class="line">        self.devices = devices</span><br><span class="line">        self.chunk_size = chunk_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, out, targets, normalize</span>):</span></span><br><span class="line">        </span><br><span class="line">        total = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将最终的线性输出层 并行 到多个 gpu中</span></span><br><span class="line">        generator = nn.parallel.replicate(self.generator, devices=devices)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将 transformer 的输出张量 并行 多个 gpu 中</span></span><br><span class="line">        out_scatter = nn.parallel.scatter(out, target_gpus=self.devices)</span><br><span class="line">        out_grad = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> out_scatter]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将目标 并行 到多个 gpu 中</span></span><br><span class="line">        targets = nn.parallel.scatter(targets, target_gpus=self.devices)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将生成拆分成块？？</span></span><br><span class="line">        chunk_size = self.chunk_size</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, out_scatter[<span class="number">0</span>].size(<span class="number">1</span>), chunk_size):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 预测分布</span></span><br><span class="line">            out_column = [[</span><br><span class="line">                Variable(o[:, i:i + chunk_size].data,</span><br><span class="line">                         requires_grad=self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>)</span><br><span class="line">            ] <span class="keyword">for</span> o <span class="keyword">in</span> out_scatter]</span><br><span class="line">            gen = nn.parallel.parallel_apply(generator, out_column)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算损失</span></span><br><span class="line">            y = [(g.contiguous().view(-<span class="number">1</span>, g.size(-<span class="number">1</span>)),</span><br><span class="line">                  t[:, i:i + chunk_size].contiguous().view(-<span class="number">1</span>))</span><br><span class="line">                 <span class="keyword">for</span> g, t <span class="keyword">in</span> <span class="built_in">zip</span>(gen, targets)]</span><br><span class="line">            loss = nn.parallel.parallel_apply(self.criterion, y)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 损失求和并归一化</span></span><br><span class="line">            l = nn.parallel.gather(loss, target_device=self.devices[<span class="number">0</span>])</span><br><span class="line">            l = l.<span class="built_in">sum</span>()[<span class="number">0</span>] / normalize</span><br><span class="line">            total += l.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 反向传播</span></span><br><span class="line">            <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                l.backward()</span><br><span class="line">                <span class="keyword">for</span> j, l <span class="keyword">in</span> <span class="built_in">enumerate</span>(loss):</span><br><span class="line">                    out_grad[j].append(out_column[j][<span class="number">0</span>].grad.data.clone())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播整个模型</span></span><br><span class="line">        <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            out_grad = [Variable(torch.cat(og, dim=<span class="number">1</span>)) <span class="keyword">for</span> og <span class="keyword">in</span> out_grad]</span><br><span class="line">            o1 = out</span><br><span class="line">            o2 = nn.parallel.gather(out_grad, target_device=self.devices[<span class="number">0</span>])</span><br><span class="line">            o1.backward(gradient=o2)</span><br><span class="line">            self.opt.step()</span><br><span class="line">            self.opt.optimizer.zero_grad()</span><br><span class="line">        <span class="keyword">return</span> total * normalize</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">devices = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="literal">True</span>:</span><br><span class="line">    pad_idx = TGT.vocab.stoi[<span class="string">&quot;&lt;blank&gt;&quot;</span>]</span><br><span class="line">    model = make_model(<span class="built_in">len</span>(SRC.vocab), <span class="built_in">len</span>(TGT.vocab), N=<span class="number">6</span>)</span><br><span class="line">    model.cuda()</span><br><span class="line">    criterion = LabelSmoothing(size=<span class="built_in">len</span>(TGT.vocab),</span><br><span class="line">                               padding_idx=pad_idx,</span><br><span class="line">                               smoothing=<span class="number">0.1</span>)</span><br><span class="line">    criterion.cuda()</span><br><span class="line">    BATCH_SIZE = <span class="number">12000</span></span><br><span class="line">    train_iter = MyIterator(train,</span><br><span class="line">                            batch_size=BATCH_SIZE,</span><br><span class="line">                            device=<span class="number">0</span>,</span><br><span class="line">                            repeat=<span class="literal">False</span>,</span><br><span class="line">                            sort_key=<span class="keyword">lambda</span> x: (<span class="built_in">len</span>(x.src), <span class="built_in">len</span>(x.trg)),</span><br><span class="line">                            batch_size_fn=batch_size_fn,</span><br><span class="line">                            train=<span class="literal">True</span>)</span><br><span class="line">    valid_iter = MyIterator(val,</span><br><span class="line">                            batch_size=BATCH_SIZE,</span><br><span class="line">                            device=<span class="number">0</span>,</span><br><span class="line">                            repeat=<span class="literal">False</span>,</span><br><span class="line">                            sort_key=<span class="keyword">lambda</span> x: (<span class="built_in">len</span>(x.src), <span class="built_in">len</span>(x.trg)),</span><br><span class="line">                            batch_size_fn=batch_size_fn,</span><br><span class="line">                            train=<span class="literal">False</span>)</span><br><span class="line">    model_par = nn.DataParallel(model, device_ids=devices)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="literal">False</span>:</span><br><span class="line">    model_opt = NoamOpt(</span><br><span class="line">        model.src_embed[<span class="number">0</span>].d_model, <span class="number">1</span>, <span class="number">2000</span>,</span><br><span class="line">        torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>),</span><br><span class="line">                         eps=<span class="number">1e-9</span>))</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        model_par.train()</span><br><span class="line">        run_epoch((rebatch(pad_idx, b) <span class="keyword">for</span> b <span class="keyword">in</span> train_iter), model_par,</span><br><span class="line">                  MultiGPULossCompute(model.generator,</span><br><span class="line">                                      criterion,</span><br><span class="line">                                      devices=devices,</span><br><span class="line">                                      opt=model_opt))</span><br><span class="line">        model_par.<span class="built_in">eval</span>()</span><br><span class="line">        loss = run_epoch((rebatch(pad_idx, b) <span class="keyword">for</span> b <span class="keyword">in</span> valid_iter), model_par,</span><br><span class="line">                         MultiGPULossCompute(model.generator,</span><br><span class="line">                                             criterion,</span><br><span class="line">                                             devices=devices,</span><br><span class="line">                                             opt=<span class="literal">None</span>))</span><br><span class="line">        <span class="built_in">print</span>(loss)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    model = torch.load(<span class="string">&quot;iwslt.pt&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(valid_iter):</span><br><span class="line">    src = batch.src.transpose(<span class="number">0</span>, <span class="number">1</span>)[:<span class="number">1</span>]</span><br><span class="line">    src_mask = (src != SRC.vocab.stoi[<span class="string">&quot;&lt;blank&gt;&quot;</span>]).unsqueeze(-<span class="number">2</span>)</span><br><span class="line">    out = greedy_decode(model,</span><br><span class="line">                        src,</span><br><span class="line">                        src_mask,</span><br><span class="line">                        max_len=<span class="number">60</span>,</span><br><span class="line">                        start_symbol=TGT.vocab.stoi[<span class="string">&quot;&lt;s&gt;&quot;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Translation:&quot;</span>, end=<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, out.size(<span class="number">1</span>)):</span><br><span class="line">        sym = TGT.vocab.itos[out[<span class="number">0</span>, i]]</span><br><span class="line">        <span class="keyword">if</span> sym == <span class="string">&quot;&lt;/s&gt;&quot;</span>: <span class="keyword">break</span></span><br><span class="line">        <span class="built_in">print</span>(sym, end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Target:&quot;</span>, end=<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, batch.trg.size(<span class="number">0</span>)):</span><br><span class="line">        sym = TGT.vocab.itos[batch.trg.data[i, <span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">if</span> sym == <span class="string">&quot;&lt;/s&gt;&quot;</span>: <span class="keyword">break</span></span><br><span class="line">        <span class="built_in">print</span>(sym, end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="额外的组件">额外的组件</h1>
<h2 id="bpe-word-piece将单词拆分成-子词"><code>BPE/ Word-piece</code>：将单词拆分成 子词</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="共享权重输入与目标的嵌入矩阵相同">共享权重：输入与目标的嵌入矩阵相同</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="literal">False</span>:</span><br><span class="line">    model.src_embed[<span class="number">0</span>].lut.weight = model.tgt_embeddings[<span class="number">0</span>].lut.weight</span><br><span class="line">    model.generator.lut.weight = model.tgt_embed[<span class="number">0</span>].lut.weight</span><br></pre></td></tr></table></figure>
<h2 id="beam-search"><code>Beam Search</code></h2>
<p>https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/translate/beam_search.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="model-averaging将最后-k-个-checkpoint-平均创造组合模型"><code>Model Averaging</code>：将最后 k 个 checkpoint 平均，创造组合模型</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">average</span>(<span class="params">model, models</span>):</span></span><br><span class="line">    <span class="string">&quot;Average models into model&quot;</span></span><br><span class="line">    <span class="keyword">for</span> ps <span class="keyword">in</span> <span class="built_in">zip</span>(*[m.params() <span class="keyword">for</span> m <span class="keyword">in</span> [model] + models]):</span><br><span class="line">        p[<span class="number">0</span>].copy_(torch.<span class="built_in">sum</span>(*ps[<span class="number">1</span>:]) / <span class="built_in">len</span>(ps[<span class="number">1</span>:]))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="注意力可视化">注意力可视化</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">tgt_sent = trans.split()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">data, x, y, ax</span>):</span></span><br><span class="line">    seaborn.heatmap(data,</span><br><span class="line">                    xticklabels=x,</span><br><span class="line">                    square=<span class="literal">True</span>,</span><br><span class="line">                    yticklabels=y,</span><br><span class="line">                    vmin=<span class="number">0.0</span>,</span><br><span class="line">                    vmax=<span class="number">1.0</span>,</span><br><span class="line">                    cbar=<span class="literal">False</span>,</span><br><span class="line">                    ax=ax)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>):</span><br><span class="line">    fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">4</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Encoder Layer&quot;</span>, layer + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        draw(model.encoder.layers[layer].self_attn.attn[<span class="number">0</span>, h].data,</span><br><span class="line">             sent,</span><br><span class="line">             sent <span class="keyword">if</span> h == <span class="number">0</span> <span class="keyword">else</span> [],</span><br><span class="line">             ax=axs[h])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>):</span><br><span class="line">    fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">4</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Decoder Self Layer&quot;</span>, layer + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        draw(model.decoder.layers[layer].self_attn.attn[<span class="number">0</span>, h].</span><br><span class="line">             data[:<span class="built_in">len</span>(tgt_sent), :<span class="built_in">len</span>(tgt_sent)],</span><br><span class="line">             tgt_sent,</span><br><span class="line">             tgt_sent <span class="keyword">if</span> h == <span class="number">0</span> <span class="keyword">else</span> [],</span><br><span class="line">             ax=axs[h])</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Decoder Src Layer&quot;</span>, layer + <span class="number">1</span>)</span><br><span class="line">    fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">4</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        draw(model.decoder.layers[layer].self_attn.attn[<span class="number">0</span>, h].</span><br><span class="line">             data[:<span class="built_in">len</span>(tgt_sent), :<span class="built_in">len</span>(sent)],</span><br><span class="line">             sent,</span><br><span class="line">             tgt_sent <span class="keyword">if</span> h == <span class="number">0</span> <span class="keyword">else</span> [],</span><br><span class="line">             ax=axs[h])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
</div><div class="article-licensing box"><div class="licensing-title"><p>Transformer模型及源代码</p><p><a href="https://hunlp.com/posts/52952.html">https://hunlp.com/posts/52952.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>ฅ´ω`ฅ</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-06-05</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-06-06</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Transformer/">Transformer </a></div></div><div class="bdsharebuttonbox"><a class="bds_more" href="#" data-cmd="more"></a><a class="bds_qzone" href="#" data-cmd="qzone" title="分享到QQ空间"></a><a class="bds_tsina" href="#" data-cmd="tsina" title="分享到新浪微博"></a><a class="bds_tqq" href="#" data-cmd="tqq" title="分享到腾讯微博"></a><a class="bds_renren" href="#" data-cmd="renren" title="分享到人人网"></a><a class="bds_weixin" href="#" data-cmd="weixin" title="分享到微信"></a></div><script>window._bd_share_config = { "common": { "bdSnsKey": {}, "bdText": "", "bdMini": "2", "bdPic": "", "bdStyle": "0", "bdSize": "16" }, "share": {} }; with (document) 0[(getElementsByTagName('head')[0] || body).appendChild(createElement('script')).src = 'http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion=' + ~(-new Date() / 36e5)];</script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/zfb.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wx.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/553.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item">基于HMM和Viterbi算法的序列标注</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/61928.html"><span class="level-item">词表征与词向量</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "5dbf90d2d56d839db5b6ed4c926cb075",
            repo: "Cartride.github.io",
            owner: "Cartride",
            clientID: "8f4a2426c347380a6ee4",
            clientSecret: "8dc8cd44b071426b35d0bd60634941371170b798",
            admin: ["Cartride"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#模型架构"><span class="level-left"><span class="level-item">1</span><span class="level-item">模型架构</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#编码器"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">编码器</span></span></a></li><li><a class="level is-mobile" href="#解码器"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">解码器</span></span></a></li><li><a class="level is-mobile" href="#注意力"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">注意力</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#点积注意力"><span class="level-left"><span class="level-item">1.3.1</span><span class="level-item">点积注意力</span></span></a></li><li><a class="level is-mobile" href="#多头注意力"><span class="level-left"><span class="level-item">1.3.2</span><span class="level-item">多头注意力</span></span></a></li></ul></li><li><a class="level is-mobile" href="#前向层"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">前向层</span></span></a></li><li><a class="level is-mobile" href="#嵌入层"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">嵌入层</span></span></a></li><li><a class="level is-mobile" href="#位置编码"><span class="level-left"><span class="level-item">1.6</span><span class="level-item">位置编码</span></span></a></li><li><a class="level is-mobile" href="#完整的模型"><span class="level-left"><span class="level-item">1.7</span><span class="level-item">完整的模型</span></span></a></li></ul></li><li><a class="level is-mobile" href="#训练"><span class="level-left"><span class="level-item">2</span><span class="level-item">训练</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#数据批次同时创建-mask"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">数据批次，同时创建 mask</span></span></a></li><li><a class="level is-mobile" href="#训练过程"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">训练过程</span></span></a></li><li><a class="level is-mobile" href="#训练数据"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">训练数据</span></span></a></li><li><a class="level is-mobile" href="#优化器"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">优化器</span></span></a></li><li><a class="level is-mobile" href="#正则化"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">正则化</span></span></a></li><li><a class="level is-mobile" href="#测试模型"><span class="level-left"><span class="level-item">2.6</span><span class="level-item">测试模型</span></span></a></li><li><a class="level is-mobile" href="#解码算法"><span class="level-left"><span class="level-item">2.7</span><span class="level-item">解码算法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#实战"><span class="level-left"><span class="level-item">3</span><span class="level-item">实战</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#并行计算"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">并行计算</span></span></a></li></ul></li><li><a class="level is-mobile" href="#额外的组件"><span class="level-left"><span class="level-item">4</span><span class="level-item">额外的组件</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bpe-word-piece将单词拆分成-子词"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">BPE/ Word-piece：将单词拆分成 子词</span></span></a></li><li><a class="level is-mobile" href="#共享权重输入与目标的嵌入矩阵相同"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">共享权重：输入与目标的嵌入矩阵相同</span></span></a></li><li><a class="level is-mobile" href="#beam-search"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">Beam Search</span></span></a></li><li><a class="level is-mobile" href="#model-averaging将最后-k-个-checkpoint-平均创造组合模型"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">Model Averaging：将最后 k 个 checkpoint 平均，创造组合模型</span></span></a></li></ul></li><li><a class="level is-mobile" href="#注意力可视化"><span class="level-left"><span class="level-item">5</span><span class="level-item">注意力可视化</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a><p class="is-size-7"><span>&copy; 2022 ฅ´ω`ฅ</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>