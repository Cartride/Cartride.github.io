<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>快速迭代聚类 - MCFON</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="MCFON"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="MCFON"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="谱聚类算法的原理&amp;amp;emsp;&amp;amp;emsp;在分析快速迭代聚类之前，我们先来了解一下谱聚类算法。谱聚类算法是建立在谱图理论的基础上的算法，与传统的聚类算法相比，它能在任意形状的样本空间上聚类且能够收敛到全局最优解。谱聚类算法的主要思想是将聚类问题转换为无向图的划分问题。"><meta property="og:type" content="blog"><meta property="og:title" content="快速迭代聚类"><meta property="og:url" content="https://hunlp.com/posts/3118787290.html"><meta property="og:site_name" content="MCFON"><meta property="og:description" content="谱聚类算法的原理&amp;amp;emsp;&amp;amp;emsp;在分析快速迭代聚类之前，我们先来了解一下谱聚类算法。谱聚类算法是建立在谱图理论的基础上的算法，与传统的聚类算法相比，它能在任意形状的样本空间上聚类且能够收敛到全局最优解。谱聚类算法的主要思想是将聚类问题转换为无向图的划分问题。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hunlp.com/gallery/6.jpg"><meta property="article:published_time" content="2019-08-01T08:00:26.000Z"><meta property="article:modified_time" content="2019-08-03T03:54:06.155Z"><meta property="article:author" content="ฅ´ω`ฅ"><meta property="article:tag" content="spark"><meta property="article:tag" content="聚类"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/gallery/6.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hunlp.com/posts/3118787290.html"},"headline":"快速迭代聚类","image":["https://hunlp.com/gallery/6.jpg"],"datePublished":"2019-08-01T08:00:26.000Z","dateModified":"2019-08-03T03:54:06.155Z","author":{"@type":"Person","name":"ฅ´ω`ฅ"},"publisher":{"@type":"Organization","name":"MCFON","logo":{"@type":"ImageObject","url":"https://hunlp.com/img/logo.png"}},"description":"谱聚类算法的原理&amp;emsp;&amp;emsp;在分析快速迭代聚类之前，我们先来了解一下谱聚类算法。谱聚类算法是建立在谱图理论的基础上的算法，与传统的聚类算法相比，它能在任意形状的样本空间上聚类且能够收敛到全局最优解。谱聚类算法的主要思想是将聚类问题转换为无向图的划分问题。"}</script><link rel="canonical" href="https://hunlp.com/posts/3118787290.html"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?b99420d7a06d2b3361a8efeaf6e20764";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-131608076-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-131608076-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>快速迭代聚类</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="${date_xml(page.date)}" title="${date_xml(page.date)}">2019-08-01</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="${date_xml(page.updated)}" title="${date_xml(page.updated)}">2019-08-03</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">19 分钟读完 (大约2891个字)</span></div></div><div class="content"><h2 id="谱聚类算法的原理"><a href="#谱聚类算法的原理" class="headerlink" title="谱聚类算法的原理"></a>谱聚类算法的原理</h2><p>&emsp;&emsp;在分析快速迭代聚类之前，我们先来了解一下谱聚类算法。谱聚类算法是建立在谱图理论的基础上的算法，与传统的聚类算法相比，它能在任意形状的样本空间上聚类且能够收敛到全局最优解。<br>谱聚类算法的主要思想是将聚类问题转换为无向图的划分问题。</p>
<span id="more"></span>
<ul>
<li>首先，数据点被看做一个图的顶点<code>v</code>，两数据的相似度看做图的边，边的集合由$E=A_{ij}$表示，由此构造样本数据集的相似度矩阵<code>A</code>，并求出拉普拉斯矩阵<code>L</code>。</li>
<li>其次，根据划分准则使子图内部相似度尽量大，子图之间的相似度尽量小，计算出L的特征值和特征向量</li>
<li>最后，选择k个不同的特征向量对数据点聚类</li>
</ul>
<p>&emsp;&emsp;那么如何求拉普拉斯矩阵呢？</p>
<p>&emsp;&emsp;将相似度矩阵<code>A</code>的每行元素相加就可以得到该顶点的度，我们定义以度为对角元素的对角矩阵称为度矩阵<code>D</code>。可以通过<code>A</code>和<code>D</code>来确定拉普拉斯矩阵。拉普拉斯矩阵分为规范和非规范两种，规范的拉普拉斯矩阵<br>表示为<code>L=D-A</code>，非规范的拉普拉斯矩阵表示为$L=I-D^{-1}A$ 。</p>
<p>&emsp;&emsp;谱聚类算法的一般过程如下：</p>
<ul>
<li>（1）输入待聚类的数据点集以及聚类数<code>k</code>；</li>
<li>（2）根据相似性度量构造数据点集的拉普拉斯矩阵<code>L</code>；</li>
<li>（3）选取L的前<code>k</code>个（默认从小到大,这里的<code>k</code>和聚类数可以不一样）特征值和特征向量，构造特征向量空间（这实际上是一个降维的过程）；</li>
<li>（4）使用传统方法对特征向量聚类，并对应于原始数据的聚类。</li>
</ul>
<p>&emsp;&emsp;谱聚类算法和传统的聚类方法（例如<code>K-means</code>）比起来有不少优点：</p>
<ul>
<li><p>和<code>K-medoids</code>类似，谱聚类只需要数据之间的相似度矩阵就可以了，而不必像<code>K-means</code>那样要求数据必须是<code>N</code>维欧氏空间中的向量。</p>
</li>
<li><p>由于抓住了主要矛盾，忽略了次要的东西，因此比传统的聚类算法更加健壮一些，对于不规则的误差数据不是那么敏感，而且性能也要好一些。</p>
</li>
<li><p>计算复杂度比<code>K-means</code>要小，特别是在像文本数据或者平凡的图像数据这样维度非常高的数据上运行的时候。</p>
</li>
</ul>
<p>&emsp;&emsp;快速迭代算法和谱聚类算法都是将数据点嵌入到由相似矩阵推导出来的低维子空间中，然后直接或者通过<code>k-means</code>算法产生聚类结果，但是快速迭代算法有不同的地方。下面重点了解快速迭代算法的原理。</p>
<h2 id="快速迭代算法的原理"><a href="#快速迭代算法的原理" class="headerlink" title="快速迭代算法的原理"></a>快速迭代算法的原理</h2><p>&emsp;&emsp;在快速迭代算法中，我们构造另外一个矩阵$W=D^{-1}A$ ,同第一章做比对，我们可以知道<code>W</code>的最大特征向量就是拉普拉斯矩阵<code>L</code>的最小特征向量。<br>我们知道拉普拉斯矩阵有一个特性：第二小特征向量（即第二小特征值对应的特征向量）定义了图最佳划分的一个解，它可以近似最大化划分准则。更一般的，<code>k</code>个最小的特征向量所定义的子空间很适合去划分图。<br>因此拉普拉斯矩阵第二小、第三小直到第<code>k</code>小的特征向量可以很好的将图<code>W</code>划分为<code>k</code>个部分。</p>
<p>&emsp;&emsp;注意，矩阵<code>L</code>的<code>k</code>个最小特征向量也是矩阵<code>W</code>的<code>k</code>个最大特征向量。计算一个矩阵最大的特征向量可以通过一个简单的方法来求得，那就是快速迭代（即<code>PI</code>）。<br><code>PI</code>是一个迭代方法，它以任意的向量$v^{0}$作为起始，依照下面的公式循环进行更新。</p>
<div  align="center"><img src="../images/imgs13/PIC.1.1.png" width = "120" height = "23" alt="1.1" align="center" /></div><br />

<p>&emsp;&emsp;在上面的公式中，<code>c</code>是标准化常量，是为了避免$v^{t}$产生过大的值，这里$c=||Wv^{t}||_{1}$ 。在大多数情况下，我们只关心第<code>k</code>（k不为1）大的特征向量，而不关注最大的特征向量。<br>这是因为最大的特征向量是一个常向量：因为<code>W</code>每一行的和都为1。</p>
<p>&emsp;&emsp;快速迭代的收敛性在文献【1】中有详细的证明，这里不再推导。</p>
<p>&emsp;&emsp;快速迭代算法的一般步骤如下：</p>
<div  align="center"><img src="../images/imgs13/PIC.1.2.png" width = "480" height = "220" alt="1.2" align="center" /></div><br />

<p>&emsp;&emsp;在上面的公式中，输入矩阵<code>W</code>根据$W=D^{-1}A$来计算。</p>
<h2 id="快速迭代算法的源码实现"><a href="#快速迭代算法的源码实现" class="headerlink" title="快速迭代算法的源码实现"></a>快速迭代算法的源码实现</h2><p>&emsp;&emsp;在<code>spark</code>中，文件<code>org.apache.spark.mllib.clustering.PowerIterationClustering</code>实现了快速迭代算法。我们从官方给出的例子出发来分析快速迭代算法的实现。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.clustering.&#123;<span class="type">PowerIterationClustering</span>, <span class="type">PowerIterationClusteringModel</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></span><br><span class="line"><span class="comment">// 加载和切分数据</span></span><br><span class="line"><span class="keyword">val</span> data = sc.textFile(<span class="string">&quot;data/mllib/pic_data.txt&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> similarities = data.map &#123; line =&gt;</span><br><span class="line">  <span class="keyword">val</span> parts = line.split(&#x27; &#x27;)</span><br><span class="line">  (parts(<span class="number">0</span>).toLong, parts(<span class="number">1</span>).toLong, parts(<span class="number">2</span>).toDouble)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 使用快速迭代算法将数据分为两类</span></span><br><span class="line"><span class="keyword">val</span> pic = <span class="keyword">new</span> <span class="type">PowerIterationClustering</span>()</span><br><span class="line">  .setK(<span class="number">2</span>)</span><br><span class="line">  .setMaxIterations(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">val</span> model = pic.run(similarities)</span><br><span class="line"><span class="comment">//打印出所有的簇</span></span><br><span class="line">model.assignments.foreach &#123; a =&gt;</span><br><span class="line">  println(<span class="string">s&quot;<span class="subst">$&#123;a.id&#125;</span> -&gt; <span class="subst">$&#123;a.cluster&#125;</span>&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在上面的例子中，我们知道数据分为三列，分别是起始id，目标id，以及两者的相似度，这里的<code>similarities</code>代表前面章节提到的矩阵<code>A</code>。有了数据之后，我们通过<code>PowerIterationClustering</code>的<code>run</code>方法来训练模型。<br><code>PowerIterationClustering</code>类有三个参数：</p>
<ul>
<li><code>k</code>：聚类数</li>
<li><code>maxIterations</code>：最大迭代数</li>
<li><code>initMode</code>：初始化模式。初始化模式分为<code>Random</code>和<code>Degree</code>两种，针对不同的模式对数据做不同的初始化操作</li>
</ul>
<p>&emsp;&emsp;下面分步骤介绍<code>run</code>方法的实现。</p>
<ul>
<li><strong>（1）标准化相似度矩阵<code>A</code>到矩阵<code>W</code></strong></li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span></span>(similarities: <span class="type">RDD</span>[(<span class="type">Long</span>, <span class="type">Long</span>, <span class="type">Double</span>)]): <span class="type">Graph</span>[<span class="type">Double</span>, <span class="type">Double</span>] = &#123;</span><br><span class="line">    <span class="comment">//获得所有的边</span></span><br><span class="line">    <span class="keyword">val</span> edges = similarities.flatMap &#123; <span class="keyword">case</span> (i, j, s) =&gt;</span><br><span class="line">      <span class="comment">//相似度值必须非负</span></span><br><span class="line">      <span class="keyword">if</span> (s &lt; <span class="number">0.0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">&quot;Similarity must be nonnegative but found s($i, $j) = $s.&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (i != j) &#123;</span><br><span class="line">        <span class="type">Seq</span>(<span class="type">Edge</span>(i, j, s), <span class="type">Edge</span>(j, i, s))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">None</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//根据edges信息构造图，顶点的特征值默认为0</span></span><br><span class="line">    <span class="keyword">val</span> gA = <span class="type">Graph</span>.fromEdges(edges, <span class="number">0.0</span>)</span><br><span class="line">    <span class="comment">//计算从顶点的出发的边的相似度之和，在这里称为度</span></span><br><span class="line">    <span class="keyword">val</span> vD = gA.aggregateMessages[<span class="type">Double</span>](</span><br><span class="line">      sendMsg = ctx =&gt; &#123;</span><br><span class="line">        ctx.sendToSrc(ctx.attr)</span><br><span class="line">      &#125;,</span><br><span class="line">      mergeMsg = _ + _,</span><br><span class="line">      <span class="type">TripletFields</span>.<span class="type">EdgeOnly</span>)</span><br><span class="line">    <span class="comment">//计算得到W , W=A/D</span></span><br><span class="line">    <span class="type">GraphImpl</span>.fromExistingRDDs(vD, gA.edges)</span><br><span class="line">      .mapTriplets(</span><br><span class="line">        <span class="comment">//gAi/vDi</span></span><br><span class="line">        <span class="comment">//使用边的权重除以起始点的度</span></span><br><span class="line">        e =&gt; e.attr / math.max(e.srcAttr, <span class="type">MLUtils</span>.<span class="type">EPSILON</span>),</span><br><span class="line">        <span class="type">TripletFields</span>.<span class="type">Src</span>)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;上面的代码首先通过边集合构造图<code>gA</code>,然后使用<code>aggregateMessages</code>计算每个顶点的度（即所有从该顶点出发的边的相似度之和），构造出<code>VertexRDD</code>。最后使用现有的<code>VertexRDD</code>和<code>EdgeRDD</code>，<br>相继通过<code>fromExistingRDDs</code>和<code>mapTriplets</code>方法计算得到最终的图<code>W</code>。在<code>mapTriplets</code>方法中，对每一个<code>EdgeTriplet</code>，使用相似度除以出发顶点的度（为什么相除？对角矩阵的逆矩阵是各元素取倒数，$W=D^{-1}A$就可以通过元素相除得到）。</p>
<p>&emsp;&emsp;下面举个例子来说明这个步骤。假设有<code>v1,v2,v3,v4</code>四个点，它们之间的关系如下图所示，并且假设点与点之间的相似度均设为1。</p>
<div  align="center"><img src="../images/imgs13/PIC.1.3.png" width = "330" height = "280" alt="1.3" align="center" /></div><br />

<p>&emsp;&emsp;通过该图，我们可以得到相似度矩阵<code>A</code>和度矩阵<code>D</code>，他们分别如下所示。</p>
<div  align="center"><img src="../images/imgs13/PIC.1.4.png" width = "350" height = "85" alt="1.4" align="center" /></div><br />

<p>&emsp;&emsp;通过<code>mapTriplets</code>的计算，我们可以得到从点<code>v1</code>到<code>v2,v3,v4</code>的边的权重分别为<code>1/3,1/3,1/3</code>;从点<code>v2</code>到<code>v1,v3,v4</code>的权重分别为<code>1/3,1/3,1/3</code>;从点<code>v3</code>到<code>v1,v2</code>的权重分别为<code>1/2,1/2</code>;从点<code>v4</code>到<code>v1,v2</code>的权重分别为<code>1/2,1/2</code>。<br>将这个图转换为矩阵的形式，可以得到如下矩阵<code>W</code>。</p>
<div  align="center"><img src="../images/imgs13/PIC.1.5.png" width = "480" height = "175" alt="1.5" align="center" /></div><br />

<p>&emsp;&emsp;通过代码计算的结果和通过矩阵运算得到的结果一致。因此该代码实现了$W=D^{-1}A$ 。</p>
<ul>
<li><strong>（2）初始化$v^{0}$</strong></li>
</ul>
<p>&emsp;&emsp;根据选择的初始化模式的不同，我们可以使用不同的方法初始化$v^{0}$ 。一种方式是随机初始化，一种方式是度（<code>degree</code>）初始化，下面分别来介绍这两种方式。</p>
<ul>
<li>随机初始化</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomInit</span></span>(g: <span class="type">Graph</span>[<span class="type">Double</span>, <span class="type">Double</span>]): <span class="type">Graph</span>[<span class="type">Double</span>, <span class="type">Double</span>] = &#123;</span><br><span class="line">   <span class="comment">//给每个顶点指定一个随机数</span></span><br><span class="line">   <span class="keyword">val</span> r = g.vertices.mapPartitionsWithIndex(</span><br><span class="line">     (part, iter) =&gt; &#123;</span><br><span class="line">       <span class="keyword">val</span> random = <span class="keyword">new</span> <span class="type">XORShiftRandom</span>(part)</span><br><span class="line">       iter.map &#123; <span class="keyword">case</span> (id, _) =&gt;</span><br><span class="line">         (id, random.nextGaussian())</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;, preservesPartitioning = <span class="literal">true</span>).cache()</span><br><span class="line">   <span class="comment">//所有顶点的随机值的绝对值之和</span></span><br><span class="line">   <span class="keyword">val</span> sum = r.values.map(math.abs).sum()</span><br><span class="line">   <span class="comment">//取平均值</span></span><br><span class="line">   <span class="keyword">val</span> v0 = r.mapValues(x =&gt; x / sum)</span><br><span class="line">   <span class="type">GraphImpl</span>.fromExistingRDDs(<span class="type">VertexRDD</span>(v0), g.edges)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>度初始化</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initDegreeVector</span></span>(g: <span class="type">Graph</span>[<span class="type">Double</span>, <span class="type">Double</span>]): <span class="type">Graph</span>[<span class="type">Double</span>, <span class="type">Double</span>] = &#123;</span><br><span class="line">   <span class="comment">//所有顶点的度之和</span></span><br><span class="line">   <span class="keyword">val</span> sum = g.vertices.values.sum()</span><br><span class="line">   <span class="comment">//取度的平均值</span></span><br><span class="line">   <span class="keyword">val</span> v0 = g.vertices.mapValues(_ / sum)</span><br><span class="line">   <span class="type">GraphImpl</span>.fromExistingRDDs(<span class="type">VertexRDD</span>(v0), g.edges)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;通过初始化之后，我们获得了向量$v^{0}$ 。它包含所有的顶点，但是顶点特征值发生了改变。随机初始化后，特征值为随机值；度初始化后，特征为度的平均值。</p>
<p>&emsp;&emsp;在这里，度初始化的向量我们称为“度向量”。度向量会给图中度大的节点分配更多的初始化权重，使其值可以更平均和快速的分布，从而更快的局部收敛。详细情况请参考文献【1】。</p>
<ul>
<li><strong>（3）快速迭代求最终的v</strong></li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (iter &lt;- <span class="number">0</span> until maxIterations <span class="keyword">if</span> math.abs(diffDelta) &gt; tol) &#123;</span><br><span class="line">      <span class="keyword">val</span> msgPrefix = <span class="string">s&quot;Iteration <span class="subst">$iter</span>&quot;</span></span><br><span class="line">      <span class="comment">// 计算w*vt</span></span><br><span class="line">      <span class="keyword">val</span> v = curG.aggregateMessages[<span class="type">Double</span>](</span><br><span class="line">        <span class="comment">//相似度与目标点的度相乘</span></span><br><span class="line">        sendMsg = ctx =&gt; ctx.sendToSrc(ctx.attr * ctx.dstAttr),</span><br><span class="line">        mergeMsg = _ + _,</span><br><span class="line">        <span class="type">TripletFields</span>.<span class="type">Dst</span>).cache()</span><br><span class="line">      <span class="comment">// 计算||Wvt||_1，即第二章公式中的c</span></span><br><span class="line">      <span class="keyword">val</span> norm = v.values.map(math.abs).sum()</span><br><span class="line">      <span class="keyword">val</span> v1 = v.mapValues(x =&gt; x / norm)</span><br><span class="line">      <span class="comment">// 计算v_t+1和v_t的不同</span></span><br><span class="line">      <span class="keyword">val</span> delta = curG.joinVertices(v1) &#123; <span class="keyword">case</span> (_, x, y) =&gt;</span><br><span class="line">        math.abs(x - y)</span><br><span class="line">      &#125;.vertices.values.sum()</span><br><span class="line">      diffDelta = math.abs(delta - prevDelta)</span><br><span class="line">      <span class="comment">// 更新v</span></span><br><span class="line">      curG = <span class="type">GraphImpl</span>.fromExistingRDDs(<span class="type">VertexRDD</span>(v1), g.edges)</span><br><span class="line">      prevDelta = delta</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在上述代码中，我们通过<code>aggregateMessages</code>方法计算$Wv^{t}$ 。我们仍然以第（1）步的举例来说明这个方法。假设我们以度来初始化$v^{0}$ ，<br>在第一次迭代中，我们可以得到<code>v1</code>（注意这里的<code>v1</code>是上面举例的顶点）的特征值为<code>(1/3)*(3/10)+(1/3)*(1/5)+(1/3)*(1/5)=7/30</code>，<code>v2</code>的特征值为<code>7/30</code>，<code>v3</code>的特征值为<code>3/10</code>,<code>v4</code>的特征值为<code>3/10</code>。即满足下面的公式。</p>
<div  align="center"><img src="../images/imgs13/PIC.1.6.png" width = "340" height = "180" alt="1.6" align="center" /></div><br />

<ul>
<li><strong>（4）使用<code>k-means</code>算法对v进行聚类</strong></li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span></span>(v: <span class="type">VertexRDD</span>[<span class="type">Double</span>], k: <span class="type">Int</span>): <span class="type">VertexRDD</span>[<span class="type">Int</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> points = v.mapValues(x =&gt; <span class="type">Vectors</span>.dense(x)).cache()</span><br><span class="line">    <span class="keyword">val</span> model = <span class="keyword">new</span> <span class="type">KMeans</span>()</span><br><span class="line">      .setK(k)</span><br><span class="line">      .setRuns(<span class="number">5</span>)</span><br><span class="line">      .setSeed(<span class="number">0</span>L)</span><br><span class="line">      .run(points.values)</span><br><span class="line">    points.mapValues(p =&gt; model.predict(p)).cache()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;如果对<code>graphX</code>不太了解，可以阅读<a target="_blank" rel="noopener" href="https://github.com/endymecy/spark-graphx-source-analysis">spark graph使用和源码解析</a></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[【1】Frank Lin,William W. Cohen.Power Iteration Clustering](papers/Power Iteration Clustering.pdf)</p>
<p><a target="_blank" rel="noopener" href="http://blog.pluskid.org/?p=287">【2】漫谈 Clustering (4): Spectral Clustering</a></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>快速迭代聚类</p><p><a href="https://hunlp.com/posts/3118787290.html">https://hunlp.com/posts/3118787290.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>ฅ´ω`ฅ</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-08-01</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2019-08-03</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/spark/">spark, </a><a class="link-muted" rel="tag" href="/tags/%E8%81%9A%E7%B1%BB/">聚类 </a></div></div><div class="bdsharebuttonbox"><a class="bds_more" href="#" data-cmd="more"></a><a class="bds_qzone" href="#" data-cmd="qzone" title="分享到QQ空间"></a><a class="bds_tsina" href="#" data-cmd="tsina" title="分享到新浪微博"></a><a class="bds_tqq" href="#" data-cmd="tqq" title="分享到腾讯微博"></a><a class="bds_renren" href="#" data-cmd="renren" title="分享到人人网"></a><a class="bds_weixin" href="#" data-cmd="weixin" title="分享到微信"></a></div><script>window._bd_share_config = { "common": { "bdSnsKey": {}, "bdText": "", "bdMini": "2", "bdPic": "", "bdStyle": "0", "bdSize": "16" }, "share": {} }; with (document) 0[(getElementsByTagName('head')[0] || body).appendChild(createElement('script')).src = 'http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion=' + ~(-new Date() / 36e5)];</script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/3881616076.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item">线性支持向量机</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/2667793592.html"><span class="level-item">流式`k-means`算法</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "69d45ac0cc35c53e09ccd23d21c334a1",
            repo: "Cartride.github.io",
            owner: "Cartride",
            clientID: "8f4a2426c347380a6ee4",
            clientSecret: "8dc8cd44b071426b35d0bd60634941371170b798",
            admin: ["Cartride"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a><p class="is-size-7"><span>&copy; 2021 ฅ´ω`ฅ</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>