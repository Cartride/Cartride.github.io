<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Statistical Machine Translation：IBM Models 1 and 2 - MCFON</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="MCFON"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="MCFON"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Introduction这部分讲机器翻译，尤其是在统计机器翻译（SMT）系统上，此部分关注IBM翻译模型。这里以翻译法语(源语言)为英语(目标语言)为例，用$f$表示法语句子，即$f_1,f_2…f_m$，其中m为句子的长度；用e表示英语句子，即$e_1,e_2…e_l$，其中l表示英语句子的长度。用$(f^{(k)},e^{k})$表示第k个法语句子和英语句子。"><meta property="og:type" content="blog"><meta property="og:title" content="Statistical Machine Translation：IBM Models 1 and 2"><meta property="og:url" content="https://hunlp.com/posts/3979220335.html"><meta property="og:site_name" content="MCFON"><meta property="og:description" content="Introduction这部分讲机器翻译，尤其是在统计机器翻译（SMT）系统上，此部分关注IBM翻译模型。这里以翻译法语(源语言)为英语(目标语言)为例，用$f$表示法语句子，即$f_1,f_2…f_m$，其中m为句子的长度；用e表示英语句子，即$e_1,e_2…e_l$，其中l表示英语句子的长度。用$(f^{(k)},e^{k})$表示第k个法语句子和英语句子。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g91ytmyz6qj30jk0eeq4h.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g91ywegt5oj30kt0hh40m.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g91z0sh7kjj30lm0grdhm.jpg"><meta property="article:published_time" content="2018-03-15T01:29:26.000Z"><meta property="article:modified_time" content="2019-12-25T21:23:34.521Z"><meta property="article:author" content="ฅ´ω`ฅ"><meta property="article:tag" content="统计机器翻译"><meta property="article:tag" content="IBM Modes"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g91ytmyz6qj30jk0eeq4h.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hunlp.com/posts/3979220335.html"},"headline":"Statistical Machine Translation：IBM Models 1 and 2","image":["https://tva1.sinaimg.cn/large/006y8mN6gy1g91ytmyz6qj30jk0eeq4h.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g91ywegt5oj30kt0hh40m.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g91z0sh7kjj30lm0grdhm.jpg"],"datePublished":"2018-03-15T01:29:26.000Z","dateModified":"2019-12-25T21:23:34.521Z","author":{"@type":"Person","name":"ฅ´ω`ฅ"},"publisher":{"@type":"Organization","name":"MCFON","logo":{"@type":"ImageObject","url":"https://hunlp.com/img/logo.png"}},"description":"Introduction这部分讲机器翻译，尤其是在统计机器翻译（SMT）系统上，此部分关注IBM翻译模型。这里以翻译法语(源语言)为英语(目标语言)为例，用$f$表示法语句子，即$f_1,f_2…f_m$，其中m为句子的长度；用e表示英语句子，即$e_1,e_2…e_l$，其中l表示英语句子的长度。用$(f^{(k)},e^{k})$表示第k个法语句子和英语句子。"}</script><link rel="canonical" href="https://hunlp.com/posts/3979220335.html"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-03-15T01:29:26.000Z" title="2018/3/15 上午9:29:26">2018-03-15</time>发表</span><span class="level-item"><time dateTime="2019-12-25T21:23:34.521Z" title="2019/12/26 上午5:23:34">2019-12-26</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></span><span class="level-item">16 分钟读完 (大约2349个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">Statistical Machine Translation：IBM Models 1 and 2</h1><div class="content"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>这部分讲机器翻译，尤其是在统计机器翻译（SMT）系统上，此部分关注IBM翻译模型。这里以翻译法语(源语言)为英语(目标语言)为例，用$f$表示法语句子，即$f_1,f_2…f_m$，其中m为句子的长度；用e表示英语句子，即$e_1,e_2…e_l$，其中l表示英语句子的长度。用$(f^{(k)},e^{k})$表示第k个法语句子和英语句子。</p>
<span id="more"></span>

<h2 id="The-Noisy-Channel-Approach"><a href="#The-Noisy-Channel-Approach" class="headerlink" title="The Noisy-Channel Approach"></a>The Noisy-Channel Approach</h2><p>IBM模型是一个噪声通道模型的例子，给出两个参数，用$p(e)$表示任意一个句子$e_1,e_2…e_l$在英语中的概率，用$p(f|e)$表示出现法语/英语对的概率，那么对于该模型，给定一个新的法语句子，其输出的结果是（即对应的英语句子）：<br>$$<br>e^{*}=arg ,, \max_{e \in E} ,,p(e)p(f|e)<br>$$<br>这个前面的章节中有讲到为什么，这里就直接用了。此时的重点在于如何定义模型$p(f|e)$，以及如何从训练集$(f^{(k)},e^{(k)}) ,,for,,k=1…n$中评估模型的参数？</p>
<h2 id="The-IBM-Models"><a href="#The-IBM-Models" class="headerlink" title="The IBM Models"></a>The IBM Models</h2><p>直接求解$p(f_1…f_m|e_1…e_l,m)$比较难，将其条件概率细化为$p(f_1…f_m,a_1…a_m|e_1…e_l,m)$，其中变量$a_1…a_m$的$a_i \in {0,0,…,l}$表示法语的第i个单词对应英语的某个单词，这样再回到原条件概率：<br>$$<br>p(f_1…f_m|e_1…e_l)=\sum_{a_1=0}^{l}\sum_{a_2=0}^{l}…\sum_{a_m=0}^{l}p(f_1…f_m,a_1…a_m|e_1…e_l)<br>$$</p>
<h3 id="IBM-Model2"><a href="#IBM-Model2" class="headerlink" title="IBM Model2"></a>IBM Model2</h3><p>用一个有限集$\varepsilon$表示英语单词集，用$F$表示法语集，用$M$和$L$分别表示法语的最大长度和英语的最大长度，下面给出两个参数：</p>
<ul>
<li>一个是$t(f|e)$，表示从英语单词e生成法语单词f的条件概率，其中$f \in F , e \in \varepsilon \cup {NULL}$</li>
<li>一个是$q(j|i,l,m)$，表示在法语句子和英语句子长度分别为m和l的条件下，对齐变量$a_i$值为j的概率，其中$l \in{1…L}，m \in {1…M}，i \in {1…m}，j \in {0…l}$<br>前面讲到的条件概率有如下等价：<br>$$<br>p(f_1…f_m,a_1…a_m|e_1…e_l,m)=\prod_{i=1}^mq(a_i|i,l,m)t(f_i|e_{a_i})<br>$$</li>
</ul>
<p>此处定义$e_0$为<code>NULL</code>。<br>上式为什么就等价呢，下面用随机变量来讲解：<br>定义$E_1…E_l$为对应英语句子中单词的随机变量序列，L为英语句子长度的随机变量，$F_1…F_m$为法语单词的随机变量序列，M为法语句子长度的随机变量，$A_1…A_m$为对齐变量，这样建立模型为:<br>$$<br>P(F_1=f_1…F_m=f_m,A_1=a_1…A_m=a_m|E_1=e_1…E_l=e_l,L=l,M=m)<br>$$<br>上式用条件概率展开如下：<br>$$<br>P(F_1=f_1…F_m=f_m,A_1=a_1…A_m=a_m|E_1=e_1…E_l=e_l,L=l,M=m)\<br>=P(A_1=a_1…A_m=a_m|E_1=e_1…E_l=e_l,L=l,M=m)\cdot \<br>P(F_1=f_1…F_m=f_m|A_1=a_1…A_m=a_m,E_1=e_1…E_l=e_l,L=l,M=m)<br>$$<br>上面两部分分别做如下两个假设：</p>
<p>1、<br>$$<br>P(A_1=a_1…A_m=a_m|E_1=e_1…E_l=e_l,L=l,M=m)\<br>=\prod_{i=1}^{m}P(A_i=a_i|A_1=a_1…A_{i-1}=a_{i-1},E_1=e_1…E_l=e_l,L=l,M=m)\<br>=\prod_{i=1}^{m}P(A_i=a_i|L=l,M=m)<br>$$<br>2、<br>$$<br>P(F_1=f_1…F_m=f_m|A_1=a_1…A_m=a_m,E_1=e_1…E_l=e_l,L=l,M=m)\<br>=\prod_{i=1}^{m}P(F_i=f_i|F_1=f_1…F_{i-1}=f_{i-1},A_1=a_1…A_m=a_m,E_1=e_1…E_l=e_l,L=l,M=m)\<br>=\prod_{i=1}^{m}P(F_i=f_i|E_{a_i}=e_{a_i})<br>$$<br>第二行假设随机变量$F_i$仅仅依赖于$E_{ai}$<br>【【此处假设有点强，Fi竟然和其它的法语变量没关系…有点不太懂？？？】】</p>
<h2 id="Applying-IBM-Model-2"><a href="#Applying-IBM-Model-2" class="headerlink" title="Applying IBM Model 2"></a>Applying IBM Model 2</h2><p>前面讲到了IBM Model 2 中的参数$q(j|i,l,m)$和$t(f|e)$，即我们知道了分布$p(f,a|e)$，而我们需要知道对于任意的$f,a,e$，得出如下分布：<br>$$<br>p(f|e)=\sum_ap(f,a|e)<br>$$<br>最后，假定我们已经估计了语言模型$p(e)$，那么我们对任意一个法语句子f的翻译结果就是：<br>$$<br>arg,, \max_ep(e)p(f|e)<br>$$<br>IBM模型并不是一个好的翻译系统，但是仍然是一个关键的算法 ，这里说道的两种原因：$t(f|e)$被用到各种翻译系统，现代的翻译模型都是建立在IBM模型上的。<br>继续接上面最后的公式，对于由英语句子和法语句子对组成的训练集中，我们可以分析出一组对齐变量，使得下面的概率最大，也就是最符合的对齐变量：<br>$$<br>arg ,, \max_{a_1…a_l}p(a_1…a_m|f_1…f_m,e_1…e_l,m)<br>$$<br>继而求解如下子问题：<br>$$<br>a_i=arg,, \max_{j \in (0…l)}(q(j|i,l,m)t(f_i|e_j))<br>$$</p>
<h2 id="Parameter-Estimation"><a href="#Parameter-Estimation" class="headerlink" title="Parameter Estimation"></a>Parameter Estimation</h2><p>定义$c(e,f)$表示在训练集中单词e和单词l对齐的次数，$c(e)$表示e和任意一个法语单词对齐的次数，$c(j|i,l,m)$表示在看到长度为l的英语句子和长度为m的法语句子，且在看到单词i对应的是单词j的次数(就是$a_i=j$的次数)，$c(i,l,m)$表示长度为l的英语句子和长度为m的法语句子下标为i的个数。<br>上面的含义有点乱，而且下面给出的算法我也是看了好一会才理解什么意思，如下分别对全部语料库和部分语料库给出的算法，这里先分析对全部语料库的算法：<br><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g91ytmyz6qj30jk0eeq4h.jpg"></p>
<p>接上面定义的变量的含义，这里当$a_i^{(k)}=j$时，有$\delta(k,i,j)=1$，否则为0；算法中每次都会一起加1，看着值一样，其实是有区别的，这里我举个例子：<br>训练集中的数据为$f^{(k)},e^{(k)},a^{(k)}$拿书中的一个句子为例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l=6,m=7</span><br><span class="line">e= And the programma has been implemented</span><br><span class="line">f= Le programme a ete mis en application</span><br><span class="line">a=&#123;2,3,4,5,6,6,6&#125;</span><br></pre></td></tr></table></figure>
<p>这里$c(e)$就没什么好说的，就是统计如$c(And),c(the)$的个数，$c(e,f)$就是统计如$c(the,Le)$的个数，$c(j|i,l,m)$作如下解释，比如f中第一个单词Le对应e中第二个单词the，那么就将$c(2|1,6,7)$的值增加1，当然，对于$c(the),c(the,Le),c(1,6,7)$都会增加1，也就是说如果还有这样一个样本l=6，m=7，同时f中的第一个单词对应着e中第二个单词，那么$c(2|1,6,7),c(1,6,7)$也会增加1，但是$c(the),c(the,Le)$就不会增加了，这样就理解上面的算法了吧。接着看下面的算法：<br><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g91ywegt5oj30kt0hh40m.jpg"></p>
<p>观察两个算法的区别，主要在于$\delta(k,i,j)=1$计算不同，$\delta(k,i,j)=1$表示第k组平行预料（训练集中法文-英文句子）里的第i个法文词，第j个英文词。如果是上帝模式，那$\delta(k,i,j)=1/0$分别表示这两个词之间应当/不应当对齐，其问题在于我们不可能有全部语料库，也就是说等于1或者0，没有人能够知道，所以采用最大似然估计来估计（EM算法），于是就采用如下公式：<br>$$<br>\delta(k,i,j)=\frac{q(j|i,l_k,m_k)t(f_i^{(k)}|e_j^{(k)})}{\sum_{j=0}^{l_k}q(j|i,l_k,m_k)t(f_i^{(k)}|e_j^{(k)})}<br>$$</p>
<h2 id="More-on-the-EM-Algorithm-Maximum-likelihood-Estimation"><a href="#More-on-the-EM-Algorithm-Maximum-likelihood-Estimation" class="headerlink" title="More on the EM Algorithm: Maximum-likelihood Estimation"></a>More on the EM Algorithm: Maximum-likelihood Estimation</h2><p>这部分好像没什么用额，功力不够，就不写了</p>
<h2 id="Initialzation-using-IBM-Model-1"><a href="#Initialzation-using-IBM-Model-1" class="headerlink" title="Initialzation using IBM Model 1"></a>Initialzation using IBM Model 1</h2><p>EM算法对IBM模型2的初始化敏感，依赖初始值(随机数)，这里使用IBM模型1，主要区别在于将模型2开始对$q(j|i,l,m)$的概率设为定值：<br>$$<br>q(j|i,l,m)=\frac{1}{l+1}<br>$$<br>注意这里的分母$l+1$表示的是j全部的取值个数，$j \in {0,1,…,l}$，这样做的意思就是说，在长度分别为l和m的英语句子和法语句子中，$a_i$对应j的关系是同概率的，没有什么相关性。<br>那么句子预测结果的概条件率公式可重写如下：<br>$$<br>p(f_1…f_m,a_1…a_m|e_1…e_l,m)=\prod \frac{1}{l+1}t(f_i|e_{a_i})=\frac{1}{(1+l)^m}\prod_{i=1}^{m}t(f_i|e_{a_i})<br>$$<br>EM算法重写如下：<br>$$<br>\delta(k,i,j)=\frac{q(j|i,l_k,m_k)t(f_i^{(k)}|e_j^{(k)})}{\sum_{j=0}^{l_k}q(j|i,l_k,m_k)t(f_i^{(k)}|e_j^{(k)})}<br>=\frac{t(f_i^{(k)}|e_j^{(k)}}{\sum_{j=0}^{l_k}t(f_i^{(k)}|e_j^{(k)})}<br>$$<br>算法如下：<br><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g91z0sh7kjj30lm0grdhm.jpg"></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Statistical Machine Translation：IBM Models 1 and 2</p><p><a href="https://hunlp.com/posts/3979220335.html">https://hunlp.com/posts/3979220335.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>ฅ´ω`ฅ</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2018-03-15</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2019-12-26</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/">统计机器翻译</a><a class="link-muted mr-2" rel="tag" href="/tags/IBM-Modes/">IBM Modes</a></div><div class="bdsharebuttonbox"><a class="bds_more" href="#" data-cmd="more"></a><a class="bds_qzone" href="#" data-cmd="qzone" title="分享到QQ空间"></a><a class="bds_tsina" href="#" data-cmd="tsina" title="分享到新浪微博"></a><a class="bds_tqq" href="#" data-cmd="tqq" title="分享到腾讯微博"></a><a class="bds_renren" href="#" data-cmd="renren" title="分享到人人网"></a><a class="bds_weixin" href="#" data-cmd="weixin" title="分享到微信"></a></div><script>window._bd_share_config = { "common": { "bdSnsKey": {}, "bdText": "", "bdMini": "2", "bdPic": "", "bdStyle": "0", "bdSize": "16" }, "share": {} }; with (document) 0[(getElementsByTagName('head')[0] || body).appendChild(createElement('script')).src = 'http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion=' + ~(-new Date() / 36e5)];</script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/1528548331.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item">HMM模型</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/2923522808.html"><span class="level-item">XGBoost算法原理小结</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "0a3d302b78883edb40e05e5d1557dd51",
            repo: "Cartride.github.io",
            owner: "Cartride",
            clientID: "8f4a2426c347380a6ee4",
            clientSecret: "8dc8cd44b071426b35d0bd60634941371170b798",
            admin: ["Cartride"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Golang/"><span class="level-start"><span class="level-item">Golang</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/LeetCode/"><span class="level-start"><span class="level-item">LeetCode</span></span><span class="level-end"><span class="level-item tag">62</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="level-start"><span class="level-item">数据结构</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">26</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CNN/"><span class="level-start"><span class="level-item">CNN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">迁移学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%A0%B4%E8%A7%A3/"><span class="level-start"><span class="level-item">破解</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">算法</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">英语学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a><p class="is-size-7"><span>&copy; 2021 ฅ´ω`ฅ</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>