<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Attention机制 - MCFON</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="MCFON"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="MCFON"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Encoder-Decoder所谓encoder-decoder模型，又叫做编码-解码模型。这是一种应用于seq2seq问题的模型。 什么是seq2seq呢？简单的说，就是根据一个序列x，来生成另一个输出序列y。seq2seq有很多应用，例如翻译，文档摘要，问答系统等等。在翻译中，输入序列是待翻译的文本，输出序列是翻译后的文本；在问答系统中，输入序列是提出的问题，而输出序列是答案。"><meta property="og:type" content="blog"><meta property="og:title" content="Attention机制"><meta property="og:url" content="https://hunlp.com/posts/2591765099.html"><meta property="og:site_name" content="MCFON"><meta property="og:description" content="Encoder-Decoder所谓encoder-decoder模型，又叫做编码-解码模型。这是一种应用于seq2seq问题的模型。 什么是seq2seq呢？简单的说，就是根据一个序列x，来生成另一个输出序列y。seq2seq有很多应用，例如翻译，文档摘要，问答系统等等。在翻译中，输入序列是待翻译的文本，输出序列是翻译后的文本；在问答系统中，输入序列是提出的问题，而输出序列是答案。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006tNbRwgy1g9y1rxvkdmj30q608xaar.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006tNbRwgy1g9y23ckxwqj30od0dkwff.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006tNbRwgy1g9y2jwe59nj30dr0f5q41.jpg"><meta property="article:published_time" content="2019-12-15T20:05:23.000Z"><meta property="article:modified_time" content="2019-12-15T20:47:51.891Z"><meta property="article:author" content="ฅ´ω`ฅ"><meta property="article:tag" content="Attention"><meta property="article:tag" content="Seq2seq"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://tva1.sinaimg.cn/large/006tNbRwgy1g9y1rxvkdmj30q608xaar.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hunlp.com/posts/2591765099.html"},"headline":"Attention机制","image":["https://tva1.sinaimg.cn/large/006tNbRwgy1g9y1rxvkdmj30q608xaar.jpg","https://tva1.sinaimg.cn/large/006tNbRwgy1g9y23ckxwqj30od0dkwff.jpg","https://tva1.sinaimg.cn/large/006tNbRwgy1g9y2jwe59nj30dr0f5q41.jpg"],"datePublished":"2019-12-15T20:05:23.000Z","dateModified":"2019-12-15T20:47:51.891Z","author":{"@type":"Person","name":"ฅ´ω`ฅ"},"publisher":{"@type":"Organization","name":"MCFON","logo":{"@type":"ImageObject","url":"https://hunlp.com/img/logo.png"}},"description":"Encoder-Decoder所谓encoder-decoder模型，又叫做编码-解码模型。这是一种应用于seq2seq问题的模型。 什么是seq2seq呢？简单的说，就是根据一个序列x，来生成另一个输出序列y。seq2seq有很多应用，例如翻译，文档摘要，问答系统等等。在翻译中，输入序列是待翻译的文本，输出序列是翻译后的文本；在问答系统中，输入序列是提出的问题，而输出序列是答案。"}</script><link rel="canonical" href="https://hunlp.com/posts/2591765099.html"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?b99420d7a06d2b3361a8efeaf6e20764";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-131608076-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-131608076-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>Attention机制</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="${date_xml(page.date)}" title="${date_xml(page.date)}">2019-12-16</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="${date_xml(page.updated)}" title="${date_xml(page.updated)}">2019-12-16</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></span><span class="level-item">22 分钟读完 (大约3232个字)</span></div></div><div class="content"><h2 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h2><p>所谓encoder-decoder模型，又叫做编码-解码模型。这是一种应用于seq2seq问题的模型。</p>
<p>什么是seq2seq呢？简单的说，就是根据一个序列x，来生成另一个输出序列y。seq2seq有很多应用，例如翻译，文档摘要，问答系统等等。在翻译中，输入序列是待翻译的文本，输出序列是翻译后的文本；在问答系统中，输入序列是提出的问题，而输出序列是答案。</p>
<span id="more"></span>
<p>为了解决seq2seq问题，有人提出了encoder-decoder模型，也就是编码-解码模型。所谓编码，就是将输入序列转化成一个固定长度的向量；解码，就是将之前生成的固定向量再转化成输出序列。<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9y1rxvkdmj30q608xaar.jpg"></p>
<p>当然了，这个只是大概的思想，具体实现的时候，编码器和解码器都不是固定的，可选的有CNN/RNN/BiRNN/GRU/LSTM等等，你可以自由组合。比如说，你在编码时使用BiRNN，解码时使用RNN，或者编码时使用RNN，解码时使用LSTM等等。</p>
<p>这边为了方便阐述，选取了编码和解码都是RNN的组合。在RNN中，当前时间的隐藏状态是由上一时间的状态和当前时间输入决定的，也就是<br>$$<br>h_t=f(h_{t-1},x_t)<br>$$<br>获得了各个时间段的隐藏层以后，再将隐藏层的信息汇总，生成最后的语义向量<br>$$<br>C=q(h_1,h_2,h_3,…,h_{T_{x}})<br>$$<br>一种简单的方法是将最后的隐藏层作为语义向量$C$，即<br>$$<br>C=q(h_1,h_2,h_3,…h_{T_{x}})=h_{T_{x}}<br>$$<br>解码阶段可以看做编码的逆过程。这个阶段，我们要根据给定的语义向量$C$和之前生成的输出序列$y_1,y_2,….y_{t-1}$来预测下一个输出的单词$y_t$，即<br>$$<br>y_t=argmaxP(y_t)=\prod^T <em>{t=1}p(y_t \mid \lbrace y_1,…y</em>{t-1} \rbrace,C)<br>$$<br>也可以写作<br>$$<br>y_t=g(\lbrace y_1,…y_{t-1}\rbrace,C)<br>$$<br>而在RNN中，上式又可以简化成<br>$$<br>y_t=g(y_{t-1},s_t,C)<br>$$<br>其中$s$是输出RNN中的隐藏层，$C$代表之前提过的语义向量，$y_{t-1}$表示上个时间段的输出，反过来作为这个时间段的输入，而$g$则可以是一个非线性的多层的神经网络，产生词典中各个词语属于$y_t$的概率。</p>
<p>encoder-decoder模型虽然非常经典，但是局限性也非常大。最大的局限性就在于编码和解码之间的唯一联系就是一个固定长度的语义向量$C$。也就是说，编码器要将整个序列信息压缩进一个固定长度的向量中去。但是这样做有两个弊端，一是语义向量无法完全表示整个序列的信息，还有就是先输入的内容携带的信息会被后输入的信息稀释掉，或者说，被覆盖了。输入序列越长，这个现象就越严重。这就使得在解码的时候一开始就没有获得输入序列足够的信息，那么解码的准确度自然也就要打个折扣了。</p>
<h2 id="Attention模型"><a href="#Attention模型" class="headerlink" title="Attention模型"></a>Attention模型</h2><p>为了解决这个问题，提出了Attention模型，或者说注意力模型。简单的说，这种模型在产生输出的时候，还会产生一个‘注意力范围’表示接下来输出的时候要重点关注输入序列的哪些部分，然后根据关注的区域来产生下一个输出，如此往复。模型的大概示意图如下所示<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9y23ckxwqj30od0dkwff.jpg"></p>
<p>相比之前的encoder-decoder模型，attention的模型最大的区别就在于它不在要求编码器将所有输入信息都编码进一个固定长度的向量之中。相反，此时编码器需要将输入编码成一个向量的序列，而在解码的时候，每一步都会选择性的从向量序列中挑选一个子集进行一步处理。这样，在产生每一个输出的时候，都能够做到充分利用输入序列携带的信息。而且这种方法在翻译任务中取得了非常不错的效果。</p>
<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>在单向的RNN中，数据是按顺序输入的，因此在第$j$个隐藏状态$h_j$只能携带第$j$个单词本身以及之前的一些信息；而如果逆序输入，则$h_j$包含第$j$个单词及以后的一些信息。如果把这个两个结合起来，$h_j=[h\to j,h \gets j]$就包含了第$j$个输入和前后的信息。</p>
<h2 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h2><p>解码部分使用了attention模型。类似的，我们可以将之前定义的条件概率写作<br>$$<br>p(y_i\mid y_1,…,y_{i-1},X)=g(y_{i-1},s_i,c_i)<br>$$<br>上式$s_i$表示解码器$i$时刻的隐藏状态。计算公式是<br>$$<br>s_i=f(s_{i-1},y_{i-1},c_i)<br>$$<br>注意这里的条件概率与每个目标输出$y_i$相对应的内容向量$c_i$有关。而在传统的方式中，只有一个内容向量$C$。那么这里的内容向量$c_i$又该怎么算呢？其实$c_i$是由编码时的隐藏向量序列$(h_1,…h_{T_{x}})$按权重相加得到的。<br>$$<br>c_i=\sum_{j=1}^{T_x}\alpha_{ij}h_j<br>$$<br>由于编码使用了双向RNN，因此可以认为$h_i$中包含了输入序列中第$i$个词以及前后一些词的信息。将隐藏向量序列按权重相加，表示在生成第$j$个输出的时候注意力分配是不同的。$\alpha_{ij}$的值越高，表示第$i$个输出在第$j$个输入上分配的注意力越多，在生成第$i$个输出的时候受第$j$个输入的影响也就越大。那么我们现在又有新问题了，$\alpha_{ij}$又是怎么得到呢？这个其实是由第$i-1$个输出隐藏状态$s_{i-1}$和输入中各个隐藏状态共同决定的。也就是<br>$$<br>\alpha_{ij}=\frac{exp(e_{ij})}{\sum_{k=1}^{T_x}exp(e_{ik})}\e_{ij}=a(s_{i-1},h_j)<br>$$<br>也就是说，$s_{i-1}$先跟每个$h$分别计算得到一个数值，然后使用softmax得到$i$时刻的输出在$T_x$个输入隐藏状态中的注意力分配向量。这个分配向量也就是计算$c_i$的权重。我们现在再把公式按照执行顺序汇总一下：<br>上面这些公式就是解码器在第$i$个时间段内要做的事情。作者还给了一个示意图:<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9y2jwe59nj30dr0f5q41.jpg"></p>
<h2 id="序列中的Attention"><a href="#序列中的Attention" class="headerlink" title="序列中的Attention"></a>序列中的Attention</h2><p>Attention机制的基本思想是，打破了传统编码器-解码器结构在编解码结构时都依赖于内部一个固定长度向量的限制。</p>
<p>Attention机制的实现是通过保留LSTM编码器对输入序列的中间输出结果，然后训练一个模型来对这些输入进行选择性的学习并且在模型输出时将输出序列与之进行关联。</p>
<p>换一个角度而言，输出序列的每一项的生成概率取决于在输入序列中选择了哪些项。</p>
<blockquote>
<p>在文本翻译任务上，使用Attention机制的模型每生成一个词时都会在输入序列中找出一个与之最相关的词集合。之后模型根据当前的上下文向量(context vectors)和之前生成出的词来预测下一个目标词。<br>…它将输入序列转化为一堆向量并自适应地从中选择一个子集来解码出目标翻译文本。这感觉上像是用于文本翻译的神经网络模型需要‘压缩’输入文本中的所有信息为一个固定长度的向量，不论输入文本的长短。<br>via：Dzmitry Bahdanau, et al., Neural machine translation by jointly learning to align and translate, 2015</p>
</blockquote>
<h2 id="Attention-is-all-you-need"><a href="#Attention-is-all-you-need" class="headerlink" title="Attention is all you need"></a>Attention is all you need</h2><p>Google的一般化Attention思路也是一个编码序列的方案，因此我们也可以认为它跟RNN、CNN一样，都是一个序列编码的层。</p>
<p>事实上Google给出的方案是很具体的。首先，它先把Attention的定义给了出来：<br>$$<br>Attention(\boldsymbol{Q},\boldsymbol{K},\boldsymbol{V}) = softmax\left(\frac{\boldsymbol{Q}\boldsymbol{K}^{\top}}{\sqrt{d_k}}\right)\boldsymbol{V}<br>$$<br>这里用的是跟Google的论文一致的符号,其中$\boldsymbol{Q}\in\mathbb{R}^{n\times d_k}, \boldsymbol{K}\in\mathbb{R}^{m\times d_k}, \boldsymbol{V}\in\mathbb{R}^{m\times d_v}$。 如果忽略激活函数$softmax$的话，那么事实上它就是三个$n\times d_k,d_k\times m, m\times d_v$的矩阵相乘，最后的结果就是一个$n*d_v$的序列。</p>
<p>那怎么理解这种结构呢？我们不妨逐个向量来看。<br>$$<br>Attention(\boldsymbol{q}<em>t,\boldsymbol{K},\boldsymbol{V}) = \sum</em>{s=1}^m \frac{1}{Z}\exp\left(\frac{\langle\boldsymbol{q}_t, \boldsymbol{k}_s\rangle}{\sqrt{d_k}}\right)\boldsymbol{v}_s<br>$$<br>其中$Z$是归一化因子。事实上$q.k,v$分别是$query,key,value$的简写，$K,V$是一一对应的，它们就像是key-value的关系，那么上式的意思就是通过$q_t$这个query,通过与各个$k_S$内积的softmax的方式，来得到$q_t$和各个$v_s$的相似度，然后加权求和，得到一个$d_v$维的向量。其中因子$\sqrt d_k$起到调节作用，使得内积不至于太大（太大的话softmax后就非0即1了，不够“soft”了）。</p>
<p>事实上这种Attention的定义并不新鲜，但由于Google的影响力，我们可以认为现在是更加正式地提出了这个定义，并将其视为一个层地看待；此外这个定义只是注意力的一种形式，还有一些其他选择，比如query跟key的运算方式不一定是点乘（还可以是拼接后再内积一个参数向量），甚至权重都不一定要归一化，等等。</p>
<p>多头attention(Mutli-head attention) ,Query,Key,Value首先经过一个线性变换，然后输入到缩放点积attention,注意这里要做h次，其实也就是所谓的多头，每一次算一个头。而且每次Q,K,V进行线性变换的参数<br>W<br>是不一样的。然后将h次的放缩点积attention 结果进行拼接，再进行一次线性变换得到的值作为多头attention的结果。可以看到，google提出来的多头attention的不同之处在于进行了h次计算而不仅仅计算一次，论文中说到这样的好处是可以允许模型在不同的表示空间里学到相关的信息。</p>
<p>self-attention可以是一般的attention的一种特殊情况，在self-attention中，$Q=K=V$每个序列中的单元和该序列中所有单元进行attention计算。Google提出的多头attention通过计算多次来捕获不同子空间上的相关信息。self-attention的特点在于无视词之间的距离直接计算依赖关系，能够学习一个句子的内部结构，实现也较为简单并行可以并行计算。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>采用传统编码器-解码器结构的LSTM/RNN模型存在一个问题，不论输入长短都将其编码成一个固定长度的向量表示，这使模型对于输入长序列的学习效果很差(解码效果很差)。</li>
<li>而Attention机制则克服了上述问题，原理是在模型输出时会选择性地专注考虑输入中的对应相关的信息。</li>
<li>使用Attention机制的方法被广泛应用在各种序列预测任务上，包括文本翻译，语音识别等。</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Attention机制</p><p><a href="https://hunlp.com/posts/2591765099.html">https://hunlp.com/posts/2591765099.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>ฅ´ω`ฅ</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-12-16</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2019-12-16</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Attention/">Attention, </a><a class="link-muted" rel="tag" href="/tags/Seq2seq/">Seq2seq </a></div></div><div class="bdsharebuttonbox"><a class="bds_more" href="#" data-cmd="more"></a><a class="bds_qzone" href="#" data-cmd="qzone" title="分享到QQ空间"></a><a class="bds_tsina" href="#" data-cmd="tsina" title="分享到新浪微博"></a><a class="bds_tqq" href="#" data-cmd="tqq" title="分享到腾讯微博"></a><a class="bds_renren" href="#" data-cmd="renren" title="分享到人人网"></a><a class="bds_weixin" href="#" data-cmd="weixin" title="分享到微信"></a></div><script>window._bd_share_config = { "common": { "bdSnsKey": {}, "bdText": "", "bdMini": "2", "bdPic": "", "bdStyle": "0", "bdSize": "16" }, "share": {} }; with (document) 0[(getElementsByTagName('head')[0] || body).appendChild(createElement('script')).src = 'http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion=' + ~(-new Date() / 36e5)];</script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/1772150868.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item">梯度提升树(GBDT)原理小结</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/2109189733.html"><span class="level-item">GloVe数学原理详解</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "0efe79652c95991c769158cf40fe6894",
            repo: "Cartride.github.io",
            owner: "Cartride",
            clientID: "8f4a2426c347380a6ee4",
            clientSecret: "8dc8cd44b071426b35d0bd60634941371170b798",
            admin: ["Cartride"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a><p class="is-size-7"><span>&copy; 2021 ฅ´ω`ฅ</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>