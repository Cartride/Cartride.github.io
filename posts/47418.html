<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>SSD-Single Shot MultiBox Detector - MCFON</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="MCFON"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="MCFON"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="​ 本文使用单个深度神经网络来做目标检测。我们的方法称为SSD;将bounding boxes输出离散化为在每个feature map上的一组不同长宽比及不同尺寸的一组默认边框。相对于需要对象提议的方法，SSD非常简单，因为它完全消除了提案生成和随后的像素或特征重新采样阶段，并将所有计算封装在单个网络中。"><meta property="og:type" content="blog"><meta property="og:title" content="SSD-Single Shot MultiBox Detector"><meta property="og:url" content="https://hunlp.com/posts/47418.html"><meta property="og:site_name" content="MCFON"><meta property="og:description" content="​ 本文使用单个深度神经网络来做目标检测。我们的方法称为SSD;将bounding boxes输出离散化为在每个feature map上的一组不同长宽比及不同尺寸的一组默认边框。相对于需要对象提议的方法，SSD非常简单，因为它完全消除了提案生成和随后的像素或特征重新采样阶段，并将所有计算封装在单个网络中。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gttcz5ccphj60hc07b0tf02.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gttczfy0f1j60ys0m5q6x02.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gttd0gf7x2j60hc05wmxn02.jpg"><meta property="og:image" content="https://hunlp.com/posts/pic/SSD-tab3.jpg"><meta property="article:published_time" content="2021-08-25T13:31:18.000Z"><meta property="article:modified_time" content="2021-08-25T13:34:49.169Z"><meta property="article:author" content="ฅ´ω`ฅ"><meta property="article:tag" content="SSD"><meta property="article:tag" content="CV"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gttcz5ccphj60hc07b0tf02.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hunlp.com/posts/47418.html"},"headline":"SSD-Single Shot MultiBox Detector","image":["https://tva1.sinaimg.cn/large/008i3skNly1gttcz5ccphj60hc07b0tf02.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gttczfy0f1j60ys0m5q6x02.jpg","https://tva1.sinaimg.cn/large/008i3skNly1gttd0gf7x2j60hc05wmxn02.jpg","https://hunlp.com/posts/pic/SSD-tab3.jpg"],"datePublished":"2021-08-25T13:31:18.000Z","dateModified":"2021-08-25T13:34:49.169Z","author":{"@type":"Person","name":"ฅ´ω`ฅ"},"publisher":{"@type":"Organization","name":"MCFON","logo":{"@type":"ImageObject","url":"https://hunlp.com/img/logo.png"}},"description":"​ 本文使用单个深度神经网络来做目标检测。我们的方法称为SSD;将bounding boxes输出离散化为在每个feature map上的一组不同长宽比及不同尺寸的一组默认边框。相对于需要对象提议的方法，SSD非常简单，因为它完全消除了提案生成和随后的像素或特征重新采样阶段，并将所有计算封装在单个网络中。"}</script><link rel="canonical" href="https://hunlp.com/posts/47418.html"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?b99420d7a06d2b3361a8efeaf6e20764";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-131608076-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-131608076-1');</script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>SSD-Single Shot MultiBox Detector</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="${date_xml(page.date)}" title="${date_xml(page.date)}">2021-08-25</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="${date_xml(page.updated)}" title="${date_xml(page.updated)}">2021-08-25</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span><span class="level-item">16 分钟读完 (大约2406个字)</span></div></div><div class="content"><p>​ 本文使用单个深度神经网络来做目标检测。我们的方法称为SSD;将bounding boxes输出离散化为在每个feature map上的一组不同长宽比及不同尺寸的一组默认边框。相对于需要对象提议的方法，SSD非常简单，因为它完全消除了提案生成和随后的像素或特征重新采样阶段，并将所有计算封装在单个网络中。 <span id="more"></span> 在 prediction 阶段：计算出每一个 default box 中的物体，其属于每个类别的可能性，即 score，得分。如对于 PASCAL VOC 数据集，总共有 20 类，那么得出每一个 bounding box 中物体属于这 20 个类别的每一种的可能性。同时，要对这些 bounding boxes 的 shape 进行微调，以使得其符合物体的 外接矩形。还有就是，为了处理相同物体的不同尺寸的情况，SSD 结合了不同分辨率的 feature maps 的 predictions。</p>
<pre><code>       相对于那些需要 object proposals 的检测模型，本文的 SSD 方法完全取消了</code></pre>
<p>proposals generation、pixel resampling 或者 feature resampling 这些阶段。这样使得 SSD 更容易去优化训练，也更容易地将检测模型融合进系统之中。</p>
<pre><code>       在 PASCAL VOC、MS COCO、ILSVRC 数据集上的实验显示，SSD</code></pre>
<p>在保证精度的同时，其速度要比用 region proposals 的方法要快很多。SSD 相比较于其他单结构模型（YOLO），SSD 取得更高的精度，即是是在输入图像较小的情况下。如输入 300×300 大小的 PASCAL VOC 2007 test 图像，在 Titan X 上，SSD 以 58 帧的速率，同时取得了 72.1% 的 mAP。如果输入的图像是 500×500，SSD 则取得了 75.1% 的 mAP，比目前最 state-of-art 的 Faster R-CNN 要好很多。</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gttcz5ccphj60hc07b0tf02.jpg" /></p>
<p>参考：<a target="_blank" rel="noopener" href="https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab">Understanding SSD MultiBox — Real-Time Object Detection In Deep Learning</a> 、<a target="_blank" rel="noopener" href="http://www.sohu.com/a/168738025_717210">SSD:Single Shot MultiBox Detector深度学习笔记之SSD物体检测模型</a></p>
<p>论文地址: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.02325.pdf" class="uri">https://arxiv.org/pdf/1512.02325.pdf</a></p>
<p>工程地址：<a target="_blank" rel="noopener" href="https://github.com/weiliu89/caffe/tree/ssd" class="uri">https://github.com/weiliu89/caffe/tree/ssd</a></p>
<h2 id="依赖知识">依赖知识</h2>
<p>1：熟悉图像分类网络</p>
<p>2：熟悉目标检测技术：Faster R-CNN, YOLO</p>
<h2 id="网络结构">网络结构</h2>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gttczfy0f1j60ys0m5q6x02.jpg" /></p>
<h3 id="基础网络">基础网络</h3>
<pre><code>  本文的 Base network 是基于VGG16，在ILSVRC CLS-LOC数据集上进行了预训练。</code></pre>
<ol type="a">
<li><p>将VGG中的 FC6 layer、FC7 layer 转成为卷积层，并从模型的 FC6、FC7 上的参数，进行下采样得到这两个卷积层的参数。</p></li>
<li><p>将Pool5 layer的参数，从 2×2−s2 转变成 3×3−s1;但是这样变化后，会改变感受野（receptive field）的大小。因此，采用了atrous convolution(就是<a href="/confluence/pages/createpage.action?spaceKey=tybbdbsrp&amp;title=FCN%26&amp;linkCreation=true&amp;fromPageId=10485860">空洞卷积</a>)的技术。</p></li>
<li><p>并删除fc8 layer和所有的dropout层。</p></li>
<li><p>增加了4个卷积层。</p></li>
<li><p>使用用SGD 精调；学习率 0.001 , momentum 0.9 , weight decay 0.0005, batch size 32</p></li>
</ol>
<h3 id="多尺寸特征图检测">多尺寸特征图检测</h3>
<pre><code>  使用不同的卷积层来预测；卷积层的大学逐步减少，可以在不同的scales上预测。</code></pre>
<h3 id="卷积器检测">卷积器检测</h3>
<pre><code>  可以使用一系列 convolutional filters，去产生一系列固定大小的</code></pre>
<p>predictions。对于一个大小为 m×n ，具有 p 通道的特征层，使用的 convolutional filters 就是 3×3×p 的 kernels来预测类别和边框值。</p>
<h3 id="default-boxes-默认边框">Default boxes-默认边框</h3>
<pre><code> 将一组默认边框default box与不同层的feature map cell关联。假设每个feature</code></pre>
<p>map cell有k个default box，那么对于每个default box都需要预测c个类别score和4个offset，那么如果一个feature map的大小是m×n，也就是有m*n个feature map cell，那么这个feature map就一共有（c+4)*k*m*n 个输出。</p>
<pre><code> 注：default box与Faster R-CNN中的anchor类似。不过SSD将default</code></pre>
<p>box应用在多个feature map上</p>
<h3 id="训练过程">训练过程</h3>
<h4 id="匹配策略">匹配策略</h4>
<pre><code>  a) 对每个ground truth box找jaccard</code></pre>
<p>overlap(就是<a href="/confluence/pages/viewpage.action?pageId=9773751#YOLO工程测试-youonlylookonce-IoU">IOU-交并比</a>)最高的default box。</p>
<pre><code>  b) default boxes如果在任一个ground truth box的jaccard overlap大于阈值0.5。

  以上两种情况可以匹配的default boxes就是候选的样本;其中完全匹配ground</code></pre>
<p>truth的是正样本，其它是负样本。</p>
<h4 id="训练目标">训练目标</h4>
<p><span class="math display">\[
L(x,c,l,g) = \frac 1 N (L_{conf}(x,c) + \alpha L_{loc}(x,l,g)) \ \ \ \ (1) \\
L_{loc}(x,l,g) = \sum^N_{i \in Pos} \sum_{m \in \{cx,cy,w,h\}} x^k_{ij} smooth_{L1}(l^m_i - \hat g^m_i) \\
\hat g^{cx} = (g^{cx}_j - d^{cx}_i)/d^w_i \ \ \ \ \ \  \hat g^{cy} = (g^{cy}_j - d^{cy}_i)/d^h_i \\
\hat g^w_j = log( \frac {g^w_j} {d^w_i}) \ \ \ \ \ \  \hat g^h_j = log(\frac {g^h_j} {d^h_j}) \\
\ \ \\
L_{conf}(x, c) = - \sum^N_{i \in Pos} x^p_{ij}log(\hat c^p_i) \ \ \ where \ \ \  \hat c^p_i = \frac {exp(c^p_i)} {\sum_p exp(c^p_i)}
\]</span></p>
<h4 id="困难负样本挖掘">困难负样本挖掘</h4>
<p>在匹配策略完成后，产生的负样本会远远大于正样本；使用负样本中分类置信度损失函数最高的那些样本作为真正的负样本；选择的数目使得正负样本比例1：3。</p>
<h3 id="预测过程">预测过程</h3>
<pre><code> 对生成大量的 bounding boxes，首先通过设置 confidence</code></pre>
<p>的阈值为 0.01 ，我们可以过滤掉大多数的 boxes；然后对每一类使用jaccard overlap阈值0.45 来做Non-maximum suppression（NMS）；对每张图片保留最佳的200个检测结果。</p>
<h2 id="关键点">关键点</h2>
<h3 id="default-boxes尺寸和长宽比">default boxes尺寸和长宽比</h3>
<ol type="a">
<li><p>尺寸</p>
<pre><code>那么default box的scale（大小）和aspect</code></pre>
<p>ratio（横纵比）要怎么定呢？假设我们用m个feature maps做预测，那么对于每个featuer map而言其default box的scale是按以下公式计算的</p></li>
</ol>
<p><span class="math inline">\(s_k = s_{min} + \frac {s_{max} -s_{min}} {m - 1}(k -1), \ \ k \in [1, m]\)</span></p>
<p>这里smin是0.2，表示最底层的scale是0.2；smax是0.9，表示最高层的scale是0.9。</p>
<ol start="2" type="a">
<li>长宽比</li>
</ol>
<p>aspect ratio，用ar表示为下式：注意这里一共有5种aspect ratio；</p>
<p><span class="math inline">\(a_r \in \{1, 2, 3, 1/2 , 1/3 \}\)</span></p>
<p>; 宽度</p>
<p><span class="math inline">\(w^a_k = s_k \sqrt a_r\)</span></p>
<p>；高度</p>
<p><span class="math inline">\(h^a_k = s_k / \sqrt a_r\)</span></p>
<p>。另外当aspect ratio为1时，作者还增加一种scale的default box：</p>
<p><span class="math inline">\(s^‘_k = \sqrt{s_k s_{k+1}}\)</span></p>
<p>。</p>
<p>这样对于么个feature map cell有6中可选的default box。</p>
<ol start="3" type="a">
<li>中心</li>
</ol>
<p>每个 的中心坐标为<span class="math inline">\((\frac {i+0.5} {|f_k|}, \frac {j+0.5} {|f_k|})\)</span></p>
<p>；<span class="math inline">\(|f_k|\)</span></p>
<p>是方形feature map的尺寸大小，<span class="math inline">\(i,j \in [0, |f_k|)\)</span></p>
<p>最后会得到（38*38*4 + 19*19*6 + 10*10*6 + 5*5*6 + 3*3*4 + 1*1*4）= 8732个boxes；不是所有层feature map都使用6种default boxes。</p>
<h3 id="数据增广">数据增广</h3>
<p>每一张训练图像，随机的进行如下几种选择采样：</p>
<ul>
<li><p>使用原始的图像</p></li>
<li><p>随机采样一个 patch(CropImage)，与物体之间最小的 jaccard overlap 为：0.1，0.3，0.5，0.7 或 0.9。(这里的物体ojbects是? GT还是图片？)</p></li>
<li><p>随机采样一个 patch(CropImage)</p></li>
</ul>
<p>采样的 patch 是原始图像大小比例是 [0.1，1.0]，aspect ratio 在 0.5 到 2之间。当 groundtruth box 的 中心（center）在采样的 patch 中时，我们保留重叠部分。</p>
<p>最后，将采样resize到固定大小，并以0.5的概率水平翻转。</p>
<h2 id="实验结果">实验结果</h2>
<h3 id="数据增广非常关键">数据增广非常关键</h3>
<pre><code>    mAP有8.8%的提升。</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gttd0gf7x2j60hc05wmxn02.jpg" /></p>
<h3 id="更多-default-box形状效果更佳">更多 default box形状效果更佳</h3>
<pre><code>  从上图Table 2看效果。</code></pre>
<h3 id="atrous-卷积更快">Atrous 卷积更快</h3>
<pre><code>     atrous空洞卷积能够加快20%的速度</code></pre>
<h3 id="不同分辨率的输出层效果更佳">不同分辨率的输出层效果更佳</h3>
<figure>
<img src="pic/SSD-tab3.jpg" alt="C:\80523d166a7925fa27809958656d7a5e" /><figcaption aria-hidden="true">C:\80523d166a7925fa27809958656d7a5e</figcaption>
</figure>
<h2 id="疑问点">疑问点</h2>
<pre><code>  1) 在困难负样本挖掘中“Instead of using all the negative examples, we sort</code></pre>
<p>them using the highest confidence loss for each default box and pick the top ones so that the ratio between the negatives and positives is at most 3:1”。使用分类置信度损失函数排序，这里是训练阶段损失函数的参数还为得到，如何排序？是使用的交叉进行的方式么？</p>
<p>困难负样本挖掘的前向传播过程参数是单独训练的，其参数与后面进行的prior box回归与分类参数无关。困难负样本挖掘是在独立为match步骤后的default box做正负样本分类，进行一次前向传播，将负样本按loss贡献排序，优先选择loss贡献大的负样本，使得正负样本比例是1:3。</p>
<pre><code>  2）没有明确说明何为正样本论文， “For example, we have matched two default</code></pre>
<p>boxes with the cat and one with the dog, which are treated as positives and the rest as negatives”；匹配是怎样的？</p>
<p>论文章节2.2Matching strategy 中提到下文：</p>
<p><em>We begin by matching each ground truth box to the default box with the best jaccard overlap (as in MultiBox [7]). Unlike MultiBox, we then match default boxes to any ground truth with jaccard overlap higher than a threshold (0.5). This simplifies the learning problem, allowing the network to predict high scores for multiple overlapping default boxes rather than requiring it to pick only the one with maximum overlap.</em></p>
<p>意思是，先从groudtruth出发，将与groudtruth<strong>最匹配</strong>的default box放入<strong>候选正样本集；</strong>再从default box出发，将与ground truthIOU <strong>&gt;0.5</strong> 的default box放入<strong>候选正样本集。</strong></p>
<p>Faster RCNN中正样本选取也是利用的该方法，论文中原文描述如下：</p>
<p>We assign a positive label to two kinds of anchors: (i) the anchor/anchors with the highest Intersection-overUnion(IoU)overlapwithaground-truthbox,or(ii)an anchor that has an IoU overlap higher than 0.7 with any ground-truth box.</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>SSD-Single Shot MultiBox Detector</p><p><a href="https://hunlp.com/posts/47418.html">https://hunlp.com/posts/47418.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>ฅ´ω`ฅ</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-08-25</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-08-25</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/SSD/">SSD, </a><a class="link-muted" rel="tag" href="/tags/CV/">CV </a></div></div><div class="bdsharebuttonbox"><a class="bds_more" href="#" data-cmd="more"></a><a class="bds_qzone" href="#" data-cmd="qzone" title="分享到QQ空间"></a><a class="bds_tsina" href="#" data-cmd="tsina" title="分享到新浪微博"></a><a class="bds_tqq" href="#" data-cmd="tqq" title="分享到腾讯微博"></a><a class="bds_renren" href="#" data-cmd="renren" title="分享到人人网"></a><a class="bds_weixin" href="#" data-cmd="weixin" title="分享到微信"></a></div><script>window._bd_share_config = { "common": { "bdSnsKey": {}, "bdText": "", "bdMini": "2", "bdPic": "", "bdStyle": "0", "bdSize": "16" }, "share": {} }; with (document) 0[(getElementsByTagName('head')[0] || body).appendChild(createElement('script')).src = 'http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion=' + ~(-new Date() / 36e5)];</script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/zfb.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wx.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/21373.html"><span class="level-item">You Only Look Once Unified Real-Time Object Detection</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "bfe7a8cf0de0f72a19e87bc8a5e969cc",
            repo: "Cartride.github.io",
            owner: "Cartride",
            clientID: "8f4a2426c347380a6ee4",
            clientSecret: "8dc8cd44b071426b35d0bd60634941371170b798",
            admin: ["Cartride"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#依赖知识"><span class="level-left"><span class="level-item">1</span><span class="level-item">依赖知识</span></span></a></li><li><a class="level is-mobile" href="#网络结构"><span class="level-left"><span class="level-item">2</span><span class="level-item">网络结构</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#基础网络"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">基础网络</span></span></a></li><li><a class="level is-mobile" href="#多尺寸特征图检测"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">多尺寸特征图检测</span></span></a></li><li><a class="level is-mobile" href="#卷积器检测"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">卷积器检测</span></span></a></li><li><a class="level is-mobile" href="#default-boxes-默认边框"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">Default boxes-默认边框</span></span></a></li><li><a class="level is-mobile" href="#训练过程"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">训练过程</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#匹配策略"><span class="level-left"><span class="level-item">2.5.1</span><span class="level-item">匹配策略</span></span></a></li><li><a class="level is-mobile" href="#训练目标"><span class="level-left"><span class="level-item">2.5.2</span><span class="level-item">训练目标</span></span></a></li><li><a class="level is-mobile" href="#困难负样本挖掘"><span class="level-left"><span class="level-item">2.5.3</span><span class="level-item">困难负样本挖掘</span></span></a></li></ul></li><li><a class="level is-mobile" href="#预测过程"><span class="level-left"><span class="level-item">2.6</span><span class="level-item">预测过程</span></span></a></li></ul></li><li><a class="level is-mobile" href="#关键点"><span class="level-left"><span class="level-item">3</span><span class="level-item">关键点</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#default-boxes尺寸和长宽比"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">default boxes尺寸和长宽比</span></span></a></li><li><a class="level is-mobile" href="#数据增广"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">数据增广</span></span></a></li></ul></li><li><a class="level is-mobile" href="#实验结果"><span class="level-left"><span class="level-item">4</span><span class="level-item">实验结果</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#数据增广非常关键"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">数据增广非常关键</span></span></a></li><li><a class="level is-mobile" href="#更多-default-box形状效果更佳"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">更多 default box形状效果更佳</span></span></a></li><li><a class="level is-mobile" href="#atrous-卷积更快"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">Atrous 卷积更快</span></span></a></li><li><a class="level is-mobile" href="#不同分辨率的输出层效果更佳"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">不同分辨率的输出层效果更佳</span></span></a></li></ul></li><li><a class="level is-mobile" href="#疑问点"><span class="level-left"><span class="level-item">5</span><span class="level-item">疑问点</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="MCFON" height="28"></a><p class="is-size-7"><span>&copy; 2021 ฅ´ω`ฅ</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>